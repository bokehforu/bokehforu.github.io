var store = [{
        "title": "ELEC202 Lec 7&8 FM&PM",
        "excerpt":"mainly talk about FM&amp;PM in ELEC202 at Lec 7&amp;8   信号的过程   Components      Source encoder converts message into message signal.   Transmitter converts message signal or bits into format appropriate for channel transmission (analog/digital signal).   Channel introduces distortion, noise, and interference.   Receiver decodes received signal back to message signal.   Source decoder decodes message signal back into original message.   Communication System   COMP202 Lec 7&amp;8 FM&amp;PM           PM即时频率：$f_i(t) = f_c + k_p \\frac{dm}{dt}$，其中 $f_c$ 是载波频率，$k_p$ 是相位调制的灵敏度，$m(t)$ 是消息信号，$\\frac{dm}{dt}$ 是消息信号的导数。            FM即时频率：$f_i(t) = f_c + k_f m(t)$，其中 $f_c$ 是载波频率，$k_f$ 是频率调制的灵敏度，$m(t)$ 是消息信号。                                       频率偏差：$\\Delta f = \\max           f_i - f_c           $，频率偏差是指在频率调制中，载波频率最大的偏离程度。                                单音频FM信号：$X_{FM}(t) = A_c \\cos[2\\pi f_c t + \\beta \\sin(2\\pi f_m t)]$，这是一个单音频的频率调制信号的公式。其中 $A_c$ 是载波幅度，$f_c$ 是载波频率，$\\beta$ 是调制指数，$f_m$ 是消息信号的频率。            调制指数：$\\beta = \\frac{\\Delta f}{f_m}$，调制指数是频率偏差和消息频率的比值，在频率调制中，它是描述调制深度的关键参数。            卡森规则：$BW_{FM} \\approx 2(1 + \\beta)f_m$，这是卡森规则，用于估计频率调制信号的带宽。其中 $BW_{FM}$ 是频率调制信号的带宽，$\\beta$ 是调制指数，$f_m$ 是消息信号的频率。       如果 $\\beta « 1$，那么可以使用近似公式：$BW_{NB} \\approx 2f_m$，这是一个在调制指数很小的情况下用于估计频率调制信号带宽的近似公式。   LEC 7   FM频率调制   关于FM和PM，首先要知道三角函数的背景知识，定义一个正弦波的公式为   \\[\\mathrm{y}=\\mathrm{A} \\sin (\\mathrm{Bx}+\\mathrm{C})+\\mathrm{D}\\]     $\\mathrm{A}$ 是幅值   $\\mathrm{B}$是由$2 \\pi f$组成的   $C$ is the value of the phase   $D$ is the shifting of the $Y$ vaule in coordinate axes   So we could say that the trigonometric functions can be showed below  \\(x=A \\sin \\left(\\frac{2 \\pi}{T} t+\\varphi\\right)=A \\sin (2 \\pi f t+\\varphi)\\)   The key point here is I need understand the meaning and detail of phase and frequency. After it , we can talk about FM and PM right now.在上述等式中，T没有被讨论到。   FM定义  频率调制 调制是将载波信号的频率与载波信号的频率进行线性变化的过程，也是与信息信号进行线性变化的过程。 在PPT中，Dr.W give us that the definition of the FM which is a envaluation showing below. \\(f_i=f_c+k_f m(t)\\)     $k_f$ is the modulation sensitivity   modulation sensitivity 本质上是一个常数，调制灵敏度通常由偏差灵敏度来衡量，即输入信号频率给定变化时输出信号频率的变化。偏差灵敏度以赫兹/伏特（Hz/V）为单位表示，是衡量调频解调器的频率与电压传递函数的斜率。   在PPT中说，If the unit of $m(t)$ is volts, the unit of $kf$ is Hz/V. 我感觉$m(t)$的单位在课程背景中就是$v$   $fi$ is the final wave function的频率   $f{c}$ is the carrier frequncy which we need add in.   FM的瞬时频率  瞬时频率的 需要注意的是在这里需要明白频率和相位的关系。 频率是指信号在单位时间内完成的完整周期数，比如在一秒内完成的值。在这里举一个扩充的例子，$sin{（x）}$这个周期正弦波中，its $f$ is $1/2\\pi$. It is from the front fact about $B$. It indicates that in 1s, 在x轴上，这个函数前进了$1/2\\pi$的长度。这就是对频率$f$的定义。计算过程是 \\(B=1\\)   \\[B=2\\pi f\\]  \\[f=1/2\\pi\\]  因此，对于正弦波而言，频率可以表示为相位关于时间的导数，即f=dθ/dt。但是，这个关系式仅仅适用于正弦波这种特定形式的周期信号，并且仅仅在信号周期为定值时成立。 Instantaneous frequency: \\(f_i(t)=\\frac{1}{2 \\pi} \\frac{d \\theta(t)}{d t}=f_c+\\frac{1}{2 \\pi} \\frac{d \\varphi(t)}{dt}\\) 对于这个式子的解释是$\\theta(t)$是例如$Sin\\theta(t)$中的幅度角的值。由我们上面得出的正弦波的幅度和相位的关系和$B$的组成，可以知FM的调制方法后的信号的瞬时频率是 \\(f_i(t)=\\frac{1}{2 \\pi} \\frac{d \\theta(t)}{d t}\\) 解释一下就是由当前调制后信号的角度，经过$2\\pi f$得出$f$后，求导得出此时的瞬时频率，同时由于FM的调制方法，我们可以得出载波信号的频率是不会改变的，在变化的是我们的$m(t)$.$m(t)$有自己的幅度角，对其求导，得出关系式的后半部分。 \\(f_i(t)=f_c+\\frac{1}{2 \\pi} \\frac{d \\varphi(t)}{dt}\\) 由于我们是FM，所以对于载波信号是直接改变信号的频率的，而由频率的变化转化成幅度角的变化是由之前的关系得出的，所以对于FM中我们已知的变化的信号对应的frequency，我们需要使用   **相位 **   \\(\\varphi(t)=k_f \\int_{-\\infty}^t m(\\tau) d \\tau\\) 来得出我们需要的角幅度，再在(8)中被求导，来得出我们需要的瞬时频率。   PM的瞬时频率公式   Instantaneous frequency: \\(f_i(t)=\\frac{1}{2 \\pi} \\frac{d \\theta(t)}{d t}=f_c+\\frac{1}{2 \\pi} \\frac{d \\varphi(t)}{dt}\\)   PM调制直接是变化幅度角度，所以在使用此公式求瞬时frequency的时候，我们使用 \\(\\varphi(t)=k_p*m(t)\\)   Maximum-freq. deviation deviation in in FM   在频率调制（FM）中，最大频率偏差是指在信号传输过程中，载波频率被调制或偏离其原始频率的最大数量。最大频率偏差通常被指定为调频信号的一个参数，被定义为调制信号的瞬时频率与载波频率之间的最大差异。它通常以赫兹（Hz）为单位表示，与调制信号的振幅成正比。   最大频率偏差决定了调频信号的带宽。   公式如下,载波频率被调制或偏离其原始频率的最大数量。可以看到m(t)就是原始数据的函数表达 \\(\\Delta f_{\\max }=\\max \\left(f_i-f_c\\right)=k_f \\max [|m(t)|]\\)   FM modulation  index   \\[\\beta_f=\\frac{\\Delta f_{\\max }(调制指数)}{W(基带)}\\]  where W  is the bandwidth of m(t).   PM Signal Representation   PM调制是一种模拟调制技术，是指通过改变载波信号的相位来传输模拟信号。在相位调制中，相位与调制信号的瞬时振幅成正比。 \\(x(t)=A_c \\cos \\theta(t)=A_c \\cos \\left(2 \\pi f_c t+\\varphi(t)\\right)\\) 这里要重新提什么是相位，就是最开头的C，而对于x(t)来说，这个等式描述的是调制后的信号图像，可以看到，有$f_c$和$\\varphi(t)$ 这个本身在变化的信息上的角的度数。   这个公式同时对FM和PM适用，用来求出他们的实际调制后的函数图像。我们使用不同的$\\varphi(t)$来对应不同的调制方法。   FM   $\\varphi(t)$等于 \\(\\varphi(t)=k_f \\int_{-\\infty}^t m(\\tau) d \\tau\\) 原因之前有提过，FM我们只有变化的频率值，而在这我们需要知道变化的频率对应的角度，所以使用积分求出对应的角度   PM   在PM中，我们直接改变的就是相位角，使用$k_p* angle$的方法，就是我们改变的大小，所以在求的时候$\\varphi(t)$不用经过任何处理   $\\varphi(t)$等于 \\(\\varphi(t)=k_p\\times m(t)\\)   $k_p$and $k_f$ are deviation constants for PM and FM, respectively.The maximum-phase deviation in PM system is given by \\(\\Delta \\varphi_{\\max }=k_P \\max [|m(t)|]\\)   PM modulation index   \\[\\beta_P=\\Delta \\varphi_{\\text {max }}\\]  上面是什么  零零碎碎记的东西   小细节   Frequency or phase of the carrier varies according to the message signal. This is further divided into frequency and phase modulation.   Frequency Modulation is the process of varying the frequency of the carrier signal linearly with the message signal. Phase Modulation is the process of varying the phase of the carrier signal linearly with the message signal.   AM和FM的优劣   与调幅 Amplitude (AM)相比，角度Angle(AM)调制的优点：   更有效地使用功率： 像FM和PM这样的角度调制技术比AM更有效地使用功率，因为它们通过改变载波信号的频率或相位，而不是振幅来传输信息。载波信号的振幅保持不变，这意味着传输功率保持不变，从而更有效地利用功率。 更好的信号质量： 与调幅相比，角调制技术更不容易受到噪音和干扰的影响。角度调制信号的信噪比（SNR）更高，这意味着信号质量更好。这是因为噪声和干扰主要影响信号的振幅，而在角度调制技术中，振幅保持不变。   更大的带宽：   角度Angle(AM)调制比AM(classic)的缺点：   通常更大的带宽：角度调制技术通常需要比AM更大的带宽。这是因为载波信号的频率或相位被调制，这导致边带在频率上扩散，导致更宽的带宽。 较小的范围： 与调幅相比，角度调制技术的范围较小。这是因为接收器需要一个更高的信噪比（SNR）来解调信号。频率偏差越高，所需的信噪比就越高，这就限制了传输的范围。此外，角度调制信号受多径传播的影响，会造成干扰并降低范围。   角度调制特性   角度调制的特点有：      FM/PM信号的功率不随调制而变化。   FM/PM信号没有能够复制调制的包络。   载波频偏与调制信号的幅度成正比。   简要解释：      在角度调制中，频率和相位被用来调制载波信号，而不是振幅。因此，信号的功率不受调制影响，与原始载波信号的功率相同。   由于调制是通过改变相位或频率来实现的，因此无法在FM/PM信号的包络中复制出调制信号的形状。这与振幅调制(AM)不同，因为在AM中，信号的包络可以准确地复制出原始信号的形状。   调制信号的幅度变化会导致载波频率的偏移，这种频率偏移与调制信号的幅度成正比。因此，当调制信号的幅度变化较大时，载波的频率偏移也会相应地变大。   可以再放一个图片解释FM和PM的调制过程   LEC 8   Bandwidth estimation for FM, Carson’s Rule – Narrowband FM  – Wideband FM   FM Demodulation   – Slope detector  – Zero-crossing detector   Angle Modulation : recap   Modulated signal调制过的信号 is： $s(t)=A_c \\cos \\theta(t)$  $\\theta(t)$ is the angle:            $\\theta(t)=f(m(t))$   Standard FM:           $\\theta(t)=2 \\pi \\mathrm{f}{\\mathrm{c}} t+k{\\mathrm{f}} \\int \\mathrm{m}(\\tau) d \\tau$   频率调制 调制是将载波信号的频率与载波信号的频率进行线性变化的过程，也是与信息信号进行线性变化的过程。 在PPT中，Dr.W give us that the definition of the FM which is a envaluation showing below. \\(f_i=f_c+k_f m(t)\\) 所以  \\(s(t)=A_c \\cos (2 \\pi \\mathrm{f}_{\\mathrm{c}} t+k_{\\mathrm{f}} \\int \\mathrm{m}(\\tau) d \\tau)\\) Single tone FM signal \\(x_{F M}(t)=A_c \\cos \\left[2 \\pi f_c t+\\beta \\sin \\left(2 \\pi f_m t\\right)\\right]\\) 瞬时频率 \\(f_i(t)=\\frac{1}{2 \\pi} \\frac{d \\theta(t)}{d t}=f_c+\\frac{1}{2 \\pi} \\frac{d \\varphi(t)}{dt}\\)   对于这个函数来说，$ \\beta \\sin \\left(2 \\pi f_m t\\right)$ 和$k_{\\mathrm{f}} \\int \\mathrm{m}(\\tau) d \\tau$ 是相等的   Instantaneous frequency:    $f_i=f_c+k_f m(t)$   $kf$ is just a constant – modulation sensitivity.   phase in the integral of frequency, and frequency is the derivative of the phase   Instantaneous frequency = derivative of the angle   (for PM) $\\omega_i(t)=\\omega_c+k_p m^{\\prime}(t)$   (for FM) $\\omega_i(t)=\\omega_c+k_f m(t)$   Frequency deviation $=$ frequency sensitivity $\\times \\max $(message)   Frequency swing $=2 \\times$ frequency deviation   Modulation index $=$ deviation ratio $=\\beta$   $\\beta$$\\begin{aligned} &amp; =\\text { maximum frequency deviation } \\div \\text { baseband bandwidth } \\ &amp; =\\Delta f / f_{\\mathrm{m}}\\end{aligned}$   Bandwidth   Narrowband FM   Demodulation   ","categories": [],
        "tags": [],
        "url": "/comp-202/",
        "teaser": null
      },{
        "title": "ELEC211: Digital Electronics & Microprocessor Systems",
        "excerpt":"    The content contains two note-files, which only included the content from the ARM M0 teached by Dr. Pineapple Pizza. :)    The content has not been edited or corrected and may contain some errors.           The content of this file should be correct. I use this file to prepare for the final.                         ELEC 211       Digital Electronics &amp; Micro       88       Pass                               211       Written Exam (75%)       86                                 211.1       Course Work (10%)       100                                 211.2       Course Work (10%)       90                                 211.3       Course Work (5%)       88                          ","categories": [],
        "tags": [],
        "url": "/elec211pdf/",
        "teaser": null
      },{
        "title": "Proof of Cramer’s Rule",
        "excerpt":"The article contains three proofs.   证明一   证明：假设A是一个可逆的n × n矩阵，我们考虑线性系统AX = b。这个系统有一个唯一的解：   转换不了解，第二步转换 感觉是基础问题不知道 \\(X = A^{-1}b = \\frac{1}{|A|}\\text{adj}(A) \\cdot b = \\frac{1}{|A|} \\left[ \\begin{array}{cccc} A_{11} &amp; A_{21} &amp; \\cdots &amp; A_{n1} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ A_{1n} &amp; A_{2n} &amp; \\cdots &amp; A_{nn} \\end{array} \\right] b\\)   这里的 $\\cdot$ 表示矩阵乘法。通过矩阵乘法的公式，第k个未知数$x_k$可以写成：   \\[x_k = \\frac{1}{|A|} \\sum_{i=1}^{n} A_{ik}b_i = \\frac{1}{|A|} \\text{det} [c_1, \\ldots, c_{k-1}, b, c_{k+1}, \\ldots, c_n]\\]  这里$c_i$表示A的第i列。第二个等式来自于对矩阵 $[c_1, \\ldots, c_{k-1}, b, c_{k+1}, \\ldots, c_n]$ 沿第k列进行的余子式展开。   证明二   首先，假设我们有一个可逆的矩阵$A$，且$\\det(A) \\neq 0$，并且$Ax = b$是一个线性方程。我们声明这个方程有一个唯一解。注意到$A^{-1}b$是一个解，因为$A(A^{-1}b) = (AA^{-1})b = b$，所以解是存在的。   假设$s$是这个方程的一个任意解，所以$As = b$。但是，我们可以得到$s = (A^{-1}A)s = A^{-1}(As) = A^{-1}b$，所以$A^{-1}b$是唯一的解。   对于每一个整数$i, 1 \\leq i \\leq n$，让$a_i$表示$A$的第$i$列，$e_i$表示单位矩阵$I_n$的第$i$列，并且让$X_i$表示从$I_n$通过替换第$i$列为列向量$x$得到的矩阵。   我们知道对于任意的矩阵$A, B$，乘积$AB$的第$k$列是$A$和$B$的第$k$列的乘积。同时，观察到$Ae_k = a_k$对于$k = 1, …, n$。因此，通过乘法，我们有：   \\[\\begin{aligned} A X_i &amp; =A\\left(e_1, \\ldots, e_{i-1}, x, e_{i+1}, \\ldots, e_n\\right) \\\\ &amp; =\\left(A e_1, \\ldots, A e_{i-1}, A x, A e_{i+1}, \\ldots, A e_n\\right) \\\\ &amp; =\\left(a_1, \\ldots, a_{i-1}, b, a_{i+1}, \\ldots, a_n\\right) \\\\ &amp; =M_i \\end{aligned}\\]  因为$X_i$是用$x$替换了$I_n$的第$i$列，通过余子式展开计算$X_i$的行列式我们得到 ： \\(det(X_i) = (-1)^{i+i}x_i\\det(I_{n-1}) = 1 \\cdot x_i \\cdot 1 = x_i\\)   因此，根据行列式的乘法性质，我们有 \\(det(M_i) = \\det(AX_i) = \\det(A)\\det(X_i) = \\det(A)x_i\\)   所以，$x_i = \\frac{\\det(M_i)}{\\det(A)}$，这就是我们所需要的。   证明三   形式化总结   线性方程的矩阵表示 \\(Ax=c\\) 其中，系数矩阵 $A$ 是一个$  n×n$ 的方阵，$ x=(x_1,x_2,\\cdots,x_n)^T$是一个长度为$n$ 的列向量，$c= (c_1,c_2,\\cdots, C_n)^T$也是一个长度为n的列向量。   根据克拉默法则，方程的解为： \\(x_i=\\frac{D_i}{D},i=1,2,\\cdots,n\\)   其中， $Di$ 是用 $C$替换了$A$ 的第$i$列得到的矩阵的行列式,$D$则是$A$的行列式。可以看到，当$D$等于0时，原方程无解。   证明过程   将线性方程组 $A x=c$ 两边同时左乘 $A$ 的逆, 得到 $A^{-1} A x=A^{-1} c$, 即： \\(x=A^{-1} c \\text { 。 }\\) 我们将系数矩阵表示成列向量的形式, 即: \\(A=\\left(p_1, p_2, \\ldots, p_n\\right)\\) 因此原方程又可以写成: \\(\\sum_{k=1}^n x_k p_k=c\\) 则行列式 $D_i$ 的值可以表示为:第二个等号到第三个等号，可以理解为行和列等价，提出一个scalar？  \\(\\begin{aligned} D_i &amp; =\\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, c, p_{i+1} \\ldots, p_n\\right) \\\\ &amp; =\\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, \\sum_{k=1}^n x_k p_k, p_{i+1} \\ldots, p_n\\right) \\\\ &amp; =\\sum_{k=1}^n x_k \\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, p_k, p_{i+1} \\ldots, p_n\\right) \\\\ &amp; =x_1 \\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, p_1, p_{i+1} \\ldots, p_n\\right)+x_2 \\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, p_2, p_{i+1} \\ldots, p_n\\right)+\\ldots \\\\ &amp; \\quad+x_n \\operatorname{det}\\left(p_1, \\ldots, p_{i-1}, p_n, p_{i+1} \\ldots, p_n\\right) \\\\ &amp; =x_i \\cdot \\operatorname{det}(A) \\quad \\\\ &amp; =x_i \\cdot D \\quad \\end{aligned}\\) 所以 $x_i=\\frac{D_i}{D}$   总结   克拉默法则的表述                  数域 $K$ 上 $\\mathrm{n}$ 个方程的 $\\mathrm{n}$ 元线性方程组有唯一解的充要条件 $       A       \\neq 0$, 且解为 $\\left(\\frac{\\left       B_1\\right       }{       A       }, \\frac{\\left       B_2\\right       }{       A       }, \\cdots, \\frac{\\left       B_n\\right       }{       A       }\\right)$, 其中 $B_i$ 为用常数列替换 $A$ 第i列后的矩阵。           线性空间角度                  若 $\\alpha_1, \\alpha_2, \\ldots, \\alpha_n$ 是 $K^n$ 的一组基, $\\beta \\in K^n$ ，则 $\\beta=\\sum_{i=1}^n \\frac{\\left       B_i\\right       }{       A       } \\alpha_i$ 。           问题 如何理解这一结果?                                      $\\frac{\\left           B_i\\right           }{           A           }$ 有什么意义?                           行列式有什么意义?                                   为什么是 $\\frac{\\left           B_i\\right           }{           A           }$ ?                           对任意线性空间是否成立类似的结论?   能否类比定义域 $F$ 上的线性空间 $V$ 上的行列式 $\\Delta: V^n \\rightarrow F$, 从而有类似结论?   ​   几何角度   在 $K^n$ 中将一标架作非退化仿射变换 $\\sigma$ : \\(\\left\\{\\begin{array}{c} K^n \\rightarrow K^n \\\\ \\left\\{x_1, x_2, \\ldots, x_n\\right\\} \\mapsto\\left\\{\\sum_{j=1}^n f_1\\left(\\alpha_j\\right), \\sum_{j=1}^n f_2\\left(\\alpha_j\\right), \\ldots, \\sum_{j=1}^n f_n\\left(\\alpha_j\\right)\\right\\} \\end{array}\\right.\\) ,设 $\\delta=\\left(x_1, x_2, \\ldots, x_n\\right)^T$, 即坐标变换公式: $\\delta=A \\delta^{\\prime}$, 那么有 $\\delta^{\\prime}=\\left(\\frac{\\left|B_1\\right|}{|A|}, \\frac{\\left|B_2\\right|}{|A|}, \\ldots, \\frac{\\left|B_n\\right|}{|A|}\\right)^T$   表层意义   也就是说, 克拉默法则的几何理解就是它给出了非退化仿射变换变换后的新坐标公式。有了这个工具, 在做非退化仿射变换的时候就能更方便地求新坐标了。   本质意义   进一步地, 当 $A$ 是一个正交矩阵, 即做的是正交变换（以同向为例），那么有  \\(\\delta^{\\prime}=A^{\\prime} \\delta=\\left(\\left|B_1\\right|,\\left|B_2\\right|, \\ldots,\\left|B_n\\right|\\right)^T\\)   于是有 \\(\\alpha_i \\cdot \\delta=\\left|B_i\\right|(i=1,2, \\ldots, n)\\)   考虑原标架是右手直角标架, 此时等号右边表示 $\\delta$ 在第 $\\mathrm{i}$个纬度上的分量为“高”, 其他单位坐 标向量为“底”的几何体的“体积”。而“底”的面积为1, 所以这个“体积”就等于“高”。易知等号左边则表示 $\\delta$ 在第 $\\mathrm{i}$ 个纬度上的分量。   考虑原标架是任意标架，而且$ A$ 是任意可逆矩阵，那么可以类比地理解：一个向量在用一组新向量线性表出时在每个新向量的维度上的分量是以它为“高”、别的新坐标向量为“底”的几何体的体积比上新向量组构成的几何体的体积。   关于证明           行列式的定义和应用：行列式是一个从数域的$n^2$维向量空间映射到数域自身的函数。在一个数域$F$上，我们可以定义一个行列式$\\Delta$如下：   \\[\\Delta : F^{n^2} \\rightarrow F\\]      这个函数在$n$维线性空间$F^n$上是有效的。            正交单位化：在一个数域$F$上，我们可以对$n$维线性空间$F^n$的任何基进行正交单位化。这可以把基转换为一个右手直角坐标系。            克拉默法则的本质和应用：克拉默法则是一个几何直观的抽象，它在度量线性空间中有效。度量线性空间能表示诸如”面积”、”体积”这样的几何概念，而非度量空间不一定可以。            线性方程组与线性空间的关系：线性方程组背后隐含了线性空间的结构，而二维和三维的几何可以帮助我们直观地理解数量关系（高维几何则需要依赖代数来理解）。       结   “克拉默法则的本质是将几何直观抽象到度量线性空间。”   reference   https://ccjou.wordpress.com/2009/11/10/%E5%85%8B%E6%8B%89%E7%91%AA%E5%85%AC%E5%BC%8F%E7%9A%84%E8%AD%89%E6%98%8E/   https://zhuanlan.zhihu.com/p/57944485   https://zhuanlan.zhihu.com/p/262988664   https://planetmath.org/proofofcramersrule  ","categories": [],
        "tags": [],
        "url": "/proof-of-Cramer-s-rule/",
        "teaser": null
      },{
        "title": "MIT missing Cour",
        "excerpt":"进度条…(2/8)   Lecture 1 Shell           bash中如果想提供一个包含空格的参数，可以用‘或”“把它们引起来，或者用转义字符\\，比如My\\ Photos来将空格转义            $PATH是环境变量，即在本地文件夹下没有找到对应可以执行的程序时会自动在环境变量的路径中寻找相应的程序。which提示了能够运行本指令的程序路径，比如       ~$ which echo /bin/echo             ls -l表示以详细方式列出当前文件夹下的文件       missing:~$ ls -l /home drwxr-xr-x 1 missing  users  4096 Jun 15  2019 missing        第1个字符表明这个文件的类型。d表示这是一个文件夹，如果是-表示这是一个普通文件，l表示这是一个链接文件，类似于windows下的快捷方式，b表示这是一个块设备文件，一般置于/dev目录下，没有文件大小，只有一个主设备号和辅设备号。块设备是一次传输一整块数据的设备，比如硬盘。c表示这是一个字符设备文件，一般置于/dev目录下，字符设备是一次只传输一个字符数据的设备，比如键盘。p表示这是一个命令管道文件，与shell编程有关，s表示这是一个socks文件，与shell编程有关       d后面有3*3个标志，表示不同的身份对该文件的权限。r表示可读权限，w表示可写权限，x表示可执行权限，-表示无相应权限。第一组表示该文件的所有者的权限，第二组表示文件所有者同组用户的权限，第三组表示其他用户的权限       权限后面的第一个数字表示1. 当这是一个文件时，为硬连接数，即有几个文件硬链接到了这个文件 2. 当这是一个文件夹时，为链接占用的节点，即该目录中包含的子目录的个数       对于一个文件夹来说，为了进入这个文件夹，必须拥有”search”权限，也就是拥有对这个文件夹以及其所有父路径文件夹的x权限。为了ls这个文件夹，必须拥有这个文件夹的r权限            重定向输入输出流：&lt; file将输入设定为文件，&gt; file将结果输出到文件，原先文件的内容会被覆盖       missing:~$ echo hello &gt; hello.txt missing:~$ cat hello.txt hello missing:~$ cat &lt; hello.txt hello missing:~$ cat &lt; hello.txt &gt; hello2.txt missing:~$ cat hello2.txt hello        &gt;&gt;可以来向文件附加数据。|是管道符号，可以将前一个命令的输出作为下一个命令的输入。       curl --head --silent google.com | grep --ignore-case content-length | cut --delimiter=' ' -f2 # 查看向google发送HTTP GET请求的头文件中的content length属性的值        文件描述符：一般情况下每个unix命令运行时都会打开3个文件：              标准输入文件(stdin)：文件描述符为0，unix默认从stdin输入数据       标准输出文件(stdout)：文件描述符为1，unix默认向stdout输出数据       标准错误文件(stderr)：文件描述符为2，unix会向stderr流中写入错误消息           默认情况下，command&gt;file将stdout重定向到file，command&lt;file将stdin重定向到file       command 2&gt;&gt;file # 将stderr追加到文件末尾//        /dev/null文件是一种特殊的文件，写入到它的内容都会被丢弃，也无法从中读取到任何内容，如果希望执行某个命令，但是不希望在屏幕上显示输出结果，可以将输出重定向到/dev/null       command &gt;&gt; /dev/null 2&gt;&amp;1 # 屏蔽stdout和stderr        command &gt;&gt; /dev/null已经将标准输出重定向，2&gt;&amp;1中的&amp;表示等同，2&gt;表示错误输出，2&gt;&amp;1表示错误输出重定向的对象等同于标准输出重定向的对象，即/dev/null            sysfs：Linux内核下基于内存的文件系统，可以将很多内核参数以文件形式暴露，从而可以方便地修改kernel。比如笔记本电脑的屏幕亮度可以以文件的形式在sys/class/backlight下被暴露       $ sudo find -L /sys/class/backlight -maxdepth 2 -name '*brightness*' /sys/class/backlight/thinkpad_screen/brightness $ cd /sys/class/backlight/thinkpad_screen $ sudo echo 3 &gt; brightness  # permission denied，因为&gt;重定向符号之前的sudo并不能被后面观察到，也就是说写入brightness这个操作实际上并没有执行sudo $ echo 3 | sudo tee brightness  # success，tee这个命令是获取标准输入，将内容输出成文件，并将其打印到屏幕上             chmod(change mode)来控制用户对文件的权限的命令。只有文件拥有者(owner)和超级用户(super user)可以修改文件或者目录的权限       chmod [-cfvR] [--help] [--version] mode file... # mode格式为 [ugoa...][[+-=][rwxX]...][,...] # u表示该文件的拥有者，g表示与该文件的拥有者属于同一个group者，o表示其他人，a表示这三者皆是 # +表示增加权限，-表示取消权限，=表示唯一设定权限 # r表示可读取，w表示可写入，x表示可执行，X表示只有当该文件是个子目录或者该文件已经被设定过为可执行 # 示例:将file1.txt设定为所有人皆可读取 chmod ugo+r file1.txt        也可以采用八进制的方法来规定权限                                  #           权限           rwx           二进制                                           7           读+写+可执行           rwx           111                             6           读+写           rw-           110                             5           读+执行           r-x           101                             4           只读           r–           100                             3           写+执行           -wx           011                             2           只写           -w-           010                             1           只执行           –x           001                             0           无           —           000                           # file1.txt这个文件对所有的用户均可读可写可执行 chmod 777 file1.txt # file2.txt这个文件对其他用户只可执行 chmod ug=rwx,o=x file2.txt # 与以下相同 chmod 771 fil2.txt        一般比较常用的是chmod 755和chmod 777            shebang: #!       写在脚本的第一行，用来规定该脚本的解释器。#!后接解释器的绝对路径。比如想要规定这个脚本用sh来执行，那么在第一行添加       #!/bin/sh        推荐使用/usr/bin/env python来规定该脚本解释器，这是因为env会在$PATH中查找python解释器的安装位置，这样可以不用提供一个解释器的绝对路径，从而提高程序的可移植性            后台执行shell       在shell命令的最后一个位置加&amp;       Lecture 2 Shell Tools and Scripting   Shell Scripting   Shell是一个用C语言编写的程序，是一种解释性语言。Windows Explorer是一个典型的图形界面shell   Bourne Shell /bin/sh或/usr/bin/sh   Bourne Again Shell /bin/bash           给变量赋值：       注意在定义变量时变量名不加美元符号，变量名和等号之间不能有空格。在使用一个已经定义过的变量时需要加美元符号       foo=bar # 注意不能是foo = bar，否则bash会认为这是运行了foo命令，并以=和bar作为参数传入 echo \"$foo\" # prints bar echo '$foo' # or echo \"${foo}\" # 花括号加不加可选，主要是为了清晰变量名的边界 # prints $foo # 注意在bash中\"和‘是不同的。在'中$变量不会被替换，\"中$后面的变量会被替换为其值        readonly变量是只读变量，不能被赋值       myurl=\"www.fanxiao.tech\" readonly myurl        使用unset命令可以删除变量            获取字符串的长度       string=\"abcd\" echo ${#string} # 输出4             提取子字符串       从字符串的第2个字符开始截取四个字符       string=\"runoob is a great site\" echo ${string:1:4} # 输出unoo             函数       # 以shell脚本的名称创建一个文件夹并cd到这个文件夹中 mcd(){ mkdir -p \"$1\" cd \"$1\" }               $0：脚本本身的名称       $1-$9：脚本的第1-第9个参数       $@：所有脚本的参数       $#：脚本参数的个数       $?：前一个命令的返回代码       $$：当前脚本的PID       !!：完整的上一个命令，包括参数。如果一个命令只是因为没有root权限失败，则可以执行sudo !!来重新执行该命令       $_：上一个命令的最后一个参数                数组       数组索引从0开始。用括号()来表示数组，数组元素用空格分开。定义数组的一般形式为       数组名=(值1 值2 值3 值4)       如       array_name=(value0 value1 value2)        还可以单独定义数组的各个分量，如array_name[0]=1       读取数组元素值的方式是$(数组名[下标])，使用@则可以获取数组中的所有元素，例如       echo ${array_name[@]}        获取数组的长度的方法是       length=${array_name[@]}             bash基本运算       原生bash不支持简单的数学运算，但是可以通过其他命令实现，比如expr       val=expr 2 + 2   # 注意：表达式和运算符之间一定要有空格，例如2+2是不对的，必须写成2 + 2,注意不是单引号而是反引号 echo \"两数之和为$val\"  # 输出为\"两数之和为4\"        条件表达式要放在方括号之间，并且要有空格，例如       if [$a == $b] then echo \"a等于b\" fi if [$a != $b] then echo \"a不等于b\" fi        关系运算符：                                  运算符           说明                                           -eq           检测两个数是否相等，相等则返回true                             -ne           检测两个数是否不等，不等则返回true                             -gt           检测左边的是否大于右边的，大于则返回true                             -lt           检测左边的是否小于右边的，小于则返回true                             -ge           检测左边的是否大于等于右边的，大于等于则返回true                             -le           检测左边的是否小于等于右边的，小于等于则返回true                             !           非运算                             -o           或运算                             -a           与运算                           注意：乘号前必须要加上反斜杠\\转义才是乘法运算            test命令可以用于检查某个条件是否成立       # 数值测试 num1=100 num2=200 if test $[num1] -eq $[num2] then echo '两个数相等' else echo '两个数不相等' fi # 文件测试 cd /bin if test -e ./bash then  echo '文件存在' else echo '文件不存在' fi        注意：新的test[[]]比旧的test[]更好，尽量使用[[]]            流程控制：shell编程的流程控制不可为空，即if和else的代码块里必须执行一定的动作       将if和else写成一行的方法：       if [ $(ps -ef | grep -c \"ssh\") -gt 1]; then echo \"true\"; fi # 查找当前所有进程中ssh进程的个数，如果大于1则返回true        for循环的一般格式       for var in item1 item2 ... itemN do command1 command2 commandN done        写成一行：       for var in item1 item2 itemN; do command1; command2; commandN; done;        while循环：       int=1 while [ $int -lt 5 ] do echo $int let \"int++\"  # let是bash中用于计算的工具，变量计算中不需要加上$表示变量 done # 运行结果 # 1 # 2 # 3 # 4 # 5        case选择       每个case分支从右圆括号开始，用两个分号;;表示break，跳出整个case...esac语句       echo '输入1到4之间的数字' echo '你输入的数字为' read aNum case $aNum in 1) echo '你选择了1' ;; 2) echo '你选择了2' ;; 3) echo '你选择了3' ;; 4) echo '你选择了4' ;; *) echo '你没有输入1到4之间的任何数字' ;; esac        break命令       while true do echo -n \"输入1到5之间的数字\" read aNum case $aNum in \t1|2|3|4|5) echo \"你输入的数字为$aNum!\" \t;; \t*) echo \"你输入的数字不是1到5之间的！结束\" \t\tbreak        ;;    esac done             shell函数       [function] funname [()] { action [return int] } # example demoFun(){ echo \"第一个shell函数\" } demoFun # 调用这个函数             程序的返回值：执行成功返回0，执行失败则返回其他大小的数值。注意，和C语言不同，shell中0表示true，1表示false       获取一个程序的变量值，如$(CMD)会先执行CMD，获取CMD的输出并再相应位置进行替换。比如执行for file in $(ls)，将先执行ls，然后遍历执行ls后获得的返回值            进程替换(process substitution)：&lt;(CMD)将执行CMD，然后将结果输出到一个临时文件，并把&lt;()替换为这个文件名。比如cat &lt;(ls -l)相当于ls -l | cat，diff &lt;(CMD1) &lt;(CMD2)是比较这两个CMD的区别            shell文件包含       包含外部脚本，以封装一些公用的代码作为一个独立文件       . file # 注意.和文件名中间有一个空格 # 或者 source file             shell通配符(globbing)       wildcard: 使用*或?来进行匹配，比如有foo1、foo2、foo几个文件，rm foo?将删除foo1和foo2，而rm foo*将删除foo1、foo2和foo等三个文件            花括号{用来扩展子字符串       convert image.{png,jpg} # will expand to convert image.png image.jpg      ","categories": [],
        "tags": [],
        "url": "/Lec1-and-lec2-content/",
        "teaser": null
      },{
        "title": "Injective, Surjective and bi-jective",
        "excerpt":"A small concept in discrete mathematics   函数的类别 Injective, Surjective and bi-jective   Functions, Domain, Codomain,Range   Function（函数）   函数是一种关系，在给定定义域的情况下，将定义域中的每个元素映射到唯一的值域中的元素。函数通常用 f(x) 或 g(y) 等符号表示，其中 x 和 y 是定义域和值域中的元素。函数描述了输入和输出之间的映射关系。   Domain（定义域）   The set of input values   定义域是函数的所有可能输入值的集合。它是函数可以接受的输入范围。例如，对于函数 f(x) = x^2，定义域可以是实数集合 R，因为任何实数都可以作为该函数的输入。   Codomain（值域）   The set of possible output values 那我感觉codomian就一直是$\\R$ 我有点不太理解这个codmain这个set是如何产生的，一个   值域是函数中所有可能的输出值的集合。它是函数可以产生的所有可能结果的范围。与定义域不同，值域不一定是函数实际映射到的值的集合，而是函数可能生成的所有结果的集合。例如，对于函数 f(x) = x^2，值域可以是非负实数集合 R≥0，因为平方函数的结果始终为非负实数。   Range（值域*）   The set of actual output values   Range是函数实际映射到的值的集合。它是函数在给定定义域上生成的所有实际输出值的集合。通常，值域是通过确定函数的所有可能输出值并排除任何不可达的值来确定的。例如，对于函数 f(x) = x^2，如果定义域为实数集合 R，那么值域将是非负实数集合 R≥0，因为平方函数的结果始终为非负实数。   Injective, Surjective and bi-jective定义和简明解释   Definition   来源： https://www.math.fsu.edu/~pkirby/mad2104/SlideShow/s4_2.pdf   Given $f: A \\rightarrow B$           $f$ is one-to-one (short hand is $1-1$ ) or injective if preimages(预先映射) are unique. In this case, $(a \\neq b) \\rightarrow(f(a) \\neq f(b))$. 一个a只匹配一个在set B中的b            $f$ is onto or surjective if every $y \\in B$ has a preimage. In this case, the range of $f$ is equal to the codomain.我感觉codomian和range的关系没搞明白            $f$ is bijective if it is surjective and injective (one-to-one and onto).       来源：YouTube视频      one to one / injective            For  every input there is unique output. All the elements in the domain  have to be used, but all elements in the co-domain need not be used.就是在input的元素中，映射出去，co-domain中要留有剩余。                  onto / Surjective            (Range  = co-domain)  Every element in the co-domain is the image of at least one element in  the domain.       或者说range要=co-domain           bijective            These functions are one-one functions but every element in the co-domain  is used.           我的理解   对于函数，我们考虑到A这个set和B这个set中存在的一些元素，这是背景信息要求。那么，当A的元素出发对应到了B中的元素，这就是满足函数的关系。在这个基础上有两个方向。第一个方向是one to one，这个对满足function的关系的要求基础之上，额外要求对于set A中的元素应该全部射出，set B可以留有空白的元素。 而另外一个方向，则是指明了在set B中，B中的元素全部至少被A中的一个元素被射中，甚至可以被A中的多个元素射中。而bijective 就是这两个路径的叠加，就是set A中的元素被全部射出，而set B中的元素全部被set A中的元素对应   上面的理解感觉是错的 ，红色部分one to one的理解错了   新的理解   https://www.youtube.com/watch?v=MY4-5mXfWzo&amp;ab_channel=Areallnamesgone   视频中显示，函数的定义是set A中的元素都是单个箭头出发，而不是从a1出发有两个箭头，满足了这个关系就是函数，我觉得这个好理解，因为满足了线性关系后，set A中的元素对应了两个set B中的元素(比如f(1)=2但是f(1)又可以=34)，这非常奇怪了，线性关系就被破坏了。继续到one to one，可以进行字面意思的理解，one to one就是在set A到 set B的映射关系中，一个在set A(domain)中的元素只可以唯一对应set B中的元素，比如(set A{a_1,a_2,a_3,a_4}和set B{b_1,b_2,b_3,b_4,b_5}这里的元素，假设他们下标匹配对应，a_1配备b_1…最后留下b_5是空的，没有被A中的元素中对应的，这样也是可以的。因为这个case满足了我们对于set A中的元素都要可以对应set B中的这种情况)。继续onto，这个要求是set B中的元素at least 都要被A中出发的元素射中，就是说set B没有空的元素，但是一个在set B中的元素可以被很多从set A的元素出发的箭头(关系)对应。最后bijective，满足了set A中的单一输出箭头(函数，映射关系)都有一个在set B中对应的元素(one to one)，同时set B中的元素都接受到set A的元素中出发的箭头(onto),这两个路径的分别满足，让set A和set B中的元素得到了全部的匹配和各自唯一的匹配。   Function关系的演变      https://www.youtube.com/watch?v=ojHAAqgW1_M&amp;ab_channel=TheMathSorcerer   ","categories": [],
        "tags": [],
        "url": "/Injective,-Surjective-and-Bi-jective/",
        "teaser": null
      },{
        "title": "Discrete Mathematics",
        "excerpt":"虎头蛇尾…   离散数学 CMU 2001 notes   Lec1   intro   …   Set           首先定义空集的概念  $\\empty$ Definition: the only set include no elements.            交并补的概念    补充       The Sum Principle补充   Proof of Ramsey’s Theorem   你想证明的这个等式可以通过组合数的性质和帕斯卡三角形来解释和证明。以下是证明的一种方式：   首先，我们知道组合数 $\\binom{n}{m}$ 表示从 $n$ 个元素中选择 $m$ 个元素的组合数。这可以表示为：   \\[\\binom{n}{m} = \\frac{n!}{m!(n-m)!}\\]  同样，$\\binom{n}{m+1}$ 表示从 $n$ 个元素中选择 $m+1$ 个元素的组合数：   \\[\\binom{n}{m+1} = \\frac{n!}{(m+1)!(n-m-1)!}\\]  然后，我们来看左边的等式：   \\[\\binom{n}{m} + \\binom{n}{m+1}\\]  将上述两个组合数的表达式代入，得到：   \\[\\frac{n!}{m!(n-m)!} + \\frac{n!}{(m+1)!(n-m-1)!}\\]  现在，我们的目标是将这个式子变形成 $\\binom{n+1}{m+1}$ 的形式。我们注意到，$\\binom{n+1}{m+1}$ 也是从 $n+1$ 个元素中选择 $m+1$ 个元素的组合数：   \\[\\binom{n+1}{m+1} = \\frac{(n+1)!}{(m+1)!(n-m)!}\\]  我们希望将左边的式子变形成 $\\binom{n+1}{m+1}$ 的形式。为此，我们可以考虑如何将两个分数相加，使得分母部分与 $\\binom{n+1}{m+1}$ 相同。我们观察到：   \\[\\frac{n!}{m!(n-m)!} + \\frac{n!}{(m+1)!(n-m-1)!} = \\frac{(n+1)!}{(m+1)!(n-m)!}\\]  上述等式成立是因为分子部分相等。这就完成了证明。   因此，我们证明了：   \\[\\binom{n}{m} + \\binom{n}{m+1} = \\binom{n+1}{m+1}\\]  这个等式在组合数学中被称为 Pascal’s Rule（帕斯卡规则），它在帕斯卡三角形中有重要的几何解释。   下面笔记使用北理莫斯科的lec notes   Fri. 18th   3.2 集合的概念   集合    定义 我们指元素的组合。   数学描述latex打不出空格{}  \\(A={a:a满足specific的性质}\\) 两个集合的差集    定义   3.2.2 关系   二元关系   什么是二元关系，没有被定义  我觉得是两个未知数的关系就是2元关系  问:满足函数关系的本事是不是要满足映射关系，映射关系set A 到set  B，从一个A的element出发，只对应一个set B中的b，但是没有说是满射(满射)的英文是什么onto？  onto 是set B 中的b elements at least 对应一个 set A中的a   8 20th 计数   例 3.16. 定义 $[n]^{(r)}={T \\subseteq{1,2, \\ldots, n}:|T|=r}$. 设 $\\mathcal{A} \\subseteq[n]^{(r)}$. 设 $s&gt;r$ 。定义 \\(\\mathcal{B}=\\left\\{B \\in[n]^{(s)}: \\exists A \\in \\mathcal{A}, \\text { s.t. } A \\subseteq B\\right\\} .\\) $|\\mathcal{B}|$ 有多大呢（当然 $|\\mathcal{B}|$ 依赖于 $|\\mathcal{A}|)$ ? 解答. 上界：根据定义 $\\mathcal{B} \\subseteq[n]^{(s)}$ ，所以 $|\\mathcal{B}| \\leq\\left|[n]^{(s)}\\right|=\\left(\\begin{array}{l}n \\ s\\end{array}\\right)$. 下界：考虑如下集合 \\(M=\\{(A, B) \\in \\mathcal{A} \\times \\mathcal{B}: A \\subseteq B\\} .\\) 分别采用 $\\mathcal{A}$ 和 $\\mathcal{B}$ 的观点来计算 $|M|$ 。                                     从 $\\mathcal{A}$ 的观点：对每个 $A \\in \\mathcal{A}, A$ 包含在 $\\left(\\begin{array}{l}n-r \\ s-r\\end{array}\\right)$ 个不同的 $B$ 中。因此, $           M           =           \\mathcal{A}           \\left(\\begin{array}{l}n-r \\ s-r\\end{array}\\right)$.                                                           从 $\\mathcal{B}$ 的观点：对每个 $B \\in \\mathcal{B}, B$ 最多包含 $\\left(\\begin{array}{l}s \\ r\\end{array}\\right)$ 个不同的 $A$ 。因此, $           M           \\leq           \\mathcal{B}           \\left(\\begin{array}{l}s \\ r\\end{array}\\right)$.                           解释   $[n]^{(r)}=\\{T \\subseteq\\{1,2, \\ldots, n\\}:|T|=r\\}$  对这个定义的明晰                  $[ ]$ and $()$ 都是对set的描述，其中集合中元素的个数的表示方法是$       A       $ ，比如$       \\mathcal{P}(A)       =2^{       A       }$           ${T \\subseteq{1,2, \\ldots, n}}$   则表示$T$ 被这个set包含，T中可能有1-n之间的元素，                  $       T       =r$           说明T的size就是r   $[n]^{(r)}$   说明有r组n这个set要配对，T中的元素分别输出到n值   $[n]^{(r)}$ 表示从集合 ${1, 2, \\ldots, n}$ 中选取$r$个元素的所有可能集合。而不是 “有r组n这个set要配对，T中的元素分别输出到n值”。   $[n]^{(r)}$ 表示的是从集合 ${1, 2, \\ldots, n}$ 中选取$r$个元素的所有可能集合，而不是将元素与n进行配对。   康尔托对角线证法   主要的构造方法是在[0,1]中，使用小数表示一个自然数，或者说使用一个双射来连接关系的情况下，特使得$x_{ij}(j=i)$ 的位置设置一个不同数，使用这个方式，当一个数字的每个数上的位置，不可以被对角线上对应位置的数字表示的时候，就说明他   图 Tue.   定义4.1   欧拉通路：经过图中的每一条边一次且仅一次。   欧拉回路：经过图中的每一条边一次且仅一次，且回到出发点。   定义4.2   设 v 是图中的某个顶点，与 v 连接的边的数目叫做 v 的度数，记作 d(v)。   ###命题 4.3   对任意的图 G，如果图 G 中存在一条欧拉通路，则最多只有两个点的度数是奇数。   命题 4.4   对任意的图 G，如果图 G 中存在一条欧拉回路，则每个点的度数都是偶数   命题4.4和4.3 只可以判断在本身存在时，这里的检测方法就是说，   定义 4.5   一个（无向，即边没有方向）图 $G$  由点和边组成，点的集合通常用$V$   表示，边的集合用 $E$  表示。图 $G$ 一般写作 \\(G = (V, E)\\) 点的相邻 两个点有边   边的相邻 两个边之间有点   点的度数 点发散或者接收的条数   简单图 两点之间最多一条边（不会不复杂，但是会没有来回   **通路** 从一点到另一点由边连接的序列（点和边均允许重复）  **路径** **点**不重复的通路  **回路** 起点和终点相同的通路 (到底是一个成环的路还是？首尾链接的路可以)   连通图 任意两点之间均有通路连接   子图 由图的某些点和这些点上某些边组成的图   导出子图：由图的某些点和这些点上所有的边组成的图/感觉没什么用，就是选了一些线和点呗   连通分支：   定理4.7   对任意的连通图 G，      图 G 中存在一条欧拉通路，当且仅当要么每个点的度数都是偶数，要么恰有两点的度数是奇数。   图 G 中存在一条欧拉回路，当且仅当每个点的度数都是偶数。   充分必要？   定理4.8 &amp;4.9握手定理和其的推论   有点问题   使用对称理论证明   树与环 Aug. 25th   定义   Aug. 26th 图的同构   定义   对有些问题而言，我们只关心边的相互关系，并不对顶点做过多区分，数学上我们考虑一个新的概念，叫做同构。   满足双射，在两个图$G=(V,E)$ 和$H=(V’,E’)$中，   三个算法   1. 贪心算法 最小生成树 Kruskal 算法   具向的理解是首先把最短到最长的权重的line升序排列取出，再使用这些line上的权重值进行连接，在连接时观察是否连结成环，如果成环，则取消   2. 信息熵算法   3. Dijkstra 算法   ","categories": [],
        "tags": [],
        "url": "/CMU-Discrete-mathematics-2001-notes/",
        "teaser": null
      },{
        "title": "learning how to learn powerful mental tools to help you master tough subjects",
        "excerpt":"UCLA online  learning how to learn powerful mental tools to help you master tough subjects   Focued mode   Diffuse mode   Focued mode   什么是focusing.使用比喻来解释，a pinball game works by, you pull back on the plunger, release it, and a ball goes boinking out, bouncing around on the rubber bumpers, and that’s how you get points.   So, here’s your brain, with the ears right here, and the eyes looking upwards. And we can lay that pinball machine right down inside it. So, there you go. There’s the analogy for the focused mode.   So look at how that thought moves smoothly around on the fuzzy underlying orange neural pathway. In some sense it’s as if it’s traveling along a familiar, nicely paved road. But what if the problem you’re working on needs new ideas or approaches?   Diffuse mode   To get to this new thought pattern, you need a different way of thinking. And that’s represented here, by the diffuse mode. Look at how widely spaced the rubber bumpers are. Thought takes off, look at how it moves widely, bounces around. It could travel a long way before being interrupted by hitting a bumper. In this diffuse mode of thinking, you can look at things broadly from a very different, big-picture perspective. You can make new neural connections traveling along new pathways. You can’t focus in as tightly as you often need to, to finalize any kind of problem solving. Or understand the finest aspects of a concept. But you can at least get to the initial place you need to be in to home in on a solution.   This course is meant to help you reframe how you think about learning, to help reduce your frustration.   Video 2   To gain muscular structure, you need to do a little work every day, gradually allowing your muscles to grow. Similarly, to build neural structure, you need to do a little work every day, gradually allowing yourself to grow a neuro-scaffold to hang your thinking on a little bit, every day, and that’s the trick.   We learned about how the brain’s two different thinking modes focused and diffuse, each helps us learn but in very different ways. Finally, we learned that learning something difficult can take time. Your brain needs to alternate it’s ways of learning as it grapples with and assimilates the new material. Thanks for learning about learning. I’m Barbara Oakley.   video 3 what is learn   brain   video 4 Procrastnation   Pomodoro   25min sepqtetary working time to focusing on some thing   v 5 Procrastnation and learning step      数学和科学的抽象性：文章指出数学和科学的抽象性是这些学科有时更具挑战性的原因之一。相比之下，我们可以通过实际事物来理解和感知其他抽象概念，而数学和科学的概念往往没有直接的对应物。   实践对学习的重要性：文章强调了在学习数学和科学时实践的重要性。通过实践，可以加强神经连接，使抽象的概念更加具体和实际。文章还提到了大脑通过实践形成的神经模式的比喻。   学习方法：文章介绍了一种学习方法，即集中学习一段时间后休息或转换注意力，以便大脑在后台进行深度思考和巩固概念的理解。文章还提到了使用番茄工作法（Pomodoro Technique）来克服拖延症，并建议进行有针对性的短期集中学习。   Chunking（分块）：文章提到下一步将讨论”chunking”，即如何掌握和理解关键概念的重要要素。然而，这一点在给出的文本中并没有具体展开。   v6 记忆概论      Memory Systems: The two major memory systems are working memory and long-term memory.   Working Memory: It is the part of memory involved in immediate and conscious processing of information. It is centered in the prefrontal cortex and has limited capacity (about four chunks of information).   Blackboard Analogy: Working memory is compared to an inefficient mental blackboard that requires repetition to retain information.   Metabolic Vampires: Refers to natural dissipating processes that can cause memories to fade if not repeated or reinforced.   Long-Term Memory: It is like a storage warehouse distributed across different regions of the brain. Different types of long-term memories are stored in specific areas.   Revisiting Information: To effectively store information in long-term memory, it is necessary to revisit it multiple times to increase the chances of recall later.   Immense Capacity: Long-term memory has the capacity to store billions of items, but information can become buried and difficult to retrieve without proper practice.   Importance of Long-Term Memory: Long-term memory stores fundamental concepts and techniques relevant to learning and understanding new information.   Working Memory’s Role: Working memory is used to process and handle new information but transferring it to long-term memory requires time and practice.   Spaced Repetition: A technique that involves repeating information over time with spaced intervals. It enhances the transfer of information from working memory to long-term memory.   Effectiveness of Spaced Repetition: Research shows that spaced repetition over multiple days is more effective for memory retention compared to mass repetition in a short period.   Analogy of Building a Wall: Just as a brick wall needs time for the mortar to dry and strengthen the structure, synaptic connections in the brain require time to form and strengthen for better memory retention.   Reference to the Acropolis: The Acropolis is mentioned as an example of a lasting structure, metaphorically indicating the importance of establishing strong and enduring memories.   v7 睡眠      Awake state and brain toxins毒素: Being awake generates toxic products in the brain.   Brain cleansing during sleep: When you sleep, brain cells shrink, increasing the space between them. This allows fluid to flow and wash away toxins.   Importance of sleep: Sleep helps keep the brain clean and healthy, contrary to it seeming like a waste of time.   Effect of sleep deprivation: Insufficient sleep can result in a buildup of metabolic toxins, impairing clear thinking. It can also be associated with various negative conditions and health risks.   Sleep and memory consolidation: Sleep plays a crucial role in the memory and learning process. It helps organize and strengthen important memories while erasing less important ones.   Neural rehearsal during sleep: The brain rehearses challenging aspects of learning during sleep, reinforcing neural patterns.   Sleep enhances problem-solving: Sleep improves problem-solving abilities and understanding of learned material. Deactivation of the conscious mind in the prefrontal cortex facilitates communication between brain areas.   Dreaming and learning: Going over learned material before sleep increases the chances of dreaming about it. Dreaming about the material can enhance understanding and consolidate memories.   Focused mode and diffuse mode: Engaging in focused mode work before sleep helps activate the diffuse mode, aiding in learning and problem-solving.   Week 2 内容 9th Sept.   lec1&amp;lec2&amp;lec3   What is a chunk?   Chunking is the mental leap that helps you unite bits of information together through meaning.  The new logical whole makes the chunk easier to remember, and also makes it easier to fit the chunk into the larger picture of what you’re learning.   这种概念的运作方式类似于将计算机文件压缩成ZIP文件，将许多信息整合成一个更容易处理和记忆的单元。   chunking是一种认知策略，有助于将信息整合成更大的概念块，使学习和记忆更加高效。   在学习新的信息或技能时，形成一个”chunk”（块）的过程可以被看作是将信息逐渐整合在一起的过程，以便更有效地理解和应用。   数学和科学学习：当你学习新的数学和科学材料时，通常会提供带有详细解答的示例问题。这是因为在你尝试理解如何解决问题时，你的认知负担很重。因此，从一个解决方案的示例开始有助于你理解问题的关键特征和基本原理。但要注意，不要只关注为什么执行一个步骤，而忽略了各个步骤之间的联系，即为什么下一个步骤是你应该执行的下一步。这就像使用地图来帮助你前往新地方旅行一样，要注意使用地图时周围发生的事情，很快你就能自己到达目的地，甚至能够找到新的到达目的地的方式。   注：主要是联系   如何制作一个”chunk”（块）   “chunking”的基本原理可以应用于各种领域，无论是学习智力思维还是身体运动。   第一步：集中精力关注你想要制作”chunk”的信息。这意味着在学习过程中要避免分散注意力，不要同时看电视、查看手机或电脑消息等，因为这会妨碍大脑专注于”chunking”新材料。当你开始学习新知识时，你正在建立新的神经模式，并将它们与大脑各个区域的”preexisting patterns”连接起来。如果你的思维被其他想法占据，会影响到你的学习过程。   I’m going to lean a little more towards explaining chunking of mental ideas rather than physical body motions, but you’ll see that the two approaches are closely related.   The first step on chunking is simply to focus your undivided attention on the information you want to chunk.   When you first begin to learn something, you’re making new neural patterns and connecting them with preexisting patterns that are spread through many areas of the brain. Your octopus tentacles 章鱼触须, so to speak, can’t reach very well if some of them are off on other thoughts using up some of the limited slots in your working memory.   The second step in chunking is to understand the basic idea you’re trying to chunk, whether its understanding a concepts such as continental drift, seeing the connection between the basic elements of a plot for a story, grasping the economic principle of supply and demand, or comprehending the essence of a particular type of math problem. Students can often synthesize the gist主旨, that is figure out the main idea or ideas pretty naturally, or at least they can grasp those ideas if they allow the focused and diffused modes of thinking to take turns in helping them figure out what’s going on. Understanding is like a super glue that helps hold the underlying memory traces together. It creates broad encompassing traces that can link to other memory traces. Can you create a chunk if you don’t understand? Yes, but it’s often a useless chunk that won’t fit in with or relate to other material you’re learning. That said, it’s important to realize that just understanding how a problem was solved for example, does not necessarily create a chunk that you can easily call to mind later.   of a breakthrough and understanding with solid expertise. That’s part of what you can grasp an idea when a teacher presented in class, but if you don’t review it fairly soon after you first learned it, it can seem incomprehensible when it comes time to prepare for a test. In math and science related subjects, closing the book and testing yourself on whether you yourself can solve the problem you think you understand will speed up your learning at this stage.   You often realize the first time you actually understand something is when you can actually do it yourself. It’s the same in many disciplines. Just looking at someone else’s painting doesn’t mean you could actually create that painting yourself, and just hearing a song won’t give you the expertise you need to sing it in the same resonant fashion. Just because you see it or even that you understand it, it doesn’t mean that you can actually do it. Only doing it yourself helps create the neural patterns that underlie true mastery.   第三步：获得上下文，以便不仅知道如何使用这个”chunk”，还知道何时使用它。上下文意味着要超越初始问题，更广泛地看待问题，并进行重复和实践，不仅与相关问题一起，还与无关问题一起，以便不仅知道如何使用”chunk”，还知道何时不使用它。这有助于你看到你新创建的”chunk”如何适应更大的图景。上下文是底层和顶层学习相遇的地方。它意味着你不仅要学会使用某种问题解决技巧（底层学习），还要学会何时使用该技巧而不是其他技巧（顶层学习）。   The third step to chunking is gaining context, so you can see not just how but also when to use this chunk. Context means going beyond the initial problem and seeing more broadly, repeating and practicing with both related and unrelated problems, so that you can see not only when to use the chunk but when not to use it. This helps you see how your newly formed chunk fits into the bigger picture. In other words, you may have a tool in your strategy or problem solving tool box but if you don’t know when to use that tool it’s not going to do you a lot of good. Ultimately, practice helps you broaden the networks of neurons that are connected to your chunk, ensuring it’s not only firm but also accessible from many different paths. As you can see from this top-down, bottom-up illustration, learning takes place in two ways. There’s a bottom-up chunking process where practice and repetition can help you both build and strengthen each chunk, so you can easily access it whenever you need to. There’s also a top-down big picture process that allows you to see what you’re learning and where it fits in. Both processes are vital in gaining mastery over the material. Context is where bottom-up and top-down learning meet. To clarify here, chunking may involve your learning how to use a certain problem solving technique. Context means learning when to use that technique instead of some other technique. Doing a rapid two-minute picture walk through a chapter in a book before you begin studying it, glancing at pictures and section headings can allow you to gain a sense of the big picture, so can listening to a very well-organized lecture. These kinds of activities can help you know where to put the chunks you’re constructing, how the chunks relate to one another; just as you see here with the image of the man in the car. Learn the major concepts or points first, these are often the key parts of a good instructor or on book chapters, outline, flow charts, tables, or concept maps. Once you have this done, fill in the details. Even if a few of the puzzle pieces are missing at the end of your studies, you can still see the big picture. So, there you go.   Summing it up, chunks are best built with focused attention, understanding of the basic idea, and practice to help you gain mastery and a sense of the big picture context. Those are the essential steps in making a chunk and fitting that chunk into a greater conceptual overview of what you’re learning, but there’s more. Thanks for learning how to learn.   大纲，，理解basic info，理解和划重点学习但不是只划重点，填充内容，构建学习flow   能力错觉   The importance of recall, illusions of competence in learning.   very simple, technique. Recall. After you’ve read the material, simply look away, and see what you can recall from the material you’ve just read.   Including simply rereading the text a number of times. Or drawing concept maps that supposedly enrich the relationships in the materials under study.   When we retrieve knowledge, we’re not just being mindless robots. The retrieval process itself enhances deep learning, and helps us to begin forming chunks. It’s almost as if the recall process helps build in little neural hooks, that we can hang our thinking on.   开始分块   thought, concept mapping, drawing diagrams that show the relationship between the concepts would be the best.   Using recall, 在头脑中检索关键观点，而不是passive地重读   因为看书比回想更容易，所以学生们在学习的过程中坚持他们的 这样的学习方式效果并不好。这就提醒我们，只要想 并不能保证你能真正学会。有一个超级有用的方法，可以确保你在学习，而不是用能力的幻想来欺骗自己，那就是测试自己在学习什么。   回忆，而不是边看书边复习，但这里还有一个小窍门，在你不在通常的学习地点时回忆材料 也能帮助你加强对材料的掌握。你没有意识到，但当你学习新知识时，你常常会你在学习新知识时，往往会在潜意识中接受到当时学习材料时周围房间和空间的提示。   This can throw you off when you take tests because you often take tests in a room that’s different from the room you were learning in. By recalling and thinking about the material when you are in various physical environment, you become independent of thecues from any one given location. That helps you avoid the problem of the test room being different from where you originally learned the material.   week2 是什么激励了你？   Certainly, here is a summarized list of key points from the provided text:           Interest Facilitates Learning: Learning is easier when you are genuinely interested in the subject matter.            Neurons and Information Processing: The neurons in your cortex process information about your surroundings and actions.            Neuromodulators and Importance: Neuromodulators carry information about the importance and value of experiences rather than their content.            Three Important Neuromodulators: Acetylcholine, dopamine, and serotonin are discussed as important neuromodulators.            Acetylcholine and Learning: Acetylcholine is crucial for focused learning when paying close attention. It activates circuits related to long-term memory.            Dopamine and Motivation: Dopamine is a key chemical influencing motivation and reward learning. It plays a significant role in decision-making.            Dopamine and Addiction: Addictive drugs increase dopamine activity, leading to craving and dependence.            Loss of Dopamine Neurons: Loss of dopamine neurons can result in a lack of motivation, anhedonia, and even Parkinson’s disease.            Serotonin and Social Behavior: Serotonin affects social behavior, with higher levels seen in dominant individuals and lower levels in risk-takers and inmates with violent behavior.            Emotions and Learning: Emotions are intertwined with perception, attention, learning, and memory. The amygdala is a key brain structure for integrating emotions and cognition.            Website for More Information: Brainfacts.org is recommended as a resource for further information on acetylcholine, dopamine, and serotonin.            Conclusion: The message concludes by emphasizing the importance of keeping the amygdala “happy” for effective learning.       week 2 组块库的价值   文章主要讨论了“分块（chunking）”在学习和创新思维中的重要性。           分块的概念：分块是一种压缩信息的方法，使得我们能够更有效地存储和检索信息。            创新与分块：分块能够帮助人们以新颖和创造性的方式组合信息。例如，Bill Gates等行业领袖会专门安排长时间的阅读期，以便他们能一次性掌握多种多样的观点。            跨学科应用：分块不仅在特定领域有用，而且可以跨学科地应用。这种跨学科的应用被称为“转移（transfer）”。            专家与分块：例如，国际象棋大师能快速访问数千种不同的棋局模式；音乐家、语言学家和科学家也有自己的知识分块。            分块的训练：随着经验的增长，你所创建的分块会变得更大，更稳固。这些分块形成了你的“神经模式库”。            专注模式与发散模式：专注模式用于顺序、逐步的思考，而发散模式则更多地依赖于直觉和跨领域的联接。            不断练习的重要性：如果你不练习你所学的分块，它们可能会逐渐模糊，从而影响你对大局的理解。            直觉的局限性：虽然直觉非常有用，但它生成的解决方案需要通过专注模式来仔细验证。            学习的积累效应：一旦你掌握了第一个概念并将其加入你的“心智库”，那么第二个、第三个概念就会更容易地被加入。       这个文本主要是关于”chunking”（数据分块）以及”diffuse and focused modes of thinking”（散漫和集中的思考模式）在学习和问题解决中的作用。文本解释了如何通过分块技术将知识和概念组织成易于理解和应用的”块”，以提高问题解决和创新思考的能力。           数据分块（Chunking）: 数据分块是一种通过将复杂信息分解成易于理解和记忆的小块来增强记忆和学习的技术。这不仅有助于信息存储，还有助于在不同的情境和学科之间应用这些信息，这被称为“转移”（Transfer）。                       创新与分块: 分块能帮助人们在思维中持有多个和不同的概念，这有助于在创新思考中形成新的和原始的组合。                        跨领域应用（Transfer）: 一个分块的概念不仅在一个领域内有用，而且可以应用到其他完全不同的领域。                        散漫和集中思考模式:                       集中模式（Focused Mode）: 用于逐步、有逻辑地解决问题或学习新概念。                        散漫模式（Diffuse Mode）: 用于在看似不相关的分块概念之间建立联系，从而解决新颖的问题。                        整体直觉（Holistic Intuition）: 散漫模式通常用于形成直觉或洞见，这些直觉需要通过集中模式进行验证。                        实践与大局观:                      如果不经常使用和练习你的“分块”，它们可能会逐渐淡出记忆，导致难以组织和应用这些信息。                        贯穿全文的是一个积极的态度：坚持和努力会让学习变得更加容易。                   总体而言，分块和思考模式是高效学习和解决问题的两个关键组成部分。不仅如此，这两者相互作用，使个体能够更灵活、更具创造性地应对各种挑战。   The ability to combine chunks in new and original ways underlies a lot of historical innovation.   week-long reading periods so that they can hold many and varied ideas in mind during one time. This helps generate their own innovative thinking by allowing fresh in mind, **not yet forgotten ideas to network amongst themselves.** Basically, what people do to enhance their knowledge and gain expertise, is to gradually build the number of chunks in their mind, valuable bits of information they can piece together in new and creative ways.   The bigger and more well-practiced your chunked mental library, whatever the subject you're learning, the more easily you'll be able to solve problems and figure out solutions. As we'll discover soon, chunking isn't all you'll need to develop creative flexibility in your learning, but it's an important component.   Chunks can also help you understand new concepts. This is because when you grasp one chunk, you'll find that that chunk can be related in surprising ways to similar chunks, not only in that field but also in very different fields. This idea is called **transfer**. For example, concepts and problem solving method you learned for physics, can be very similar to chunked concepts in business. I found some aspects of language learning were very helpful for me when I later began to learn computer programming. A chunk is a way of compressing information much more compactly. As you gain more experience in chunking in any particular subject, you'll see that the chunks you're able to create are bigger, in some sense that the *ribbons* are longer. Not only are those ribbons longer, but the neural patterns are in some sense darker. They're more solid and firmly ingrained. If you have a library of concepts and solutions internalized as chunked patterns, you can think of it as a collection or a library of neural patterns.  Your diffuse mode can help you connect two or more chunks together in new ways to solve novel problems.   Another way to think of it is this, as you build each chunk it is filling in a part of your larger knowledge picture, but if you don't practice with your growing chunks, they can remain faint and it's harder to put together the big picture of what you're trying to learn.   In building a chunked library, you're training your brain to recognize not only a specific concept, but different types and classes of concepts so that you can automatically know how to solve quickly or handle whatever you encounter. You'll start to see patterns and simplify problem-solving for you and will soon find that different solution techniques are lurking 潜伏 at the edge of your memory. Before midterms or finals, it can be easy to brush up and have these solutions at the mental ready.   There are two ways to figure something out or to solve problems.   First, **through sequential step-by-step reasoning** and second, **through a more holistic intuition**整体直觉.   **Sequential thinking** where each small step leads deliberately故意的 towards a solution, involves the **f**ocused mode.   **Intuition** on the other hand, often seems to require this creative diffuse mode linking of several seemingly different focused mode thoughts.   **Mos**t difficult problems and concepts are **grasped through intuition,** because these new ideas make a leap away from what you're familiar with. Keep in mind that the diffuse modes, semi-random way of making connections means that the solutions it provides should be very carefully verified using the focused mode. Intuitive insights aren't always correct.    你可能认为题太多。没办法全学完， 这就是 law of Serendipity 将要应用的地方. Just focus on whatever section you're studying只要专注于你在学习的地方. You'll find that once you put that first problem or concept in your mental library, whatever it is, then the second concept will go in a little more easily and the third more easily still你会发现你一旦把一个概念放进思维库，无论什么概念，那么第二个相关的概念就会非常容易，第三个也是. Not that all of this is a snap, but it does get easier. 不是非常快的，但是这确实是变得容易。   Einstellung   When you’re learning a new idea, for example a new vocabulary word or a new concept or a new problem solving approach, you sometimes tend to practice it over and over again during the same study session.   当你在学的时候，你会在一个session中重复学习的倾向。   A little of this is useful and necessary, but continuing to study or practice after you’ve mastered what you can in the session is called overlearning. 但是这在大多数时候是没有用的。Overleaning can have its place.过剩也有它的道理。 It can produce an automaticity that can be important when you’re executing a serve in tennis or a perfect piano concerto.不知道 If you choke on tests or public speaking, overlearning can be especially valuable. 准备考试或者公共演讲有用。Did you know that even expert public speakers practice on the order of 70 hours for a typical 20-minute TED Talk? Automaticity can indeed be helpful in times of nervousness, but be wary of repetitive overlearning during a single session.要警惕重复练习。 Research has shown it can be a waste of valuable learning time.研究证明浪费时间。 The reality is, once you’ve got the basic idea down during a session, continuing to hammer away at it during the same session doesn’t strengthen the kinds of long term memory connections you want to have strengthened.一旦你有了basic的想法或者联系后，你应该远离它， Worse yet, focusing on one technique is a little like learning carpentry by only practicing with a hammer. 更糟糕的是，只专注于一种技巧 就像只用锤子练习木工一样。After awhile you think you can fix anything by just bashing at it.一段时间后，你会觉得 任何事情都可以靠敲打来解决。 Using a subsequent study session to repeat what you’re trying to learn is just fine and often valuable.少吃多餐学习 It can strengthen and deepen your chunked neuron patterns.可以帮助你 chunk “神经元模式”。   重复学习也是好的，下面。。It can also bring the illusion of competence that you’ve mastered the full range of material, when you’ve actually only mastered the easy stuff. 重复学习会带来以为自己掌握的错觉，但是实际上你只是掌握了简单的内容。Instead, you want to balance your studies by deliberately focusing on what you find more difficult. This focusing on the more difficult material is called deliberate practice. 相反，你要平衡你的 通过有意识地把重点放在你认为更难的地方来平衡你的学习。这种专注于较难的地方称为刻意练习。这往往是 好学生和优秀学生之间的区别。   All this is also related to a concept known as Einstellung.”Einstellung “的概念 In this phenomenon, your initial simple thought, an idea you already have in mind or a neural pattern you’ve already developed and strengthened, may prevent a better idea or solution from being found. 最开始的在心中的想法或者一个neural pattern已经被发展和强化，可能会诞生更加好的解决办法。 We saw this in the focus pinball picture, where your initial pinball of thought went to the upper part of the brain, but the solution thought pattern was in the lower part.弹球思维 是在大脑的上半部分，而解决问题的思维模式 模式却在下部。 The crowded bumpers of the focus mode and the previous patterns you built can create a sort of rut that prevents you from springing to a new place where the solution might be found. Incidentally, the German word einstellung means mindset. Basically you can remember einstellung as installing a roadblock because of the way you were initially looking at something. This kind of wrong approach is especially easy to do in sports and science, not to mention other disciplines, because sometimes your initial intuition about what’s happening or what you need to be doing is misleading. 聚焦模式的拥挤碰撞和你以前建立的模式 会让你产生一种束缚感，使你无法跳到一个新的地方去寻找解 可能找到解决方案的地方。顺便提一下，德语中的 einstellung 的意思是心态。基本上，你可以把 einstellung 就是安装路障，因为你最初看待事物的方式是 安装路障。这种错误的方法 尤其是在体育和科学领域，更不用说其他学科了、 因为有时你对正在发生的事情或你需要做的事情的最初直觉 因为有时你对正在发生的事情或你需要做的事情的最初直觉会产生误导。You have to unlearn your erroneous older ideas or approaches even while you’re learning new ones. One significant mistake students sometimes make in learning is jumping into the water before they learn to swim. In other words, they blindly start working on homework without reading the text book, attending lectures, viewing online lessons, or even speaking with someone knowledgeable. This is a recipe for sinking. It’s like randomly allowing a thought to, kind of pop off in the focus mode pinball machine, without paying any real attention to where the solution truly lies. Understanding how to obtain real solutions is important in learning and in life. Mastering a new subject means learning not only the basic chunks, but also learning how to select and use different chunks. 你必须在错误的旧观念或方法，甚至在学习新观念或方法的同时学习新的想法或方法。学生在学习过程中 学生在学习中有时会犯的一个重大错误就是 在学会游泳之前就跳进水里。换句话说，他们盲目地开始做作业 不读课本，不听讲座，不看在线课程，甚至不与有经验的人交谈，就盲目地开始做作业、 查看在线课程，甚至不与知识渊博的人交谈，就盲目地开始做作业。这是沉没的秘诀。这就好比随意让一个念头 弹球机中弹出来，而没有真正注意到解决方法的真正所在。 解决方案的真正所在。了解如何获得真正的解决方案 在学习和生活中都很重要。掌握一门新学科意味着 掌握一门新学科，不仅意味着要学习基本的知识块，还要学习如何选择和使用不同的知识块。 使用不同的语块。The best way to learn that is by practicing jumping back and forth between problems or situations that require different techniques or strategies. This is called interleaving. Once you have the basic idea of the technique down during your study session, sort of like learning to ride a bike with training wheels, start interleaving your practice with problems of different types or different types of approaches, concepts, procedures. Sometimes this can be a little tough to do. A given section in a book, for example, is often devoted to a specific technique, so when you flip to that section you already know which technique you’re going to be using. Still, do what you can to mix up your learning. In science and math in particular it can help to look ahead at the more varied problem sets that are sometimes found at the end of chapters. Or you can deliberately try to make yourself occasionally pick out why some problems call for one technique as opposed to another.最好的学习方法是 练习在需要不同技巧或策略的问题或情况之间来回跳跃。 不同的技巧或策略。这就是所谓的交错练习。一旦你在学习过程中掌握了 在学习过程中掌握了技巧的基本概念后，就像学习骑自行车一样，开始交错练习不同类型的问题或不同类型的方法、 概念、程序。有时做起来有点困难。例如，一本书中的某个章节通常会专门讨论 因此，当你翻到那一节时，你已经知道你要用到哪种技术了。 技巧。不过，还是要尽力让你的学习更加丰富多彩。特别是在科学和数学方面 在章节末尾会有更多不同的问题集。 在章节末尾。或者，你可以有意识地偶尔让自己找出为什么有些问题需要一种技巧而不是另一种技巧。 为什么需要一种技巧而不是另一种技巧。 You want your brain to become used to the idea that just knowing how to use a particular concept, approach, or problem-solving technique isn’t enough.你要让大脑习惯于 只知道如何使用特定的概念、方法或 解决问题的技巧是不够的。 You also need to know when to use it. 你还需要知道何时使用它。Interleaving your studies, making it a point to review for a test, for example, by skipping around through problems in the different chapters and materials can sometimes seem to make your learning a little more difficult, but in reality, it helps you learn more deeply.穿插学习、 例如，为了复习备考而跳过不同章节和材料中的问题，有时似乎会让你的学习变得枯燥乏味。 不同章节和材料中的问题，有时似乎会让你的学习 但实际上，它有助于你更深入地学习。 Interleaving is extraordinarily important.交错是非常重要的。 Although practice and repetition is important in helping build solid neural patterns to draw on, it’s interleaving that starts building flexibility and creativity.但交错学习才是建立灵活性和创造性的开始。 It’s where you leave the world of practice and repetition, and begin thinking more independently. 这让你离开练习和重复的世界，开始更加独立地思考。When you interleave within one subject or one discipline, you begin to develop your creative power within that discipline. When you interleave between several subjects or disciplines, you can more easily make interesting new connections between chunks in the different fields, which can enhance your creativity even further. Of course it takes time to develop solid chunks of knowledge in different fields, so sometimes there’s a trade off.权衡利弊   Developing expertise in several fields means you can bring very new ideas from one field to the other, but it can also mean that your expertise in one field or the other isn’t quite as deep as that of the person who specializes in only one discipline. 多领域发展内容可以使你在一些领域中带来新的想法创意，但是这也意味着你的经验不会比深耕于某一个领域的人的多   你要让大脑习惯于 只知道如何使用特定的概念、方法或 解决问题的技巧是不够的。你还需要知道何时使用。穿插学习、 例如，通过跳过不同章节和材料中的问题来为考试复习。 不同章节和教材中的问题，有时似乎会增加学习难度。 但实际上、 它能帮助你更深入地学习。穿插学习异常重要。尽管练习和重复对于建立稳固的神经模式有帮助，但交错学习才是建立灵活性和创造性的开始。这让你离开练习和重复的世界，开始更加独立地思考。当你在一门学科或你就开始在这门学科中发展自己的创造力。当你在多个学科或时，你就能更容易地在多个科目或学科之间建立有趣的新联系。 在不同领域的大块内容之间建立有趣的新联系，从而进一步提高你的创造力。 进一步提高你的创造力当然，在不同领域积累扎实的知识需要时间，所以有时需要权衡利弊。   下面讲多学科融合，没什么东西   Philosopher of science Thomas Kuhn discovered that most paradigm shifts in science are brought about either young people or people who were originally trained in a different discipline. They’re not so easily trapped by einstellung, blocked thoughts due to their preceding training. And of course there’s the old saying that science progresses one funeral at a time as people entrenched in the old ways of looking at things die off. Finally, don’t make the mistake of thinking that learning only occurs in the kinds of subjects you acquire from teachers or books. When you teach a child how to deal effectively with a bully, or you fix a leaky faucet, or you quickly pack a small suitcase for a business trip to Hong Kong, all of these illustrate the outcomes of important aspects of learning. Physicist Richard Feynman was inspired in his Nobel Prize-winning work by watching someone throw a dinner plate into the air in a cafeteria. Mike Rowe of the television shows Dirty Jobs and Somebody’s Gotta Do It shows how important and exciting learning can be in a variety of different, non-academic disciplines.另一方面，如果你只在一门学科上发展 另一方面，如果你只发展一门学科的专业知识，你可能会对这门学科有很深的了解，但 你可能会在自己熟悉的思维方式中变得更加根深蒂固，无法应对新的想法。 无法应对新思想。科学哲学家 托马斯-库恩（Thomas Kuhn）发现，大多数科学范式的转变都是由以下两种人带来的 要么是年轻人，要么是原本接受过不同学科训练的人。 不同学科的人。他们不那么容易被先前的训练所束缚，思维受阻。 由于他们之前所受的训练，他们不那么容易受困于 当然还有一句老话，那就是 科学是在一次次葬礼中进步的，因为那些固守旧的 看待事物的方式的人都会死去。最后，不要误 认为学习只发生在你从老师或书本上学到的科目中。 从老师或书本中获得。当你教孩子如何 当你教孩子如何有效地对付恶霸时，当你修理漏水的水龙头时，当你快速地 当你教孩子如何有效应对恶霸时，当你修好漏水的水龙头时，当你为去香港出差快速收拾一个小行李箱时，所有这些都说明了学习的重要方面的成果。 这些都说明了学习的重要方面的成果。物理学家理查德-费曼 在他的诺贝尔奖获奖作品中看到有人在自助餐厅里把餐盘扔向空中，从而获得灵感。 在自助餐厅向空中投掷餐盘时受到启发。电视 的迈克-罗在电视节目《肮脏的工作》和《总得有人去做》中 展示了在各种不同的非学术学科中，学习是多么重要和令人兴奋。 在各种不同的非学术学科中，学习是多么重要和令人兴奋。   ##WEEK3 拖延症与记忆概论   拖延症   我将教你懒人解决拖延症的方法。这意味着你将了解自己内心的 “僵尸”，即你的大脑在特定暗示下产生的常规习惯性反应。这些 “僵尸反应 “通常都是为了让此时此地变得更好。   与此类似，拖延症患者拖延的只是一件小事。他们一而再、再而三地这样做，逐渐养成了习惯。他们甚至可以看起来很健康，但长期效果并不好。      你已经学习了一个非常实用的工具来帮助你解决拖延问题，即“番茄工作法”，也就是25分钟的不间断专注时间，后面跟着一点放松时间。   学习避免拖延之所以重要，是因为好的学习是一个逐步的活动。   意志力很难获得。它消耗了大量的神经资源。   拖延可以是一个单一的、具有巨大影响的坏习惯，换句话说，它影响了你生活中许多重要的方面。   无处不在的僵尸思维   第一次开倒车很难   但是无数次后，你的大脑会进入一种僵尸模式，只对几个关键因素半知半解，而不是被所有数据淹没。骑自行车也是同样的道理。一开始很难，后来就很容易了。   Neuroscientifically speaking, chunking is related to habit.   所以习惯是什么，an energy saver   它能让我们解放思想，从事其他类型的活动。 你进入这种习惯性僵尸模式的次数远比你想象的要多，这就是习惯的意义所在。 在养成习惯的过程中，你不必集中精力思考自己在做什么，这样可以节省精力。   你可以把习惯看作由四个部分组成，第一部分是线索。(cue)   这是让你进入 “僵尸模式 “的触发器，线索可能很简单，比如看到待办事项列表中的第一项。比如看到要回家的信息。提示本身既无益也无害。重要的是常规，是我们对提示做出的反应。   Number two, the routine. 这是你的 “僵尸模式”，是你的大脑在收到提示时习惯性做出的常规反应。 僵尸反应可能有用、无害，有时也有害。   Number three, the reward.每个习惯的养成和延续都是因为它能给我们回报。 它能给我们带来直接的快感。拖延是一个很容易养成的习惯，因为它的奖励，即把你的注意力转移到更令人愉快的事情上，发生得如此迅速和容易。   第四，信念。 belief。习惯之所以有力量，是因为你相信它们。 例如，你可能觉得自己永远无法改变把学习拖到很晚的习惯。要改变习惯，你需要改变你的基本信念。   冲浪练习 结果与过程   学新大学有负面衬衣 凡吸毒面呈细 奴卡失效 就是和陈i像你风格有新的方法   急症在结果 但是一个集中在错火车上呢个上 虚像做作业 反对就5 分到日版有此案骨气·那个作业和温暖男 不要在就看i问过上而实在估测婚个上个   专注的的番茄工作法，在工作片段上而不是在工作的结果   这样就将是过程关注在过程上而不是在一个痛苦的结果。   安静的学习   利用僵尸思维   应对反应   什么开始了zombo思维   the cue   localtion   time   how you feel   Reaction   什么是拖延，比如看了眼手机然后不回了   The routine   Plan就行，   The reward   无论什么奖励。甚至设置一个目标5:00不搞别的事情就休息   应对生活与学习   weekly plan   每天新起一页写 然后在睡前写好 潜意识会帮助你构造这个目标   番茄工作 切换一个导向过程也是换一个process   时间工作量 的准确判断   5pm之前完成，休息时间非常重要   努力在生活之余保持健康和空闲   summing up procrastination   日志 比对   目标比对完成度   奖励留在最后   观测拖延症触发的开关   使用一个新度学习系统，比如使用🍅   注意休息，有时候休息，比如在5:00pp之后   记忆 虽然我感觉没什么用   深入记忆探索   祖先不记得文字，但是知道打猎的路，进化过程的需要，使用坐标位置，使用视觉记忆而不是单一背诵，甚至是感觉。   重复和复习   使用图像辅助记忆概念。重复，test，mixed 再记   如果不能学习 HM（人名）什么是长期记忆   分时段学习更加好。      fade？消失   创造记忆宫殿   记忆技巧   记忆总结   connection   长记忆   store house  几天 长时间 提早开始   working memory   4 items   记忆技巧   生动的画，感受生动有趣，简化材料   数字和有意义的数字   可视化记忆 分类方法   熟悉场景可视化记忆   有意义的缩写和 chunk 背诵理解的材料   week4   怎么更好的learner   保持运动 促进神经元存活   复兴式学习   学习不是线性增长的概念 知识体系会坍塌 新知识吸收会花时间   生动视觉比喻   f=ma的另外一种解释   不需要羡慕天才   有点重要，看文字  有大的记忆力空间，因为思维是在原有的记忆力空间上促发诞生的，我们的思维思考方法是在原有的磨具上被发展的，换句话说就是，记忆力本身是智力的容量。   ### 改变思维   觉得自己牛逼？   week 4 下   团队的价值（脑）   研究主义 左脑感觉，在做完作业以后过度自信。   首先原则不要自我欺骗   什么是自己的盲区   脑力不够 与同学一起学习 察觉忽略 给同学讲解   学习小组而不是社交小组   测试清单 final   回答问题 我要如何准备考试   认真努力学内容吗，理解吗？   自己的观点   明白所有答案   study guide   相互提问   先难后易   在开始时候难，转向简单。focus mode 转向 diifuse mode   想一个并行操作的大厨   大脑不同部位都有功能   自制力 两分钟就转向 引发牵引力   压力 有益的最后提示   注意转向呼吸 深呼吸   保持好心情而不是焦虑   选择题，盖住选项 回想知识   stuble braided   summing up module 4   转变思维转变命运   检查问题，利用大脑功能，要休息，审视   太自信，与朋友一起学习   check   先难后易 利用两个模式解题   紧张 深呼吸   足够睡眠     ","categories": [],
        "tags": [],
        "url": "/learning-how-to-learn-powerful-mental-tools-to-help-you-master-tough-subjects/",
        "teaser": null
      },{
        "title": "Inner producted 一些问题",
        "excerpt":"A record of some simple ideas.   vector inner product   向量的内积      内积的定义:                                                            设A和B为两个向量,它们的内积定义为A在B上的投影长度,用公式表示为&lt;A,B&gt; =               A                               B               cosθ,其中θ是两向量之间的角度。                                                        内积的几何意义:内积反映了两个向量间的相似程度,当两个向量方向相同时内积最大;when两向量垂直时内积为0。            如何计算两个向量的内积:设两个n维向量为A=(a1,a2,…,an),B=(b1,b2,…,bn),则两向量的内积为&lt;A,B&gt; = a1b1 + a2b2 + … + anbn,即对应元素相乘并求和。       内积为何等于零:当两个向量垂直时,cosθ=0,从内积公式可知此时&lt;A,B&gt;=0。也就是说,内积等于零表示两个向量互相垂直。   matrix inner product      矩阵内积的定义:对于两个矩阵A和B,它们的内积定义为:&lt;A,B&gt; = tr(A^TB),即矩阵A与B转置矩阵的乘积的迹,什么是迹，就是从左到右的对角线。   矩阵内积与迹的关系:矩阵内积用矩阵迹来表达,迹反映了矩阵的特征,内积刻画了两个矩阵间的相关性。   如何计算两个矩阵的内积:对两个矩阵A和B,计算A^TB,然后求出其迹(对角元素之和)即可。   矩阵内积的性质:            对称性 &lt;A,B&gt; = &lt;B,A&gt;       双线性形式                                                       范数不等式$               &lt;A,B&gt;               &lt;=                               A                               ·                               B                               $ 这啥                                                   matrix的变换。   f(x) and g(x) inner product           函数内积的定义:对于区间[a,b]上的连续函数f(x)和g(x),它们的内积定义为\\(\\langle f, g\\rangle=\\int_a^b f(x) g(x) d x\\)            如何利用积分计算函数内积:将函数相乘后对区间[a,b]积分,即可计算内积。            函数内积的双线性形式:满足α&lt;f,g&gt; = &lt;αf,g&gt; = &lt;f,αg&gt;            函数内积与区间长度的关系:内积与区间长度成正比,因此也会normalize由 $\\int ab$  改为 $\\int \\frac{ab}{L}$。            函数内积的应用:反映函数间相关性,应用于信号处理、模式识别等领域。       \\[\\langle f, g\\rangle=\\int_a^b f(x) g(x) d x\\]  or another choice   \\[\\langle f, g\\rangle=\\frac{1}{b-a} \\int_a^b f(x) g(x) d x\\]  第一种表示法:   \\[\\langle f, g\\rangle=\\int_a^b f(x) g(x) dx\\]  直接对函数的乘积在区间[a,b]上进行积分即可得到内积。   第二种表示法:   \\[\\langle f, g\\rangle=\\frac{1}{b-a}\\int_a^b f(x) g(x) dx\\]  在积分中额外引入了比例系数$\\frac{1}{b-a}$,目的是归一化区间[a,b]的长度,使得内积不直接依赖于区间长度。   应用：傅立叶级数  ","categories": [],
        "tags": [],
        "url": "/inner-producted/",
        "teaser": null
      },{
        "title": "The summary (guide) for DIY master application in 2024 fall",
        "excerpt":"  写一些申请cs(没申到)和泛cs(cse/ce/ece/ee)硕士的想法和记录,关于学校, 关于项目, 也关于一点别的   开始之前   这篇文章主要记录了我在 2024 年 4 月 24 日至 5 月 1 日期间撰写的一些关于申请24fall 计算机科学硕士（CS）及其相关专业（如ce, ece, cse等）的想法和经历。随后，在 6 月初进行了重新整理和编辑。   如果你觉得语气有点怪或者某些用词很机械, 那是因为文章的原始内容被我用gpt和固定的prompt重新生成了一遍. 另外, 所有之前的commit记录已经被我删除了.   后记前置   这篇文章的编辑时间跨越了 4 月 24 日至 5 月 1 日，当时我正在撰写我的毕业论文，尽管那个过程非常艰难，但奇怪的是，这篇文章的撰写却非常顺畅。第一次动笔，就写了 5000 多字… 最初的草稿长度为 3.3 万字，经过初步筛选后剩下了 2.9 万字。尽管我将其简短地发布在我的页面上，但我觉得文章的口气太过激烈，因此我将其撤下重新编辑。现在，文章的字数为 19526 字（Typora 自动识别）。我希望尽快发布，以抓住大量报中介的时间。24fall的申请季已经结束了很久了，2025 年秋季学期即将开始。回顾这篇文章，我觉得这 1.9 万字更像是阐述 GPA 的重要性以及 DIY 方法的指南。   开始之前的开始   在申请季之前，我和一些同学（大约有 5-6 个与我同届的同学以及下一届的 2-3 个）一起交流一些申请信息。虽然交流有助于分享一些信息，但重复地讲解会很累，所以我想把整个申请过程完整地梳理一下。我开始写作的时间是 2024 年 4 月 24 日，持续到现在，即 5 月 1 日（现在是 5 月 7 日）。虽然这个过程并不复杂，但一步步记录下来便于将来参考。我可以很有耐心地向一个人解释，甚至 10 个人，但对于 100 个人来说就有些困难了。而且我也不能从中获利（虽然我想尝试），所以我想写一篇文档并公开分享，供所有人查阅。如果你觉得我不够资格写申请指南，那就笑笑、骂骂吧。   还有一点是, 我不喜欢一点一滴地讲解，一页纸写三言两语的内容，我觉得那样没有意义，内容太过零碎。每个人的背景都不太一样，所以我主要考虑自己的情况。因为我没有足够的时间和精力去了解所有的项目，也没有必要。在申请季只关注适合自己的信息是很正常的。   我考虑将部分内容放在我的主页上。我必须坦白地说，虽然我可以说自己 DIY 了一些申请项目，但我还是得到了很多人的帮助，无论是提出许多中肯建议的学长学姐，还是一位我在小红书上认识的非常厉害的朋友，都给了我很多申请季的帮助。在这里我要感谢他们。   很多第一手信息（我会全部分享出来）来自在读的学长学姐甚至已经毕业的学长学姐，感谢他们接受我这个陌生人(虽然是校友)的骚扰，并给予我建议和支持。   在申请季开始之前，我阅读了一位学长的申请总结，收获颇丰（尽管该帖可能因透露过多个人信息而被删除）。在我仔细了解了一些中介水平低劣的情况后，我决定自己操作申请。最终，我将整个大四上学期的时间都投入到了这件事情上。现在回想起来，我可能有点本末倒置，更应该把时间用来刷题增强计算机基础，因为相比而言, 一个排名更高或质量更好的项目对就业的帮助微乎其微，个人实力才是更为重要的。当然，实力强的人才会有机会进入更优质的项目。但是，强大的实力并非这些优质项目的教学而习得的。我说的可能有点绕，但总的来说，我在大四上花费了大量时间翻阅了Linkedln、一亩三分地、小红书、Reddit、两岸三地的 看板, Discord ，甚至还查阅了一些印度论坛（印度的计算机科学留学群体庞大，但是录取的逻辑和我们不一样, 我主要是看了一些他们对项目的评价）。这篇文章的契机是，作为西浦的大四学生，我最关心的事情就是申请研究生(可能做错了)，我想把整个过程和想法记录下来以作纪念, 也顺便给路过的人参考吧。   本人的24fall申请背景是，——删——，就这样开始了申请季。我想大部分我们学校的毕业生都会选择读硕士。就我的成绩/GPA而言，我对我的申请结果相当满意，而且项目出结果的时间非常合适。从11月开始，一个月一个ad，稳扎稳打，一点都没有慌乱和错乱的感觉。想象一下，如果你申请季最后收到了斯坦福ms ee/cs这样的offer，但前面一堆rej，你至少会失眠并不断怀疑自己半年哈哈哈。   本人的rej的项目如下      rej UCL sse 两礼拜飞速拒   rej uiuc ece meng 2月7号   rej ic edsml 一个月飞速拒   rej Cornell ece meng az   rej UVa mcs   rej 爱丁堡 cs &amp; ai 复活节   这上面想去的项目里面, 把我给拒了的, 就是ucl, uiuc, UVa。UVa在今年更新了选课政策，选本科生的课变得非常麻烦，而且项目的规模不断扩大，所以我觉得没申请上也不算遗憾。不过，在申请季开始时，UVa是我非常喜欢的学校，本土排名在前30，但国际排名相对较低, 不过我不是很care。UIUC在投递的时候就知道不太喜欢我们学校的bg，只是因为有好几个认识的朋友在那里，所以比较想去。至于UCL SSE，投完后才发现其实根本录取不了(虽然有23fall大数据专业有申请成功的case) ，有点虚幻投递了。最后的结果让我感到意外的是UVa，我还以为是稳的… 但我已经尽了全力去做能做的事情。其实，申请季并没有做什么特别努力或费心思的事情，只是浪费时间查找资料，尽力做好自己能做的。   在之前提过，我通过学长的帖子得到了申请的第一印象和很大的收获。那么为什么我会找到这样的帖子呢？是因为在我没有决定自己diy还是找中介申请的情况下，我先在收集信息和比对学长/学姐的相关出路和他们最后申请成功的项目。除了了解上一届和上上届的去向，主要是我想搞清楚中介的收费从2w+到5w+甚至10w+到底这个钱花在哪里。但是这个问题我其实到现在也没搞明白。   我总结出的结论是：大概有些(可能也不是有些)真的就是纯骗人吧。   别的先不说了，写作水平之低，就可以很好的判断出不专业性。我写点我知道的可能是在我梦中发生真实案例：      一个案例是，在签约之前说可以提供不限次数的文书修改，结果是拖着到项目的ddl临近，才给文书材料。明天0点甚至是今天下午5点就要递交所有材料了，你就说你还改不改吧:)。还有1小时或一天就要提交了，是不是对文书有什么不满意的地方。   而且就算文书看起来一切完美，中介也是ddl前提交申请居多。这可能取决于外包的写文书人员的速度。可以说问题很大，因为这个节奏应该灵活掌握。下面会提到申请的时机很重要，当然你在咨询的时候，话术就是ddl前交了就都一样的。   最基本的写作水平如此，那就更加不要提选校定位这种事情了。除了已经固定化格式化的选校项目(很多项目是每年都是固定套路项目,年年报)。甚至有些小中介还没总结出这些套路项目，选择的策略更加保底。这些项目在申请季开始之前，我也觉得很牛逼，学校牛逼ranking高，项目名字看着可以/过得去。但是在经历过申请季或者说申请季开始了一半以后，就会发现他们申请的标准其实不在天上，和自己之前的认知相差甚远，甚至稍微做一下调研，就可以知道自己完全可以handle。   某中介在学校和材料开放材料递交第一天，直接跨过学生本人，给教授发催促推荐信的email。然后把这个教授惹毛了，在学生和教授 meeting 的时候,这个学生直接被教授警告(比较罕见的case)。   语言成绩出问题。我知道的时候简直笑死了，雅思6.5的成绩在申请系统上写了5.5，甚至还有忘记提交成绩证明的，我只能说…   文书全GPT(其实没关系)，开头名人名言，人和名言在Google查不到(感觉这个还是有点关系的)。笑死我了，太离谱了。   还有把不同项目的语言要求搞错的,还有gre战士。人均建议：均分低考个gre/均分高补个gre，笑死。   **以上案例(可能)纯属虚构，仅为说明目的而使用, 你可以认为来源于网络。 **   没有以上多项问题的发生，我觉得这只是做到了一个合格的中介的基础水平。因为这完全不包括对项目的详细介绍(我会在选校细谈)。虽然项目官网会提供很多课程的介绍、选课list，但是每年开什么课、选课限制、是否可以入读之后转专业这些内容比较难获知的, 而且这些信息每年都会变化。我猜测很多中介对项目的认识程度，和刚考完大三期末考试点开项目主页的随便看看的你，是差不多的。绝大多数的认知来源是点开项目介绍页面的直接翻译。有些中介在沟通和后续合作的时候搞得很忙的样子，我都不知道在忙些什么, 可能在忙着庆祝了。   另外我提供一点猜测，就是中介的文书工作，应该大多数是由外包完成的。这个原因也很简单，如果你是boss的话，会养一批人只在每年的9月到1月工作剩下时间休息半年么。我认为这样的成本是不可能接受的，可能养1-2人还行。然后，我搜索了一下各大招聘平台对文书老师招聘工资是5000+一个月，假设这个文书老师的水平非常高超，可以做到收入5万一个月，那么大家可以仍然感受一下，一个人在一整月的工作量可以服务多少当年当季申请的学生。   以下还有几点中介为什么会存在的一些思考。   8⃣️中介服务重复购买率很低，申请的渠道靠校代和潜在的校代口口相传和广告曝光，被发布的好评只会如潮。就其实我觉得很多均分高的人，最后有一部分人没弄明白为什么自己申请的结果不错。只要观察一下身边均分不是很优秀的朋友/室友，就可以发现这帮人有时候没有帮倒忙就真的谢天谢地了。另外，差评的传递渠道不透明，很少有人花几万买了一坨屎还到处说(除非真的吃了好几坨实在受不了), 匿名平台说一次得了。而且就购买一次，都没什么横向比较机会，还能被怪自己bg低。   9⃣️重复第8点，面对褒贬不一的前路面前，会有自我修复心理。出现“我肯定是比较特殊的一个”和“他们服务我的话，肯定会用心的”的错觉。其实每个人都是平均的韭菜。   🔟宣传得很厉害的东西，基本上都不太专业或者很一般。很简单，人的经历是有限的，当把很大一部分精力放在宣传的时候，剩下的精力就很有限了。   我们总是会美化已经被固定发展了的道路，类似于‘来都来了’。   当然，以上这些都是最坏情况（或者说正常情况），我也知道很多朋友通过中介拿了很多不错的offer。因为公司只是平台，你可能会遇到很正常相对靠谱的人来对接，就像同样一个课，不同的老师上，评价也不一样是不是？或者同一个老师，每年上课也有评价的偏差。要是每个人通过中介都全聚德，那这个行业还有没有存在的必要了（也赚不到钱了）？   但是有两点要澄清，什么是不错的offer和为什么要中介。对于后者，我觉得大部分人的出发逻辑是      专业的事情交给专业的人   省心   事实证明，出发点虽然正确，你抽到负责的人往往是运气。以运气为开头的故事，往往不能省心。如果申请美研，这个抽取运气的成本是5W+人民币，我觉得不太值得。而且我相信大家学到现在，稍微努力一点就可以比大部分在这个行业中*了多年的人更加优秀。   为什么CS/EE专业要对留学机构说NO   总来说，按严重点来说，选择中介就像是你在学校邮箱中疯狂轰炸的垃圾邮件中挑了一个代写在完成你本科阶段比较重要的大作业（当然有机会碰到某些学校在读博士水平的代写）。我假设大家来xp可能都是希望读一个还不错的研究生。虽然根据身边的统计数据，我校的本科的直接就业率在提高，认识的朋友已经有好几个直接工作和不读研究生了。   1⃣️先交钱的逻辑。如果module leader告诉你，在大四这个学期开始时，你已经有60分的保底分数，你是否会觉得有必要认真学习课程内容和完成作业呢？同理，你在没有开始申请季之前，签约合同，已经付出了金钱的代价，机构已经拿到报酬了，你申请到斯坦福本身对他来说有什么实质性的好处吗？换个说法，你FYP完全不写，不用提交任何内容就有60分的前提下，你会为了写一篇目标是发SCI的FYP文章而努力吗？奇怪而疑惑，但是可能真的有？   2⃣️抽奖逻辑，你碰到一个好的对接的人，是完全抽奖的，之前提过。   3⃣️美研，或者是申请研究生吧，绝大部分项目（我感觉看中research的项目，我校几百人最多也就是3-4个吧，甚至好几届才能出一个），申请的条件就是GPA+学校背景，文书和视频写/录成屎申请成功的概率也很大，一本万利的买卖，或者说0本万利。   好了，前面都在说消极的内容，但是我觉得现阶段大家要关注自己以后想干什么，有自己的思路，研究生不是目的，只是方法（来源open cs），这个方法应该是自己去分析和思考出来的。   4⃣️所以，申请的项目你要了解它，不是学校和专业名字OK就完事了，这很重要，这是你申请完以后，下半年要入读的学校和项目啊，花费70w甚至150w。好多朋友申请完以后，甚至offer下了以后才开始了解这些项目，有点……   5⃣️开始对自己负责吧，申请研究生只是很小的一步，下面的发展过程有无数的步骤和问题要等着自己来操刀，从这一步开始为自己负责吧。   在申请季最后，其实感觉大部分项目中，学生很少得到就业（非科研）的顶级提升，某些hypms的项目是真的指数级别提升的，我指的是水平不够，没什么实习也能找到工作。我有考虑冲一个hypms的二硕…但是别的项目里面，最后还是个人能力大于学校title。   正文 (申请的步骤和操作)   选择2+   作为非顶尖选手，我主观感觉就泛CS项目而言，如果费用可以保障（30w-40w一年），对于成绩在中段的朋友请果断选择2+，西浦和利物浦CS/EE的考试难度和学习强度分配，就最后的出分结果不是一个级别的。我觉得中上水平的人也应该考虑，而顶尖选手则请随意选择。这届一个ICS的top水平的朋友，给出的评价是利物浦的cs高分不能帮助top选手获得top项目的offer。从申请结果来看，85分以上的均分也不足以保证让其拿到Open CS上S和A+项目的offer，获得的很多项目都是70+和80+都可以申请的，有效果的帮助是让这些项目从彩票的级别变到了冲刺的级别，使申请成功的难度有所下降。所以，CS 2+可能对于本身就是极高均分的选手帮助不大（假设你ranking排名top10，前1%？）。但是我觉得大部分人都不是顶尖选手吧？所以还是把2+推荐给大部分人 :)，4+ ICS的申请结果也相当不错，我CST/EST/DMT认识的朋友都和我说，在国内非常非常累而且出不了分（很难受），（大三下学期期末的时候前两天还刚做完pre，结束后，在一个礼拜内开考整个大学生涯中最重要的4-5门考试（真感觉就我校申请重要性来说，大三=高考））。   我平心而论，如果没有2+，然后超级努力地学，国内估计大三就… 而利物浦这里呢，我大三刚刚来的时候人整个都没怎么进入学习的状态，最后一个月圣诞假期的时候才开始学的（真摆），最后考的还可以（不同的学科不一样，我说的CS）。我告诉他们我在这里学习的状态和分数的时候，我感觉他们难受得想跳楼。利物浦大三下有点难，难度和课程压力都上来了，EEE还有Year 2 project耗费你的大量精力和时间。我做这个项目的时候出了大问题，每天都是图书馆半夜3-4点回宿舍，早上10点左右强迫自己醒然后开始做。最后评分导师也有问题。哎～CS也逃不掉，COMP208基本是一堆70+80+均分的人在这个课上非常容易得60几。而且利物浦在最后考试的时候有至少两个礼拜的时间复习。适合很多高水平选手，一个礼拜学完，一个礼拜刷完往年卷，期末轻轻松松拿80+的分数。   所以这样看，即使是这样，我还是感觉2+还是远比4+容易得到分数。自己权衡…苏州（国内）吃的是真好啊…   而且今年真的超级卷，利物浦的eecs/cs的最高分应该都是打破的记录了，英本大三engineer搞到90多分，太牛逼了。   （以下内容和录取的逻辑有点重复，但是主要是中外合办一波分析，你觉得不对就是你对）   其实, 中外合办的本科都希望本科生留在自己学校交学费，但是又明白没外国母体学校的reputation自己什么都不是，所以都藏着掖着推出一些bridge政策。其实说到这里，西浦基本是国内2+2政策最宽松的学校了，WKU不了解，隔壁宁诺想2+2在高考录取的时候决定一大半以上的人数，剩下的人数由4+0的人在专业里面排名决定，搞得和保研一样。成绩在次等还想去UK就有折中方案，选择只去UK交换大三一年，还有就是放弃宁诺（国内系统）的学籍和学生身份直接transfer到诺丁汉。这些操作在疫情前比较火热。之后直到现在，来或者不来，成为了他们一个权衡的选择。LGU的水平在common的认知上，肯定是比我校的reputation要高的，而且在商科金融的领域我们学校就业水平碰瓷不了一点。但是LGU的GPA太恐怖了，卷的人又多，一旦GPA掉下3.5，申请季就会非常被动和煎熬（但是在515之后有改动？）。所以我发现他们学校的common的申请结果没有很耀眼。之前LGU和CUHK出了2+2的项目时候，公众号发了好几波广告，我点进去看了看名额40-50个人…(更新: 现在又看到了cu和cuhksz的3+2项目, 感觉有点东西啊) 关于昆杜和上纽，我了解到，DKU到Duke交换政策比NYU Shanghai的限制大很多。Duke交换只能拿J1签证。这两个学校的top ranking的人出路太璀璨了，MIT CS直博/MIT FIN，申到的项目我看都不敢看，但是一旦在这两个学校卷失败，出路立马掉到rank中档的西浦宁诺级别。广以体量太小，出路也很好看，但是都是基础学科（化学，生物），我校的基础学科出路也同样很吓人(yale/cmu/nus提前批/一堆ic)，所以不知道怎么评价，加上没空了解。   还有转美本的问题…这个section太大了，可以写一篇文章来整了。但是, 如果人生有重来我一定希望是可以读美本 😭   处理挂科   首先没有我挂科, 虽然我现在大四分数在挂科的边缘… 我感觉我好功利啊, 没什么用的分数我一点学的兴趣都没有. 一直有2+可以免去挂科标记的都市传说, 这个被证明是正确的。在利物浦拿到西浦开出的成绩单开始给你办2+的手续时候, 他只关注分数而会忽略考试的次数, 所以补考的remark会被消除。但, 是不是在申请的时候有大用, 我不太清楚, 因为在申请的时候大概率要提交两个学校的成绩单, 还是会被发现是补考成绩。而且我感觉(只是感觉)只要补考成绩高, 就没啥关系, 申请的时候问题不大。我之前一直不敢想挂科补考的问题, 西浦毕竟不能重修更新GPA。   不过挂科千万不要慌, 申请应该还是按照第二次考试的分数来计算GPA的, 所以, 不要感觉天塌了。我甚至觉得在考个41, 42不如挂了补考算了…   6.16 update: 有人来咨询看了一个有补考成绩的transcript, 对面不说我根本没发现是补考的… 这个*的标号实在的太小了, 我现在感觉补考完全没关系了, 有补考成绩申请一般的大概原因是有补考成绩说明总体成绩可能一般, 但是有1-2门补考成绩(补考分数高), 别的module整体分数尚可的话, 应该是完全不会影响申请的.   WES认证   7月全出分的时候,马上可以开始做了,要处理一个月,请避开9月,10月旺季 , 因为在10月开始做wes认证, 可能要一个半月的等待时间。想想一堆项目的ddl就是在12.15, 还是不要这么这么急的做事情吧。Ps: 虽然我也不知道wes在忙什么,可能是海专精,一杯coffee一个下午挑20个人开始算成绩, 然后下班吧hhhh。另外, wes选便宜的套餐就行,我选了300美元那个, 小亏。还有一个要提及的点, 就是大三的全学分的课要更加精贵一点。大一大二会是5学分呈现, eap掉到3学分, 但是大三正常 full credit 的课程 wes会从15学分down到5.5学分,然后7.5 学分的课还是down到2.5学分. 不知道利物浦大三的成绩单是怎么处理的, 听说还有传媒的朋友在利物浦有30学分的课,我真是一头雾水。   提交什么成绩(美国)   在投递的时候, 我们会在院校背景的label写自己的就读经历。这个时候, 请务必写自己转换成wes的3.x/4的GPA, 不要写自己英国记分制的成绩, 因为第一遍初筛的时候, 设置的条件的就是GPA从高到低排, 大家都是3.X, 然后你的分数80+ or 70+在那边, 就很搞笑。当然你可以说, 美国院校会自己convert, 确实, 但是你不知道他们是怎么转换的, 比如就我知道的有些加州大学会统一对英本的GPA做3.67最高处理, 或者可能有些学校, 学校会挑自己喜欢的专业课计算。这些是我们不能把握的, 但是请把握你可以把握的部分。甚至有些学校不知道我们使用英国的打分系统, 这里想起来一个之前我校转学本科的同学, 70多分被学校算下来GPA 2点几, 就这样无缘无故和某校(好像是uiuc)说再见了。而你可能觉得是自己软背景不够云云。虽然出现这种convert问题的可能性比较低, 但是你为什么要让它出现呢?   又可以补一点内容,我发现可能大家不知道成绩单提交的格式, 正确的格式是: wes的认证报告 + 利物浦成绩单 + 西浦成绩单(自带Classification说明) + 利物浦对成绩的Classification 文件(这个文件我附在了下面代码框中), 然后做成整个一个pdf文件。可能是多此一举, 反正这个操作的理由也是同上, 我们把握可以把握的部分。   https://www.liverpool.ac.uk/media/livacuk/tqsd/code-of-practice-on-assessment/appendix_I_2010-11.pdf   关于学分(没什么用的冷知识)   在之前的section提到了就补充一点吧, 学分是每个学校的一个毕业量表,怎么说呢,大概的计算逻辑是修满多少多少学分可以毕业。其中中国高校好多是使用2.5/5这样来定义半学分和全学分的课的,西浦也是。但是利物浦使用的方法是7.5/15的组合。之前有考虑过申请欧洲的项目, 所以也了解过欧陆的学分设计, 他们使用ECTS(European Credit Transfer and Accumulation System)这个机制来计算学分。如果想申请欧陆的学校,在计算课程匹配度的时候可以参考如下, “Students should note that ECTS credits are considered equivalent to half the value of Liverpool credits, e.g. 7.5 ECTS credits would be equal to 15 Liverpool credits。”   University of Liverpool. April 2024. Academics. Retrieved from https://www.liverpool.ac.uk/global-opportunities/inbound/study-in-liverpool/academic/   但是利物浦的成绩单上保留着西浦的学分逻辑, 2.5/5和10分的eap与7.5/15的大三分数, 让正常人计算的时候摸不着头脑。   注: 我这里真的想说宁诺西浦争了这么多年,就成绩单这件小事可以看出,西浦已经输了,宁诺的成绩单和英诺的成绩单title一模一样, 加上学分完全按照ECTS设置, 只有campus不同的标注,会写上China/UK。就西浦和利物浦的成绩单,这一看就是两个学校,title,格式, 计算系统完完全全不一样。最搞笑的是,利物浦成绩单上赫然写的大一大二分数从下交(西交大)修来的,太搞笑了   就申请上的体感也是, 两校没有绝对差距, 但是诺子好像就是过西浦半个身位…   Email   我之前国内用Outlook, 国外用Gmail. 无论如何, 请重新注册一个!!!!   首先NYU和NEU的广告就能烦死你了, 要是用老邮箱, 原来的subscribed的各种广告邮件也能烦死你(我有很多商店的邮件).   也防止错过录取通知书的ddl,真有人不关注然后中介也没发现就错过了一个学校发了的ad, 要是是梦校offer你找谁哭呢。 我不喜欢163, 要手机验证, 而且邮箱link数学符号完感觉很奇怪, 有理由相信美国人也会觉得很奇怪, 之前在英国打客服电话的时候用163邮箱对面都笑了。   之前没想到要写这个section, 算比较重要和简单的一步? 因为我知道看到过一个帖子, 某校学生没发现学校发了offer导致gap的, 记得那个家伙是LSE的项目。   语言   我的语言水平一般, 所以直接waive了, 好像没怎么影响我的申请, 除了NTU CCA发邮件问我要语言成绩。   GRE   我在这里专门列出。   有时间,喜欢英语,有自信的人可以专门考一下。 我高中的时候, 刷知乎看到一个北大本科说考GRE很痛苦,太痛苦了,感受到了单词如水流入脑又如瀑布般流出记忆,笑。   但是这个现在已经不是必须的了,甚至申请的权重越来越低(我给出一个猜测,重要性占比为2%,给1%太少,给3%太多),我真的感谢那些GRE作弊哥, 以一己之力让中国大陆的GRE平均分在疫情的两三年内实现了史诗级别的跃进, 让这个考试的效力越来越低。 别人花钱我来享受这个结果,拯救了我这个英语渣子于水火之中。 总之, GRE的不考率真的是越来越高。 除非是top项目, 否则院校真的要考虑是否用这种姿态来换取申请数量的下降(说的就是你, NYU,9月GRE required然后10月改成optional)。   但是,GRE能考出的大佬还是挺牛逼的, 我深深的respect!!!   哦对了, 如果想申请CMU的一些项目好像GRE是必须的,有些顶级项目也有GRE的要求,比如CMU SCS/ Yale CS/ Duke MSCS, 但是我目测西浦大多数人申不到, 本科院校背景不够。   总结, 就近两年的EE/CS申请而已,市面上90%的项目, 已经不需要GRE了, 或者换句话说, 剩下的10%的CS/EE项目不属于西浦, 无论是 斯坦福 MSEE, CMU SCS, Yale CS…注意除了CMU, 但是我申请季完全没考虑CMU, hhh   如果对于自己非常自信(有我一个浙大的朋友0基础学一个礼拜325+的case😭), 那可以考一个玩玩, 但是你一旦感觉是自己要下定决心努力学习GRE才能考的话, 相信我请直接放弃, 这个时间放在准备大四的暑期实习/秋招, 会对申请后的发展/对找工焦虑的解决大有益处. 收益远大于10倍的一个GRE 330+的成绩。   卖惨   我见过很多在文书中卖惨的案例，例如身体残疾、父母离异、心理疾病、性别认同问题，甚至简单地描述自己是第一代大学生。虽然这些情况都可以提及，但重要的是表达时要有逻辑。在美国，强调英雄主义，因此指出问题的同时，请务必说明你是如何解决或正在解决这些问题的。例如，家境贫困、没有足够的经济支持读书，但却凭借优异的成绩获得了奖学金，一路走到今天。注意要有起承转合的叙事逻辑。如果你只是简单地陈述了困境而没有后续，那实在对不起……你是在说让赚钱的master项目给你提供励志奖学金吗？   因此，在个人陈述或申请书中提及困境时，请务必简要阐述困境，多加说明解决困境的过程。如果这些被注意到(几乎不会被注意到)，那确实会给你加分。   情侣   有些学校, 在申请系统上会问是否情侣/朋友一起入学(主要是私立学校), 我觉得这个点是有影响的, 逻辑是如果两个人都满足入学要求, 学校给这两个人发offer入读的概率就会很大, 减少担心发offer被鸽的情况。 所以你懂的, 既然有离婚买房, 那么申请季在申请系统上小结一下好像也不离谱 。   科研&amp;实习&amp;作品集   我申请下来感觉90%的项目没什么用，9%的项目有些用，1%的项目则非常重要，可能是因为GPA较低（3.1），但有着丰富的实习经验、参与过的会议和发表的论文。也许这样的申请材料会让招生委员会感到困惑，谁知道呢，这些东西总比没有要好，但重要性远不如GPA高。找到这些项目需要耐心和规划。   然而，有质量、有含金量的实习对于未来就业和申请绝对是有帮助的。尽管在申请阶段可能帮助不大，但在找工作或实习时会大大加分，没有实习经历的人必然会吃苦头。尽管这个世界有时候确实挺滑稽的，为了实习你首先必须有实习经历，我已经有很大预感我会吃苦头了😭。   关于Kaggle的更新：我听说有人购买Kaggle比赛的成果，但如果你购买的是银牌，根本没什么用；金牌有点用。   虽然对大多数研究生项目的申请没有太大帮助，但对于找到自己感兴趣的研究方向，甚至未来职业规划来说，还是有帮助的。此外，不仅局限于科研，比如骑车、徒步、攀岩等，在大学阶段探索自己的兴趣对个人成长也是很有益处的。   录取的逻辑——为什么GPA如此重要   我突然意识到前面三个小节都在谈论GPA。为什么呢？因为硕士申请的逻辑实际上就是看学校背景和GPA来筛选申请者。我一直在想西交利物浦大学（XJTLU）的学校背景大概在哪里。就陆本来说，西浦的定位大概在中上211和非顶尖985之间，比如重庆大学、湖南大学，最顶尖能上到中山大学(已经很强了😭)。最强的uu，我认为可以上到华五水平的25%左右（华五就是第五, 有个跌三观的认知是在申请水硕上面，xp的各位可能比复旦的很多普通人有优势，很多复旦的申请者的结果可能都干不过上海大学）。当然，92中最顶尖的学校碰瓷不了一点，录取分数线非常高，比如苏州大学有直博斯坦福计算机专业的，我们学校氛围比较功利，不太适合这种all in的人才。而且据我观察，92中最强的人基本上是赢者通吃的，OpenCS A+/A的项目可以申到好几个，S也有一些，4月份开始幸福的纠结。但是我们学校的背景，能摸到一个A/A+其实就是很大成功了，已经非常不错了。当然，学校声誉的提升完全是因为我们使用了利物浦这个英本的pool，美国学校也不希望录取的学生全是中国的92学校，这样的逻辑在不同情况下也是合理的。比如为了男女比例平衡，斯坦福eecs录取时，对女生的门槛就稍稍降低一些。以上纯属个人猜测，不负任何责任。只是根据申请季的情况来看，我觉得我水平碰瓷不了这些92学校。   具体来说，GPA和本科背景是学校了解你的关键。绝大多数授课制研究生的招生官会认为一个好的GPA表明一个人在大学课程中有可以的学习能力，因此在研究生阶段，他应该仍然能够适应。然后这个逻辑就结束了。本科课程内容的好坏与申请人是否被培养以及学习的意义完全无关。因此，在申请时，如果面对一个相对较低的GPA，我们该如何解决呢？我想到的办法是申请成绩单中那些取得高分的课程突出自己的优势，并让低分课程的老师写推荐信解释（虽然让低分课程的老师给我写推荐信纯属巧合，我非常感谢在申请季愿意为我写推荐信的老师们）。开源节流，开源用高分课程突出优势，节流避开低分课程，并用老师的推荐信弥补。这可能并不是非常有效，但你可以看到下面两个链接中不断强调推荐信没有多大作用或者推荐信很无聊，但我注意到一个现象，推荐信被审阅的概率非常高，无论是被检查（查找问题）还是常规浏览，因此我们可以充分利用这部分内容。   但我觉得以上分析都是瞎猜，如果是一个几千人申请的大项目，这些信息是不可能被仔细阅读的。   这里转载两篇文章，不重复造轮子。   从审材料的角度谈谈研究生申请|一亩三分地研究生申请版 https://www.1point3acres.com/bbs/thread-463109-1-1.html   另外一篇在小红书，作者Shangtong Zhang，UVa的24年新的AP   Shangtong Zhang发布了一篇小红书笔记，快来看吧！ 😆 hlMl41cracI9LVC 😆 http://xhslink.com/Vcd5CH，复制本条信息，打开【小红书】App查看精彩内容！ 下面是Shangtong Zhang的个人网站: https://shangtongzhang.github.io/   为了防止上面的post被删除，我复制了所有的文本在以下的section中，如果有侵权，请务必联系我删除[notmyemailcode@gmail.com]，不胜惶恐。   去年新入职被放到了graduation admission committee里全程参与了PhD和master的录取, phD的录取感觉跟我想象的差不多，但master的录取和我想象的有一些差别很大的地方，跟大家分享一下。Disclaimer:这只是我个人经历，不见得通用。而且这个就算能generalize，也绝对只适用于master不适用于 undergraduate和PhD.  总的流程大概是一个senior的大佬出任committee chair制定一个评分标准(比如用以 的)，然后若干AP被拉进committee，是具体干活的人。大佬给每个人分配任务，每个 appication package有N个人review,最后取均分。所有的application都review完之后，系主任划一个录取的分数线，done。  重点来了，我们每个人分到了大概200个application package，需要在大概7个星期内review完。所以这个任务相当重。文书？我记得我本科申请master的时候写personal statement那叫一个精雕细琢。但你猜我能花多少时间去读PS？而且PS好坏这是个非常主观的东西。我只能去看一些关键的点(具体是什么我就不方便说了)，你英语写的再 fancy，句式再高级，故事再telling，我也没空看。我觉得你有typo我都不一定看的出来。  本科学校 vs GPA? 我一直以为本科学校会很重要，比如一个复旦的总得比蓝翔的得分高一点吧？但我问大家一个问题，印度除了IIT之外最好的学校是哪个？IIT的这些校区哪个好？伊朗最好的学校是什么？但GPA是一个很客观的number，只有地球人都知道的好学校才会有额外加分。而且学校好坏也是一个非常主观的东西。  推荐信？这个相信大家都知道，推荐人对细节的描述和跟peer的比较最重要。我见过的最搞 笑的是一个人有三个letter，但这三个letter除了签名完全一样。。 暂时只想到这些，如果大家有问题欢迎在评论里提，能回答的我会尽量回答。其实很多问题 只要换位思考一下加上下面几个fact就很容易得到答案。 (1)AP都很忙 (2)隔行如隔山  (3)越主观的判断越花费时间 (4)读Master是要交学费的  有评论提到CV和SOP哪个重要，之前忘了写了，我认为CV远远重要的多，因为从reviewer的角度看，从SOP获取信息太麻烦了，CV就简单很多。   以上是我对美国学校录取的总体认知，当然还有很多细小的点, 在下面的section中想到哪里讲到哪里, 每个subsubtitle没有明确的连续上的意义。   英国+欧洲   说到英国，感觉信息有点碎片化。学校列表、均分等信息都有，甚至细分到一些特定项目的学校列表，有些过于零散。   比如剑桥，有针对不同地区的院校列表，比如对岸，台湾的清华大学和交通大学，还有伊朗的Sharif理工大学，土耳其的Bilkent大学。这里我想提一个有趣的小插曲，有人申请时把浙江大学(zhejiang uni)写成了镇江大学(zhenjiang uni)，结果收到了拒信。这个信息是通过申请人向拒信方发邮件争辩后得到的。说到学校名称，之前KCL还是UCL在发布中国学生的背景统计时，XJTLU的全拼缺了a少了d，真是挺搞笑的。   想提一嘴ETH, 这个学校非常非常神奇和清高, 和大多数学校不一样的list操作,这个学校有一份内部的reputation网站, 按一定时间更新, 我还查到了这个网址, 但是只有ETH的在读phd, 访问学者,ap, professor可以access, 看不了一点. 这个文档会记录下, ETH的学者和各个大学的学生,phd,教职的合作后的评价,  我猜大部分应该是主观的, 正向的,我是是指留下的评价. 所以,如果你校是blank的,或者说remark的条数非常非常少,那么就很寄. 希望以后我校的uu们可以解密这一份文档.   对于欧洲，大家可能比较感兴趣？我一度对欧洲很感兴趣，但最终放弃了。除了瑞士双e和KTH比较难录，还有一些其他学校的cs是比较好申请的，比如丹麦的奥胡斯大学、瑞典的CTH、林雪平和KI（诺贝尔奖颁奖学校）、荷兰的阿姆斯特丹、代尔夫特理工、埃因霍芬理工、意大利的都灵理工、芬兰的Aalto和赫尔辛基大学。   在申请瑞典的学校时，需要注意项目的优先顺序，不是平行志愿。在申请系统上，瑞典的不同学校的优先次序会影响录取结果，简单来说，不是平行志愿。   另外，今年好像是Erasmus计划或者EIT计划的最后一年。如果不了解的话，这些计划可以让你在一年内换两到三个学校，可以获得奖学金。中期的时候, 奖学金发放得很慷慨，但考虑到搬家等问题可能会有些麻烦。   我最终放弃欧洲的申请，主要是因为受不了北欧的天气。其实我已经注册了瑞典和荷兰的系统，选好了学校，都到了最后一步，但最后还是放弃了。因为我觉得我很可能不会去，那这样做只会浪费我的精力。在申请季节，我浪费了大量无意义的精力，包括写这篇文档。   Cashcow的逻辑   匹配很重要，包括分数、GPA、申请背景等，其实缘分到了就录了,不然为什么叫抽奖呢,喜欢的都投, 万一扩招了呢。   硕士本身就是作为“cashcow”来消费的。请买得起的最绚烂的珠宝吧，即使买不起，也要试试（提交你的申请）。   大部分硕士课程的逻辑是，学校有声誉和好的课程，你进来后提升实力，然后你交学费，学校赚钱，你毕业后进入中国或者学校所在地的工业界，为学校赚取声誉，使好的企业和组织认识到这个项目/学校的优秀，更愿意招收该项目的毕业生。学校在你毕业后会利用你的人脉和就业情况作为背书，以吸引更多的“cashcow”，earn buck for research ,phd, facility, but not for U.   后置（更新，update）提交材料   在申请过程中，有些操作是后续进行的，比如雅思成绩单后交、成绩单更新等，在提交申请后，最好只多做一次。美国的申请系统，很多由外包公司制作的，有些系统每次新的提交都会导致之前所有材料的重复。我认为你可以将其理解为数组的复制，当数组已满时，添加一个新元素会复制原数组再寻找一个新地址来存储。想象一下招生团队在阅读四五份重复材料时的表情吧。推荐信应该可以后交，没问题。虽然也有评论表示，这种更新不会导致材料重复，但很多学校也声明了更新后的材料基本不会被考虑。因此，在这方面我建议最多只更新一次，包括写作样本、成绩单、语言材料等。不过我自己也更新了好几次然后也收到很多学校中的梦校录取了   好像这个section有点乱，我也搞不太清楚, 不懂了,搞不明白。   申请投递的时机   时机的重要性,说实话我在申请季开始之前完全没意识到, 后来才发现这个的重要性就比gpa差一点点 , 时机非常重要。   举个例子，西北的CE专业较早投递会相对容易些，越晚越难。   再比如，NYU一开始9月要求GRE成绩，但后来发现不太好招到学生，一堆其他比NYU还好的项目和学校都不需要GRE。   NYU的雅思要求相反，我12月申请时豁免了雅思，1月我offer都下了, 但朋友1月卡DDL提交申请时，NYU因为申请量过大而取消了豁免语言。另一个例子是NEU的不同校区，基本上是先到先得，晚了就要转校区了。当然，也有例外，比如NYU的CE项目在DDL后仍有人被录取。   时机还包括申请的项目新旧, 相当于打新, 你要是上车了一个一开始bar低,后来水涨船高的项目,那就很赚.   时机还与历史经验有关，利用上一届的案例来定位自己。这种做法通常很好，因为基本上八九不离十，但也不是十全十美的。项目本身会有细微的变化, 比如rice mcs这个项目, 在22fall 时候gre required, 但是在23fall 改成了highly  recommend, 然后23fall拒绝了所有没有提交gre成绩的人. 类似做法在23fall还有brown的cs, which在24fall就不这样了.  本人超级后悔没申请rice mcs…这里的时机指的是参考历史经验，但如果真的对某个项目很感兴趣，一定要申请，不要因为觉得会浪费申请费而放弃。   投递数量策略——海投   两个字, 海投. 甚至是多国家投, 多档次投, 多rolling投. 投Dream school, 也投认真研究后的保底   在上一个section我有提到, 申请的时间非常重要, 申请2-3个项目, 一旦这个这几个项目今年的招生计划, 对学生的bg品味有较大幅度的变化, 那你就寄了, 所以使用海投来规避风险是较好的策略, 我之前在xhs看到过一个申请季推荐信的神, 是一个211本国内研一的bg, 在23fall申请季申请了40+个项目, 真牛逼, 我是说推荐信数量. 我记得最后去向是uw pmp.   不吝惜申请费用   多花这个钱, 我就踩坑了, 想着这个肯定申请不上,然后就扩招了, 申请赌徒应该付出全部的钱买全部的筹码, 给大家建议是应申尽申, yale harvard等，不妨多花钱提高申请几率。当然，申请费用总计1.5-2万元人民币左右（我的申请费用应该在7000多人民币），申请20所学校应该就够了。如果觉得心疼申请费，可以关注学校的申请活动，有时会提供免费申请码。还可以考虑加入一些美国的学术组织，有些组织的会费大约20美元, 就可以免除多个学校的申请费用。   硕士(MSc)与工程硕士(Meng)   在申请季节，有些人对这两个学位的区别很在意，尤其是在想继续申请博士项目时。但我个人认为区别并不大，更重要的是关注项目本身。项目之间的差异才是更值得考虑的因素。对了在UK, 这两个确实有区别, meng有看到ucl和Bristol本科可以直升硕士发一个meng学位. 但对于外校的本科生来说, 卖的一般是MSc学位, 这点确实有一定区别，国内就业这个点几乎不关注。另外，还有一个有趣的news，剑桥大学本科毕业后5年或7年（具体记不清了），学校会直接授予一个艺术硕士学位，这是不是很有趣呢？   论坛及社交媒体   各种论坛和社交媒体(xhs/地/知乎/留学圈)都是很有用的平台，但要善于筛选对自己有用的信息，尤其是不要被一些过于优秀的背景所影响。   项目的招生规模   之前很少有人在申请时考虑一个项目的招生规模，但我觉得这是相当重要的因素，它反映了学校的培养态度。是真正用心培养学生，还是只当他们是cashcow？大班授课的体验我们已经有所了解，一个教授面对200个学生，讲台上游走，学生们人山人海一般。我曾看过耶鲁大学的一个社会学公开课，每个学生坐在圆桌上，教室里不超过10个学生，教授在中间讲课。我想这是我一辈子都无法体验的了，但这反映了一个问题，学校是如何对待学生的。许多质量好的项目通常班级规模较小，10人以下算是小规模，20-60人左右是正常规模. 但是近年来有, 200人甚至400人以上的项目，虽然这些项目和学校也很好，但我个人不太喜欢。读完两年书，同学名字都认不全，这不太像是来上学的感觉。我交了学费，教授你至少也该用心点吧？虽然学费不是直接给你的，但是我交学费是在为学校的建设和研究项目做贡献。虽然上课本身并不是最重要的，但是我觉得至少应该提供一个合适的学习环境。   一些小建议   在申请的项目都ddl之前, 不要交流各自申请的项目. 保护自己也不影响他人. 你自己要是90分,在ddl之前, 和一个70分的人去说我申了什么什么项目, 这不是给人上压力吗…项目很多都是同校竞争, 同校同专业竞争, 所以大家都安全一点呗. 但是在ddl之后交流, 就不会出现这个问题, 原来大家眼光一样,我感觉还挺惺惺相惜的. 人总是在美化自己不能改变的事实, 那些已经过去的东西. 其实就算这样都发现很多撞申请的, 你应该不想进了一个项目最后发现可以开一个50个人的西浦校友会吧? 笑死, 这种情况比较少, 但是某个项目冲到人多, 你有可能真的会被ab掉.   推荐信   推荐信至关重要，越多越好。早期建立联系，及早联络。如果自己撰写推荐信，注意使用不同的IP和设备，换不同的作者身份。目前已知，纽约大学会检查此类信息。利物浦大学的计算机科学和电子工程项目对推荐信数量要求越来越严格，请多向相关老师寻求帮助。若推荐信不足，仍然建议提交一些相对一般的申请，因为明尼苏达大学、德克萨斯A&amp;M大学和纽约大学等学校会审查推荐信不足的申请。敢于尝试的话，可以考虑一些不要求推荐信或允许手动提交推荐信的项目，但这并不被推荐，灰色手段不建议使用，但有时不得已而为之…   小补: 学长的post   由于已被删除，我也不愿透露他人信息，我对这篇文章的印象主要包括以下三点：      从3.7到3.8的GPA提升, 对申请的帮助是巨大的,(补充, 比如3.79和3.81是两个水平)。   强大的软实力对许多项目而言相当重要（学长bg和水平我真的流口水🤤）。   在录取时，许多项目存在同校竞争的情况（我补充，中外合作项目的竞争，英国本科的竞争，甚至同一所学校的竞争）。   DKU本科 2023年秋季的一个申请总结post，因为我不认识他，我直接写了，而且也删除了, 反正很难对应到一个具体的人。      作者大概描述了自己辉煌的本科经历和研究经历，主要集中在金融领域（这里我真想说，DKU的资源确实独特，我顺着论文进去，惊讶地发现有10多个人均参与研究，老师甚至在英国创办了小公司，带领全组发表论文，把我这个小年轻看得一愣一愣的）不过这个po主在这里干了很多工作, 没话说, 有机会人也要中用啊, 我看到这个公司里面一半的人以上都是数据标注,数据处理   一段实习经历似乎是家里安排在本地银行分行。   后来的实习经历显然更为出色，水平和本科声誉在线。   然后就是接近于大满贯大申请结果, 我依稀记得是, ETH, cambridge, 应该有牛津, 不知道有没有duke ece了,应该有, 这个基本是dku本科水平稍微好一点的保底, 最后去向是西北 msai, yyds。   天气   好吧我又来写了, 这在选校的时候还是要考虑一下, 我在英国读了两年, 是真的浑身难受, 整个人都不好了,感觉整个心情和心态都变了很多   DMT   快到最后了, 简单的说一下我的专业DMT, 这个专业基本上就是一个CST, 95%相同, 但是更加不合理一点, 到了利物浦以后专业名字变成了CSEE(dmt pathway), OK我可以接受, title说完了. 说说课设, 我其实觉得如果2+的话, DMT的课程设置比CST好一些, 好在压力比CST小一些, 轻松一些. 然后DMT课程的整体设计我的评价是不知道在干什么, ee也想教, cs也想教, 还有一个虚幻的游戏track. 往年dmt的title不能吸引到大一的童鞋, 加上不能2+申请的出路比较惨淡(但是有中过Upenn cggt好像也不能说惨淡), 今年20届莫名其妙吸引到一批人,其实出路还挺好看的, 认识的人里面有Brown CS, Upenn EE, ic bme, USC CS(game dev), ic Analogue and Digital Integrated Circuit Design MSc, nu ce, Cornelltech ece meng, Duke ece. 能在dmt成绩好的话, 我觉得和cst无二, 甚至更好, 当然两个项目的课设我真是无力吐槽, cs的track没os和net, 甚至连选修课的option也无. 我整个本科阶段选修课的数量为…2节课,  year3上c++, xp大一和利物浦year2的课有大量重复的设计, 还有不知道在干什么的强行塞入的信号处理/系统, cs没什么project无数的report, 说说做游戏year2的intro game是必修, 然后就没有了, 再year3的 adv game是不可以选的… 吐槽起来三天三夜也讲不完, 但是dmt录取的门槛比cst低, 加上我个人觉得整体上dmt课程设计稍微比cst好那么一点(50笑百), 更靠近ai一点, cst没进去dmt也还不错, 只比cst输名字, 反正就这样吧.   再谈英国录取?   英国的学校, 什么项目录取了多少人,有多少人申请, 甚至可以看到按种族区分的报告. 这些可以在这个 whatdotheyknow 网站上找到. 但是学校是ucl, lse,ic, 牛剑,曼大, 爱丁堡这些, 因为中介只对这些学校感兴趣. 我觉得这个网站有点像论坛，很多都是同一个中国的中介(好像叫kiki)在网站上发问题，要求学校公布项目的录取数据。由于各种原因，学校一定会回复一个像样的报告，但是有些数据是模糊处理的,每个人都可以access,然后在xhs和各种地方就传开了。需要注意的是，申请量和录取人数的对照，不能客观反映项目的录取难度，但如果申请量很大，比如3000+只录取了200+人，那么项目确实是比较难的。我举一个反例，像剑桥大学的pure math part iii作为世界上最著名的硕士项目，申请量实际上并不是非常庞大，每年大约500到700人，尽管现在帝国昔日辉煌已经过去，但是这个项目吸引的申请者基本上都是来自美国本科前20中排名靠前的学校、或者伦敦大学学院/帝国理工学院/华威大学排名前3%的学生？其他的英国本科基本都需要排名第一或第二。我甚至看到过哈佛本科生来申请这个项目，还有申请成功了普林斯顿大学的数学博士然后推迟一年来入读这个项目的。之前30-40年前的part iii的毕业生基本上都是教授，总之很多有学术抱负的数学人才都在申请吧。所以申请这个项目的基本上都是数学排名第一或第二的本校学生，很多都是排名第一或第二的，你说难不难吧。今年我看到UIC和XJTLU都有学生申请到part iii纯数，真的很厉害。据我不负责任的猜测，应该是中外合办第一次接触到part iii纯数。   选校(恰饭)   这个section的大部分内容被我删除了，作为有偿分享的部分。价格为303人民币（which = 我在北京办签证时候的第一顿烤肉的费用），可以在付款完成之后，将支付记录和名字发送至以下邮箱：notmyemailcode@gmail.com，使用学校邮箱(@xjtlu.student.cn/@liverpool.ac.uk)。提供的信息越详细越好（名字、专业、账号名字、付款时间）。我会尽量在48小时内发送文档。我只是想看看到底能不能收到钱，嘿嘿，玩一下。   但是前景(钱景)貌似比较悲观😭.   另外这个section直接分享出来容易被人骂, 申请季已经被人上嘴脸了, 类似于“这个项目很nb, 你为什么这么说它”, “某某项目明明不错, 你为什么这么评价”. 我想说这些评价本来就很主观应该没有什么对错. 也没有说某个学校的某个项目就比某个学校的某个项目好, bar高的项目也不是肯定就比bar低的项目好, 有很多客观因素要考虑, 比如费用, 天气, 生活的城市, 就业的期望, 课程项目的压力…等等 但是选校恰恰是bar为前提的, 不然没有意义. 所以多种原因吧, 我最后决定不公开共享了, 看看能不能恰到饭和避免引起争议.         如果购买你会得到什么? 你只会得到一个我编辑的PDF，其中包含对许多项目的主观评价和我自己对一些项目bar的认知 (1w+字)。其实有接近60%的内容来自openCS, 不是100%完全是因为openCS上没有很多ee,ce,ece的项目, 不保证绝对正确，但是是我申请季的一连贯感受和记录。其中包含了2个2025年秋季值得打新的项目和一个录取难度较低的项目。      我觉得这个list/pdf 卖303人民币挺贵的。或者按照某些人的话说就是太不要脸了, 反正你可以理解成我不太想直接分享, 这样?   但是总之, 选校和选项目是申请最重要的步骤, 也是我花费最多时间的步骤,因为这其实是申请季可以唯一应该稍微认真的地方, 因为GPA已经是定数了. 另外其实你本科GPA(3.0以下)完全寄了其实也有办法拯救, 花一年时间可以和西浦cs的3.8+申请结果差不多. 但是选校list还是自己总结整理比较靠谱，选一些自己喜欢的项目，和申请到后肯定会去的保底学校，这样就差不多了。   anyway，想免费拿list也OK。   使用学校邮箱(@xjtlu.student.cn/@liverpool.ac.uk)发送邮件到notmyemailcode@gmail.com，简单阐述一下如下主题：   自己准备diy/已经做了什么   好尬…我希望我的选校list可以帮助真正有用的人，而不是一边报了机构一边还想稳一手到处看看的uu，申到了最后又被拿去发一些夸张的录取广告，吸引一波又一波的新韭菜们。然后, 其实我在后记中放了大量的链接，很有价值。   anyway，我真的觉得我其实挺菜的。   所有的文本我会在2025年1月15日重新完整更新发在这个page上，如果我还记得的话…   可能有些人有咨询的需求（笑死，真的有吗），但是我暑假比较忙，就不恰这个钱了。但是可以用email沟通聊上几嘴。另外我的小红书 id是454336362。   提醒   如果你报中介的时候发现了如下项目，   UPenn ee、哥大ee、NYU ce、UW ee pmp、UCL Scientific and Data Intensive Computing MSc，其实还有很多但是以上这几个太著名了  还有neu is（几乎是有认知的美国学校的stem研究生项目bar的鞋底）  那么我只能说，你的大几万中介费有很大可能性要打水漂了，因为这些项目对GPA符合要求的西浦选手几乎是来者不拒。在往年，往往年有不断尝试申请和ad的很大数量的cases。就录取难度来说，在保证GPA的前提下申请这些项目难度不大的（虽然有点太夸张了，但是夸张点说，文书不要骂学校就行）。所以如果你报了中介，可以在申请计划上删除这些学校然后自己申请得了，因为这些项目是中介赚钱的保底 :) 但是，这些项目的质量，我感觉都还是很不错的。   另外关于offer们，我觉得，收到太多平级offer可能没什么意义，比如说，收到3个匹配，或者说3个保底. 比较好的申请结果是一个冲刺（彩票），一个匹配一个保底，所以选校的梯度比较重要，很多申请季认识的朋友除了抱怨中介useless之外，都有点后悔没有申请某某彩票项目. 其实我也是，有些项目投了不就是买个念想，不要在10年以后说“要是当年表白就好了~”，乐。   什么是好项目   看美本在申请什么，去美本在去的项目，看大家是如何拿脚投票就行。也注意自己要什么，有的人注重title，有的人注重费用，有的人注重课程设计，都没什么不好的。就其实大学，还是要读出自己的想法上的路子，GPA这种东西申请完废纸一张，西浦GPA4.0社会认可度不如北大2.0一根毛。找工作也不看GPA。而且GPA也不代表知识水平高，考完一年我早忘完了学了什么，大厂也不会因为你GPA高觉得你nb…真的完全没用，导致我现在特别慌。而且申请结束后, 其实成绩已经没有意义了, 相信我真的没有意义了.  到最后，我想到了之前在大二时候看到的《上海交通大学生存指南》中的句子，作者是08年的侯晓迪，是上交低绩点直博Caltech的真神（我一直想不明白为什么有这么神的人，印象最深的一句话是“熬夜最难的是前72小时.”）。不是文章开头的“中国本科教育早已崩溃…”，而是作者在谈博士申请的时候，说“简单的话就读一个硕吧，只要出钱就好”。无限感慨，作者当时轻描淡写的一笔，到现在对我来说还挺难的，在无限担心去gt挂科的各种后果…本人成绩和姿势水平一般，而且记忆力也一般（但是不知道为什么这种申请时候看到的细碎的消息我可以记住然后搜出链接）。   4月25日 2024年 记   我写的时候一直骂自己，写这种东西干什么，我自己的申请季已经结束了，这种文本的意义对我来说是无效的，可能还要被申请到一些项目的人骂，说“你凭什么这么说这个项目，这个项目挺好的，你配申请到么” 云云。我自己想的是，当我回想半年前，当我开始diy的时候，我是多么希望有一篇这样的东西（但是我现在知道为什么没有了，又累又对自己没用，吃力不讨好），给xjtlu这种奇怪的本科定定位，我打扰了好多个学长学姐，问出来的消息虽然对我很有帮助, 但是都非常非常零碎。现在我就是想把东西都一股脑的写下来，也许很多都是错的，但是我本身是无所谓，因为我的申请季已经结束了，我拿我写fyp的时间写1w+字（没想到现在2w+了，过3w了，但是会检查删掉敏感内容）的东西不是找人来骂我的，所以希望骂我的人少点。 加上我成绩也没有很好，也不配给各位大佬指指点，申请完研究生也远远不代表找工作/申博的成功，而且我个人越来越感觉项目和项目之间的差距没申请前想象的这么大，其实还是人和人之间的差距，因为这个差距实在是太大了， ————删掉了———— 我也发现了好多bg超强和水平的学长学姐…仰望！也非常非常感谢在留学圈加的各位学长学姐给我无私帮助和给我一些建议。   final….   其实我对以后的发展也很迷茫, 西浦给我的高峰, 对我来说就是出申请结果的时候, 我也明白自己平平无奇, 利物浦/西浦的本科毕业证=破纸一张, GPA的作用对找工作可能有个那么1%的作用吧哈哈哈, 而且也有点不想学cs了, 申请了这么多ece, cs, ce也是顺着惯性再走, 研究生上课再难再硬, 对找到一个适合的工作帮助有限甚至是负分. 这也解释了很多master项目的偏水的原因, 因为这些是对职业发展没有帮助的东西, master院校的目的和你的目的都很明确… 说实话, 反正现状和我预想的差距有点大. 但是就目前的现状来看, 我学习的大部分阶段都好幸运, 申请季也超级顺利(补充,美签也过了,yeah!!!), 也认识了愿意帮助我的好多好多好多陌生朋友, 希望剩下的日子也能侥幸和幸运下去~   这下真的到最后了, 也祝大家都有美好的前程…  于 Apr. 27th 2024, Liverpool, Merseyside(写这句话的时间)   好像埋了一个小坑, 没有写如何写ps, cv和sop, 如果这个文章有热度的话可以补一补, 估计又是几千字,有点不想写这个section…会让大家又发现我是真的菜.   后记   放一些可能有帮助的link, 和当reference用, 我把这些link放在我了我主页的collection的部分中点击跳转   刘未鹏:7年在南大生活 https://mindhacks.cn/2009/05/17/seven-years-in-nju/ 胡津铭:硕士毕业半年的茫茫社招路 https://conanhujinming.github.io/post/thoughts_of_hunting_jobs/ 胡津铭:高效学习的几个技巧 https://conanhujinming.github.io/post/the_art_of_learning/ Lvmin Zhang:苏大直博斯坦福,个人主页 https://lllyasviel.github.io/Style2PaintsResearch/lvmin 2019南大商科转CS申请总结(绷不住,cs专业课比我半科班还多) https://github.com/Jason003/19fall-CS-Application-Conclusion Y-H(作者对岸人,从Upenn科学计算转学GT CSE):聊聊CSE in Gatech &amp; Others https://yuho-yhhsieh.medium.com/%E8%81%8A%E8%81%8Acse-in-gatech-others-40ec3a519089 經驗分享 2024 Fall 美國 CS 碩士申請心得 CMU MSAII/UCSD CS75 https://howard0100000.medium.com/2024-fall-%E7%BE%8E%E5%9C%8B-cs-%E7%A2%A9%E5%A3%AB%E7%94%B3%E8%AB%8B%E5%BF%83%E5%BE%97-a6cb08e2817a 北大:出国申请总结（pure Computer Science） https://github.com/ZhenbangYou/University-Application--Computer-Science-Graduates-  Open CS, 但是注意是陆本的定位, 主要关注在于项目的录取的bar而不是项目的具体质量  另外,各位可以看看浙大,华科历年的飞跃手册,里面一些对项目的评价总结得很全面, 虽然bar已经是物是人非了     上海交通大学生存手册_新版 https://survivesjtu.gitbook.io/survivesjtumanual 上海交通大学生存手册_08年_旧版(历久弥新), 曾经推荐给小巴们, 反响不大hh, 我一厢情愿了 http://www.houxiaodi.com/assets/misc/manual.pdf Randy Pausch 最后一课: Achieving Your Childhood Dreams https://www.youtube.com/watch?v=ji5_MqicxSo CARRIE ANNE: Crash Course Computer Science(我大三才看到, 对了解计算机学科非常有帮助 https://www.bilibili.com/video/BV1EW411u7th/?share_source=copy_web&amp;vd_source=827dfb109fc21cf17537658558bd420a 小众宝藏项目：Cornell医学院Biostats &amp; Data Science，体验/经验/就业情况https://www.1point3acres.com/bbs/thread-730072-1-1.html [申请总结] [长篇申请经验分享] 【转码之路——我的22 Fall申请季总结】（万字长文，内含大量干货）                                      https://www.1point3acres.com/bbs/thread-892753-1-1.html 如何选择美国CS Master项目？(2018年) https://zhuanlan.zhihu.com/p/19908606                                              Finally, 如果你觉得这篇文章对你有帮助的话, 感谢支持,下面的支付button适合任何国际credit/debit card.     声明   我尽量去除了敏感信息, 如果还有希望删除的内容, 请使用邮件提示我删除   申请总结是根据我本人兴趣自发撰写完成，版权属于我本人。在本总结撰写过程中, 我尽量客观, 没有接受其他任何组织任何形式的支持。未经我许可，任何组织或个人不得违反相应的版权条例抄袭、转载、摘编、修改内容；不得将本文章用于商业目的；不得对本文章原意进行曲解、修改和未授权的大范围分发。  本文章并不规定任何明确的行动建议，只做简单的推荐，因此作者不承担由此产生的衍生责任。  本文章作者不能保证手册内容中没有对其他组织的误解和偏见,或者是潜在的误解和偏见。本文章内容的正确性并没有经过权威审查，本文章作者无法保证内容,方法始终有效。本文章作者亦无力确认是否违反了读者所在地的各种法规，请参照当地行政规定。如有违反，请您停止阅读并立即销毁本文章的任何副本。对于未经授权传播本文章而造成的各种问题，本文章作者概不负责。本文章作者无法确定文章内容是否会对读者身心健康产生不良影响。如果您未满18岁，或因阅读本文章而产生不适，请立即停止阅读并咨询心理医生。  本文章欢迎接受您的指教。 如果您对文章内容有任何问题、或建议, 请联络我：  notmyemailcode@gmail.com(真的是我邮箱)  我并不保证回复每一封建议邮件，但是我会认真接受并思考您的意见, 并在后续md内容中做出相应的改进和更新。   ","categories": [],
        "tags": [],
        "url": "/master-apply/",
        "teaser": null
      },{
        "title": "Notes for ‘How To Read MTF Curves’ article",
        "excerpt":"文章翻译, 阅读, 解读MTF曲线, 笔记总结  Preface   The following context and material are sourced from Dr. H.H. Nasse’s articles.  Many many thx for sharing and explain MTF in the preview articles.  However, I still had no understanding at all when I read those articles during my first year of bachelor studies. I will attempt to write this article in my own words without using any grammar or AI tools.  I have to say in some places, I will use some “direct copy” sentences. I don’t consider this as a form of academic plagiarism, as I am writing this post for learning in photography as an enthusiast.   I listed the all used article below. Again, I will use some images and words directly without any citations. If you have any concerns about this post, PLZ contact me at (notmyemailcode@gmail.com) for specific sections throughout the entire article. I will do it for you ASAP.   [1]Intro. (ZEISS page)   https://lenspire.zeiss.com/photo/en/article/measuring-lenses-objectively-why-do-we-need-mtf-curves-by-dr-hubert-nasse-part-1   [2]How to Read MTF Curves(December 2008)   http://lenspire.zeiss.com/photo/app/uploads/2018/04/Article-MTF-2008-EN.pdf   [3]How to read MTF curves? Part II(March 2009)   https://lenspire.zeiss.com/photo/app/uploads/2018/04/CLN_MTF_Kurven_2_en.pdf   [4] 如何閱讀MTF(一), Weifu Lin 林渭富 如何閱讀mtf-f85a60cf59c   (以上引用都没有被作者授权, 如有侵权, 本人会尽快删除, 文章承认前置的引用的文章的所有贡献.  本文章没有传播价值和商业价值, 是我看了引用的文章的笔记, 理解上的总结与整理 )   The main purpose for this article is helping me in realizing how designers made an excellent lens in the past and to understand which are favorable features for a good lens. And Iet me select suitable apertures not only by weather and sun   I  wanna finish this work in 2 days (2024.06.17-2024.06.18).  太难了, 最后看了一个礼拜才看了一半不到.   The final date for this article is 7.6   淦, 还是用中文写吧.   START here   photographers want to take a very natural-looking picture of a subject, the lens should be sharp, which means that the lens will reflect the correct image of the view. As you know, the light line can gather in a light point on the frame plane. The perfect lens needs to show this “point” in the image correctly, but the truth is that the lens cannot do that on every surface. In the article, the Dr. H.H. Nasse give the example pic below, I attached this image below.      原始圖片來源 &amp; Credit：Hubert H. Nasse, How to Read MTF Curves, page 6, 《LENSPIRE》   this pic indicates 8 satuations in a size comparison, which all input a small white square light, but totally output different light results in cmos(tip: pic7 should be the perfect example)   调制传递（Modulation Transfer）   Sinusoidal brightness distribution   下面是文章中第一次出现的需要解释的图      原始圖片來源 &amp; Credit：Hubert H. Nasse, How to Read MTF Curves, page 6, 《LENSPIRE》 。   在原文中, 作者提到 Since we are primarily interested in how extended objects are imaged, objects which, unlike stars, comprise an infinite number of points, we must find another way to quantitatively describe the image quality. 于是我们使用sinusoidal brightness distribution来量化. 正弦波是一个连续的、周期性的波形，它在数学上非常容易描述和分析.   如果把原始的光源场景想象成一个简单的正弦函数的话(sinusoidal brightness distribution是明亮和黑暗条纹的图案), 那么在比如说光线在经过镜头以后, 如果成像系统是完美的，我们应该得到一个清晰的、与原始正弦波相同的图像。也可以说, 使用正弦图像我可以得到一个稳定的结果进行分析. 这里的稳定不是指成像质量.   但是成像系统总是存在一些缺陷，玻璃的折射, 空气灰尘, 传感器的噪声. 实际得到的图像正弦波会与原始的场景的正弦波有所不同。 但是Several of its properties also remain stable or at least have nothing to do with imaging quality: The direction of the stripes does not change and the frequency – the number of stripes per unit length – only changes according to the imaging scale.   由于成像系统的缺陷, 光线不会完美地聚焦在它应该聚焦的地方。这就导致了所谓的“点扩散”. 也就是说, 某光线不仅照亮了应该照亮的区域, 也让周围应该是暗的区域发亮了.  这种光线的扩散效应改变了明暗条纹之间的亮度差异，使得图像的对比度降低。   回到需要解释的图,      黑色曲线代表了实际风景的正弦条纹的亮度分布(which means 原始的一个简单明暗分布), 而空心圆组成的image线条是实际成像后的结果图, 可以认为是照片的实际效果, 这里埋一个伏笔.   然后是红色点和红色线, 蓝色点和蓝色线, 这是一开始我没有理解的部分, 我以为有什么特殊含义, 但是, 其实这组Point Spread Profile说明了有一个点光源分别在成像的时候, 落在了某个地方对原始光线造成了影响, 点作为亮度最高的部分, 下面的曲线则代表了光源的Profile, 很好理解. 从最亮的地方, 逐渐减弱,这样.   于是定义来了,   1⃣️ the difference between bright and dark is referred to as “contrast”.   2⃣️ the difference between maximum and minimum for all sinusoidal, periodically changing quantities is called “modulation.”   那么这两个相似表述的区别是什么, GPT说, 对比度通常通过比较图像中最亮和最暗部分的亮度来衡量。调制通过信号的最大值和最小值的差异来衡量，反映信号的幅度变化。OK还是没理解, 回到图.   如果我们使用对比度的相关概念来描述, 在一张高对比度的照片中，太阳的亮光和树影的黑暗之间的差异非常明显。而使用调制的逻辑是, 在一个调制较高的正弦波信号中，波峰的高度和波谷的深度之间的差异非常大。   我感觉这里光学的modulation和信号处理的modulation的差距有点大, 虽然学的不精, 但是依稀记得是改变载波信号的幅度/频率/相位来传递信息(AM,FM,PM), 好的按下不表.   在这里之前的伏笔来了, “对比度”指图像中明暗区域之间的差异, 但是在事实上, 是我们判断镜头分辨率的关键.   我们引出了   调制传递函数（MTF）   用来评估光学系统将物体上的调制传递到图像中的能力。通过比较图像的调制(图像)与物体的调制(图像)来计算，结果是一个介于0和1（或0%到100%）之间的数值。   在这里文章给出了一个列子,有点难理解的, The photographer is used to expressing bright-dark differences in aperture stops, which is also very reasonable as the perception of our eyes follows such logarithmic scales. But, what, for example, does a modulation transfer of 50% mean if our pattern of stripes consists of a difference of 6 aperture stops between the brightest and darkest points, i.e. a brightness ratio of $1 : 2^6  = 1 : 64 $ ? Is the difference in the image 3 aperture stops or $1:32$, which would correspond to 5 aperture stops? 神来一笔, 我们如何理解 modulation transfer of 50%, 调制传递率（Modulation Transfer）的50%并不是指整体画面会变暗50%。 Both would be wrong. In reality, we would then still have approximately 1.5 aperture stops in the above-mentioned case.   给出Contrast计算的公式 \\(\\text{Contrast} = \\frac{\\text{Maximum} - \\text{Minimum}}{\\text{Maximum} + \\text{Minimum}}\\) 我觉得还是挺容易理解的公式, 带入Contrast值=50%, 然后文章给出了例子, 没看懂从哪里来的, Therefore, in our example, the contrast of the object is 63 divided by 65, or approx. 哦, 就是突然给了两个值, Maximun-Minmun=63, Maximun+Minmun=65, 再63÷65≈0.97. 作为经过调制传递率为50%的成像，我的理解是满足上面那个公式上的定义, 然后MTF=50% 开始定义, 这时候文章下面有一个图我去比较了, 结果又理解错了. 正常的步骤是直接得出0.97的一半, 大约是0.48, 然后 (x-1)/(x+1)=0.48得到我们的估算值为 x≈2.846, 所以我们的档位从6掉到了2.846, 光量从64掉到了7.19004101289. 我在这里还是没有理解档位的问题…见下图      圖３：將反差對比的定義以正弦波圖形表示，兩者比値與測量位置情報共同構成MTF曲線。本圖經過翻譯及重繪。原始圖片來源 &amp; Credit：戶村賢一、〈MTF：MTF曲線から読み取るレンズ特性の正体〉、page 128、《ライカ通信》 Vol.1, 2000年4月。      原始圖片來源 &amp; Credit：Hubert H. Nasse, How to Read MTF Curves, page 6, 《LENSPIRE》 。   为什么这么像PN结放大…   我感觉这个地方, 一开始也有理解错的地方, 我的疑惑点有这些      MTF在图像中, 在曲线上是一个固定的参数, 好像是不会变化的, 但是在调整光圈档位的时候, 传感器接收到的maximum和minimum的光会减少, 我感觉这个在光圈变化后会变化, 但是MTF没有变.   如果研究的目标是Object, 那我感觉光圈变化不会影响MTF啊, 因为环境的maximum和minimum的光量不会变啊   对档位的理解有点奇怪, 0,1,2,3,4,5档, 如果使用$2^n$ 来理解的话, 可能可以想通, 我之前一直没搞明白, 就是越调档, 光量越小, 结果更加好? 反正我觉得有点奇怪.   这里档位, 有个点没有明白就是比如, object contract有10档, image contact只有最高有6档, 那么object contract的10档中的第6档和image contact的最高档第6档的光照亮度强度是一样的么   横坐标从1开始的, 有点没理解   OK我觉得这里的混淆, 主要是由于参照坐标系的混乱造成的.   那么这个图怎么看呢, 比如取最高点(MTF=97%进入平缓发展的点), 取(10,6)点为例, Object Contrast (Aperture Stops) = 10, Image Contrast (Aperture Stops) = 6, 使用contact的定义, 在 $2^n$带入6和10, 得到64和1024(最高亮度值), 他们的最低值都是1, 所以 \\(\\text{Object Contrast} = \\frac{L_{\\text{max, object}} - L_{\\text{min, object}}}{L_{\\text{max, object}} + L_{\\text{min, object}}} = \\frac{1024 - 1}{1024 + 1} = \\frac{1023}{1025} \\approx 0.9976\\) 再得 \\(\\text{Image Contrast} = \\frac{L_{\\text{max, image}} - L_{\\text{min, image}}}{L_{\\text{max, image}} + L_{\\text{min, image}}} = \\frac{64 - 1}{64 + 1} = \\frac{63}{65} \\approx 0.9692\\) 这里引出/使用计算mtf的公式 \\(\\text{MTF} = \\frac{\\text{Image Contrast}}{\\text{Object Contrast}} = \\frac{0.9692}{0.9976} \\approx 0.97153167602\\) 下面是作者对于这个图的简单总结, 一开始没懂怎么来的, 感觉还挺难理解的.   我们可以从三个方面来理解 MTF 曲线的特性：      高 MTF 值的小差异在高物体对比度下特别显著：            当物体对比度很高时（例如光圈档位为 9 或 10），MTF 曲线的高值（例如 90% 或 97%）之间的细微差异对图像质量有很大影响。即使 MTF 仅从 90% 增加到 97%，在高对比度的物体下，这种小的差异也能显著提高图像的对比度。                  弱的色调变化（小于一个光圈档位）不需要高 MTF 值：            当物体对比度较低（例如低于一个光圈档位时），高于 70-80% 的 MTF 值差异几乎没有实际意义。这意味着在低对比度场景中，即使 MTF 下降到 70-80%，也不会对图像质量造成明显影响。                  非常低的 MTF 值下，物体对比度的高低几乎没有影响：            当 MTF 值非常低（例如低于 20%），无论物体的对比度多高，图像的对比度总是很低。这表明系统在低 MTF 下对比度还原能力很差，导致图像质量大幅下降。                  OK, 在看了这三个特征总结之后,  object光圈档位调整的含义和具体的光圈档位感觉可以澄清, 就是不同的光量, 如果两个contract都是处在Aperture stop=6的情况下的话, 他们的光量都是$2^6=64$, 也就是说是一样的. 我一直有一个错误的想法, 就是把一个环境和一个传感器上的光均匀切割, 然后分成不同的等份作为不同档位的错误理解.   调制传递函数（MTF）表示成像系统在不同空间频率下传递对比度的能力,   这个位置的小节, 我觉得我从这段文本得到的新的认知是, 我在之前从来不知道,对比度, 明暗,对清晰度的影响, 或者说对比度在直接控制清晰度? 感觉这个说法有问题, OK, 在对岸的一个作者的一篇文章上找到了答案.   下面小结的内容来自Weifu Lin在Medium平台上的文章, 链接在 如何閱讀MTF(一) , 是作者结合蔡司的这篇文章和日本的一个作者的文章的翻译. 有两个图非常非常好, 指明了contract和Resolution的区别.      繪圖：Weifu Lin   这里的内容是直接引用的[5]. 兩種不同設計取向的鏡頭的比較。鏡頭B的解像力較高，但實際拍攝時，鏡頭A會給觀賞者「更銳利」的觀感。箭號位置所指的虛線，是人眼能分辨細節的最低臨界點。本圖經過翻譯、修訂以及重繪。原始圖片來源 &amp; Credit：戶村賢一、〈MTF：MTF曲線から読み取るレンズ特性の正体〉、page 129、《ライカ通信》 Vol.1, 2000年4月。      到这一步的时候, 我有点没看懂…   Modulation transfer function, resolving power   It is obvious that one single stripe pattern is not sufficient to characterize the quality of a lens. A very coarse pattern with large separations between bright and dark stripes could, of course, also be imaged well by a lens with a relatively large point spread function. If we decrease the separation between the stripes, however, so that the separation between bright and dark approaches the size of the point spread, then a lot of light from the bright zone is radiated into the darker zones of the pattern and the image contrast becomes noticeably lower. 我觉得可以理解成原来黑白粗线条的object contract比较高, 因为每个亮区和暗区之间的光线干扰较少. 但是在原本光照环境没有改变的情况下, 一些细小的线条远看是灰色, 导致亮区变暗，暗区变亮, 这会造成对比度的降低这样. 有一个形象的解释是, 写毛笔字, 尺寸比较大, 气势磅礴的字体可以使用大的毛笔, 但是涓涓小楷, 甚至在鼻烟壶里面写字, 这些艺术家为我需要更精细的书写工具. 菜刀如何雕刻核舟记?   为了比较不同精细度的条纹图案来研究镜头的成像能力(其实就是复杂环境)，我们使用调制传递函数（MTF）来量化. 而且, 为了研究镜头如何成像不同精细度的条纹图案，我们需要为每一个条纹图案确定一个调制传递。将这些调制传递值绘制为一个描述条纹图案精细度的参数的函数，这些值就形成了一条曲线，即调制传递函数(MTF)。   我们如何量化条纹图案精细度   条纹图案的精细度：通过计算图像中每毫米包含多少个条纹周期来测量。一个周期是两个亮条纹或两个暗条纹之间的距离，或由一个暗条纹和一个亮条纹组成的线对的距离。   空间频率(Spacial frequency)：图像平面上每毫米的周期数称为空间频率，单位是每毫米线对数，简称为 lp/mm。   下面是文章中的一个图片例子,      GPT对图注的解释如下      Measurement Aperture 2: 测量是在光圈 f/2 下进行的。这意味着镜头的实际成像性能是通过在 f/2 的光圈下拍摄条纹图案来测量的。   Diffraction-limited Aperture 5.6: 理论上，光圈 f/5.6 是受衍射极限影响的最佳光圈。也就是说，在 f/5.6 光圈下，成像质量接近衍射极限，表现出最佳的清晰度和对比度。   Measurement Aperture 5.6: 测量是在光圈 f/5.6 下进行的。镜头的实际成像性能是通过在 f/5.6 的光圈下拍摄条纹图案来测量的。   Diffraction-limited Aperture 16: 理论上，光圈 f/16 是受衍射极限影响的最佳光圈。在 f/16 光圈下，成像质量接近衍射极限，但由于光圈较小，衍射效应变得显著，从而影响图像清晰度。   For purposes of comparison the diffraction-limited transfer functions for f/5.6 and f/16 are also shown (solid line without circular dots). The diffraction-limited image is the best possible one.   什么是Diffraction-limited, 衍射受限(通常用于描述光学系统的成像性能)   Diffraction-limited 是描述光学系统在没有像差和其他缺陷情况下，由于光的衍射效应所能达到的最佳成像质量。当光线通过光学系统（如镜头）时，会由于光的波动性而发生衍射，这种效应会限制系统的分辨能力. 衍射：与光的波动性质有关，当光波遇到障碍物或狭缝时发生偏折. 看到这个地方的时候, 我不知道光的衍射是什么, 也不知道为什么会影响光学系统的能力, 但是这里的意思, 因为这个性质的存在, 有了极限, which is 图示中的黑色实线(接近直线).   OK, 换用新图, Winfu前辈做的图真的是好,      下面是文章的内容的直接复制(没有换成简体中文)   為了作為比較，也標示了f 5.6（橄欖綠色虛線）以及f 16（灰藍色虛線）的繞射極限的轉換函數。達到繞射極限上限的影像是理論上的最佳影像品質，在圖表上呈現幾近完美的直線，下降率與空間頻率成比例。在到達極限頻率（limited frequency）時，MTF趨近於０，其頻率由光的波長與光圈値兩個因素決定。   这里又想补充一点就是, 突然想到, 超过了这个原来的黑色实线(新图的蓝绿虚线,也就是繞射極限), 就会因为衍射的问题, 让成像崩了, 这样?  現實中的鏡頭即使校正，仍帶有殘餘像差，因此MTF曲線一開始會快速下降，然後緩慢趨近於０。曲線明顯向下彎折，就像上面圖６中光圈為f 2的洋紅色曲線一樣；至於光圈縮至f5.6後的藍色曲線和理論最佳値的差距就相當接近了。   當MTF曲線降至０或低於一個臨界點（Threshold） — — 例如10％，其空間頻率即為光學鏡頭在空氣中的解像力，這意味著一旦超過臨界點，黑白條紋的明暗結構整體變成灰色而難以辨識，這又是另一個問題。   圖測量鏡頭在光圈f 2時的曲線，空間頻率到達120 lp/mm時，幾乎是一片平坦，即使空間頻率增加，反差對比也幾乎沒有變化，這樣的測量非常不精確，鏡頭解像力可能達到160 lp/mm以上，也可能只有120 lp/mm。   這樣的判準，並不適合用來評判一隻鏡頭的影像品質。此外，空間頻率與數位時代的影像感測器（image sensor）的「解析度」，兩者也不能混為一談。   像差 (Aberration)   在低空间频率下，像差影响相对较小(为什么?), 随着空间频率的增加，像差的影响逐渐显现(我觉得是容易变灰, 高频下间隙太小的原因)   像差的类型(GPT生成)   球差（Spherical Aberration）      发生在球面透镜中，中心和边缘的光线不能聚焦到同一点。   导致图像中心和边缘的清晰度差异，影响整体锐度。   色差（Chromatic Aberration）      由于不同波长的光在通过镜头时折射角度不同，导致不同颜色的光聚焦在不同位置。   产生彩色边缘和色散现象，尤其在高对比度边缘处明显。   彗差（Coma）      主要影响图像的边缘部分，使点光源呈现为彗星形状。   影响图像边缘的锐度和对比度。   像散（Astigmatism）      垂直和水平方向的光线不能同时聚焦在同一点。   导致图像在某一方向模糊，影响细节表现。   场曲（Field Curvature）      图像平面不是平坦的，而是弯曲的。   中心清晰，边缘模糊或相反。   畸变（Distortion）      图像几何形状变形，直线变弯曲。   “其空间频率即为光学镜头在空气中的解像力”   表示在MTF（调制传递函数）曲线下降到某个低阈值（例如10%）时，对应的空间频率就是这个镜头在空气中的解像力。换句话说，这个空间频率是镜头能够有效分辨的最高频率。      举个例子, 假设某个镜头的MTF曲线在30 lp/mm时降到10%，那么这个30 lp/mm就是这个镜头在空气中的解像力。也就是说，这个镜头能够分辨的最细微的细节是每毫米30对条纹。超过这个频率，图像细节将无法分辨，变成灰色或模糊。   下面是文章的内容的直接复制(没有换成简体中文)   測量鏡頭在光圈f2時的曲線，空間頻率到達120 lp/mm時，幾乎是一片平坦，即使空間頻率增加，反差對比也幾乎沒有變化，這樣的測量非常不精確，鏡頭解像力可能達到160 lp/mm以上，也可能只有120 lp/mm。      我怎么感觉文章里面没解释过下图      這樣的判準，並不適合用來評判一隻鏡頭的影像品質。此外，空間頻率與數位時代的影像感測器（image sensor）的「解析度」，兩者也不能混為一談。   這也是蔡司為何決定採用MTF來描述成像品質的原因之一。我們並不直接用眼睛觀察相機鏡頭成像，鏡頭後方總是需要一個媒介：傳統銀鹽底片、CCD、CMOS、掃描器、投影機……等等，有類比式的也有數位式的。   所有媒介（包括人的眼球在內）都有自身的影像特性，每一種影像特性也可以用一組轉換函數來分別描述。MTF的優勢在於：整體的光學成像鏈的MTF是（接近於所有）個別MTF的乘積。   Let us consider a few typical examples:      有两个图, 第二张没放, 这的意思感觉就是要注意镜头素质和传感器的素质.   Product of two modulation transfer functions: Very good 35mm format lens and color negative film. The product is always smaller than the smallest factor in the imaging chain.   In this case, the total modulation is essentially limited by the film. If one specifies a minimum of 10% modulation transfer, one must expect a resolving power of 80100lp/mm. If further elements such as projection optics or the eye are taken into account, the product is even slightly smaller.   在评价光学系统性能时，为什么通常不需要考虑非常高的空间频率   理由   在这里, 我们观察使用的是MTF product lens x film, which is 看到整体的光学系统对不同空间频率的响应, 乘积后MTF越小，表示系统在该空间频率下的表现越差。涉及更多的传递函数(MTF) 往往只会使乘积变小.   数码传感器的空间频率限制和实际使用下的限制   24百万像素的35毫米全画幅格式传感器和15百万像素的APS-C格式传感器，其奈奎斯特频率大约为90lp/mm, 这是如何计算出的   同时, 40lp/mm已经足以提供足够的细节和清晰度，超出这个范围的细节对于大多数实际用途来说并不显著, 我不知道为什么. 40lp/mm被认为是一个合理的上限，因为它既能够提供足够的图像细节，又不会受到高频混叠等问题的影响。   Nyquist Frequency   想起来在信号系统里面学过, Nyquist Frequency是采样率的一半, 只要离散系统的奈奎斯特频率高于被采样信号的最高频率或带宽，就可以避免混叠现象。对于CMOS传感器而言，它表示传感器能可靠捕捉到的最高空间频率。在图像处理中，采样频率是指传感器的像素密度。 \\(f_{\\text{Nyquist}} = \\frac{1}{2} f_{\\text{sampling}}\\)   90lp/mm（每毫米90对线对）   每毫米有90对黑白线对   Edge definition, image contrast   以下繁体文字内容为直接复制[5].   但是，這些「數據變化」對實際影像品質而言有何意義？當我們談論「清晰銳利」、「明亮度」、「細節解析力」時，和這些數據之間有什麼關連？   我們拍攝的主體本身顯然不是正弦波。它們只能在實驗室中透過大量測試階段生成，使用其他目標對象進行測試，並以數學方式推導出正弦波的調變。   蔡司使用的是一種「明暗變化明顯的長方形黑白條紋圖案」的特製測試圖表，來評估相機鏡頭的有效解像力。   精細的，重複變化的圖案，僅僅只佔據我們的視覺功能中用來辨識影像品質的一小部分。重點是明暗不同亮度區域之間的邊界。因此，蔡司還必須研究MTF與邊界再現（reproduction）兩者的關係。說到這，我們不得不回到起點：點擴散函數。   然后在文章中就出现了4个图, which is由三并排图组而呈现的设计(有点绕口), 我一次性按顺序放在下面,   1⃣️      2⃣️      3⃣️      4⃣️      The following images show from left to right:   Intensity profile of the point spread function, 也就是每个图中的第一个section, 这个是光的点扩散函数, which means  that 点光源/或者说一束光在通过镜头折射穿透后, 在传感器上的分散的切面, 我觉得可以理解成底部的位置就是传感器的感光位置, 以图1⃣️为例子, 这是一个很好的镜头成像, 非常清晰, 点光源只扩散到了-20µm和20µm之间,   Intensity profile of two edge images, 对于这里的Edge profile我的理解是主要关注0µm处如何变化, 还是以图1⃣️为例, 发现在0µm初变化的非常快速, 这是一个好的镜头的表现.   The corresponding modulation transfer 这里是柱状体描述的MTF图示, 拜文章所赐, 文章会见到不同厂商各式各样的格式,方法和规格的MTF的图片. 还是以图1⃣️为例, 这是一个非常好的MTF小图, 不知读者有没有意识到, 从5Lp/mm开始接近100%的MTF率, 到80Lp/mm下仍然保持了接近于50%的MTF率. 原作者评价$\\rightarrow$ The image of the edge is sharp. In the language of modulation transfer, this characteristic is recognized by the fact that all values at the important spatial frequencies are very high and do not decrease so strongly towards the higher frequencies.   For a lens with such imaging performance, the image quality achieved is usually limited by the sensor or by other factors such as focusing accuracy, camera movements etc. 好家伙, 镜头不会限制图像的表现, 差的结果是一些客观的因素.   下面是针对不同的图的结果分析   Pic 1      Intensity profile of the point spread function for Pic 1.1   这个图在之前解释过, 可以被考虑成是一个竖直光线照在传感元件上的横切面, 可以想象成一个千层蛋糕的切面. 同时也在之前提及过, 这个数据非常非常优秀,      Intensity profile of two edge images for Pic 1.1   在之前的解释中, 没有被明确指出, 现在, 可以注意在新的图示中我划出来的红色竖线, 这表示明暗的交接线. 可以看到, lens有非常非常好的过度变化, 在经过0的时候瞬间过了,   Modulation transfer MTF for Pic1.1   非常非常优秀的MTF曲线表示, 在5lp/mm情况下,  正常的随着条纹更加精细而不断下降的数值, 合理而正常.   小注   本来是计划把4个表都解释一遍, 但是发现, 好像没有现实意义, 因为文章的意图是理解MTF曲线, 但是这种形式的MTF曲线已经不再使用. 但是在这个部分要指出的是, MTF测量表会不准, 显示 出错误的数据信息, 在文章中的例子就是, 比如现实图像在影射后, 在cmos上位移会没有显示清晰的图像, 但是位移的图像在某个Lp/mm的条纹下, 移动到了下一个位置, 导致图像没有变模糊, 仍然清晰. 虽然镜头的素质没有提高, 但是由于测试的是这种特殊的条纹, 让MTF的曲线的数据提高, 这是虚假的成绩. 这个现象在文章中被专门指出. 我在这里直接引用, But: There is no contrast at 40lp/mm! The curve of the modulation transfer can drop to zero and then increase again.  This is then called “spurious resolution”, which is a somewhat unfortunate expression because the structure with 60lp/mm is reproduced with a clear resolution.   文章中的第四种MTF曲线(The MTF values of this 4th type)   ","categories": [],
        "tags": [],
        "url": "/how-to-read-mtf-curves.md/",
        "teaser": null
      },{
        "title": "签证准备材料list",
        "excerpt":"记录签证准备材料的list   美国签证准备材料 (详细版本)      护照原件、旧护照原件（如有）   签证预约确认页   SEVIS FEE缴费收据   DS160 表格确认页   i20表格（签名）   2张白底签证照(51mm*51mm)   存款证明原件   英文简历（研究生必须）   学校录取信   Study Plan （研究生必须）   导师个人简历 （如有）   个人论文（如有）没有   自带包裏 透明没有拉链, 塑料A4纸夹片   学校成绩单中英文版本   在读证明中英文版本（如在读)   毕业证/学位证中英文版本（如毕业）   标化考试（如TOEFL、IELTS、GRE、GMAT、SAT 等）成绩单复印件或原件   父母双方收入证明   户口本/身份证   房产、车产证明   美签学签证-简单版本      护照   身份证   DS-160（含照片和条码）   签证预约信（含条码）   SEVIS缴费证明   i-20表格   录取的offer   个人简历   学习计划(study plan在美国大使馆官网可以下载)   经济文件: 做i20时候的存款证明   户口本   签证预约缴费单   51*51 mm的签证照（两张）   加粗的部分是最后使用到的文件.   日本签证           1、彩色白底免冠证件照电子版;            2、护照首页（照片信息页）及末页（第46-47页）的清晰完整对开扫描件（护照剩余有效期需大于回程半年以上）；            3、户口本扫描件（除空白页都要）；            4、非上海领区户籍需额外提供居住证正反面扫描件/在职证明+6个月以上社保/ 在职证明+近1年内税单（上海市内居住证需额外提供验证页面截图电子版）；            5、结婚证、离婚证扫描件（如有）            6、出生证扫描件（未成年必须提供）            7、日本签证受理表（电脑编辑填写，必须填写完整）            9、个人信息处理同意书（需填写好日期，姓名和手写签字，打印出来签字提供扫描件，一家人可以写在一起）            10、提供以上基本资料+经济材料（7选1）       温馨提示：领馆有权利让您补充材料，若被通知请及时配合提交；拿到签证之后再定机酒。  ","categories": [],
        "tags": [],
        "url": "/visa-preparation/",
        "teaser": null
      },{
        "title": "Life goals before the age of 30 (in addition to finding a job)",
        "excerpt":":)      Suceived in GT in the QCF and CSE program(wanna dual degree)…   Use the money which I earned to buy two leica cams (m1x, mp)   Be proficient in using a sewing machine to make small bags and edc backpack design under your own understanding (difficult)   Japanese level is equivalent to IELTS 5.5 in Eng(I think it is enough), and I can communicate with native jp people.  (difficult)   Reasonable understanding of the process, materials, steps, installation and design of house decoration   launched two self-developed independent apps, iOS / web OS   时间很长却也很快.   感觉人还是要活的现实一点, 不要太有梦想, 做一些本身有实际价值事情, 而不是感动自己/他人的事情.  ","categories": [],
        "tags": [],
        "url": "/Life-goals-at-30/",
        "teaser": null
      },{
        "title": "2025-03-07-How I use LLMs by Andrej Karpathy 看后总结",
        "excerpt":"https://www.youtube.com/watch?v=EWvNQjAaOHw   当然这个视频, 感觉是一个挺好的材料, 从一个很简单的角度切入, 快速判断什么任务可以实现 两个多小时的视频, 结果花了三天的时间还比较碎片的时间才看完, 之前通宵两天熬夜太狠了, 感觉看的时候一直没有很专注, 然后还没干什么事情, 笑死. 注:  回到这个这个视频, 回顾的想, 这个视频的信息含量没有涉及什么复杂的步骤和内容, 更多的是一个科普向的视频, 或是一个操作演示一样. 当然打开之前我就知道, 干货应该不多, 肯定不如Let‘s build 那个系列, 我只是想比较一下我使用LLM和Andrej Karpathy使用LLM的区别. 接下来的步骤都是我看过之后一次性回忆的, order可能有问题, 然后一些sub subjects会有遗漏. 加上实在感觉我看完了不等于是会了, 我认为会了仍然还有大量可能的错误, 不如直接写下来. 相信即使是最简单的逻辑和常识也需要被整理. 花一点时间, 把要大量使用的工具理解清楚我觉得还是对我重要和有价值的.   笼统介绍   一开始，Andrej Karpathy 提到，他几乎订阅了所有主流 LLM 模型的会员服务(2025 年 3 月) 接着，用了一个特别形象的比喻which is zip 文件，来形容大模型预训练后的状态。这个比喻很有意思，因为 zip 文件如果不解压，里面的内容是没法直接用的。换句话说，预训练后的模型并不像字典那样，能瞬间（O(1) 时间）找到你想要的东西, 所以模型不是pageRank那样的搜索?  LLM good at writing. 然后，Karpathy 花了一些时间解释 token 的概念，简单了解一下非常有意义。 无论是文字、标点符号，还是输入输出，都会消耗 token。我们看到的是连贯的文章，但对模型来说，它处理的是一串 token。LLM 的输入是 token，输出也是 token，它的任务就是预测下一个可能的 token，一个接一个地生成文本。（这里我打个比方：假设人 A 对美国人 B 说中文，但 B 听不懂中文。于是，A 的中文被转换成了一串数字（比如 Unicode 编码），B 看到的是这串数字。虽然 B 不懂中文，但他已经通过学习知道这些数字之间的关系，通过不断的预测, 最后他也用一串数字来回应。最后，这串数字被解码成中文，A 听到了 B 的回复。）然后视频演示了下面这个开发者做的网站，它能展示输入输出时 token 的具体的展现： https://tiktokenizer.vercel.app/   继续讲了预训练和后训练   预训练很贵, 预训练使用大量的历史上的材料, 互联网上已经有的内容, 组成了一个由token之间的关系的size很大的zip文件. 但是这个zip文件是有损失和有概率 zip 文件. 是sequence of token.   后训练 much much cheaper. Using SFT（Supervised Fine-Tuning, 监督微调）、RLHF（Reinforcement Learning from Human Feedback, 人类反馈强化学习） 和 RL（Reinforcement Learning, 强化学习）on Conversations, 这里Andrej认为post train类似于角色扮演, 后训练的重点是调整模型的行为，而不是再教知识, 我感觉对于使用者来说了解到这里就OK了? GPT讲, 换句话说，预训练教会了模型语言，而后训练教会了它如何像人一样“扮演”某种对话风格或人格。  开始演示使用大模型  展示了不同模型随便输入一个问题后, 显示了一些输出什么的. 这里我记得没什么好着重提及的, 可能Andrej使用了perplexity来使用deepseek的模型有点难评.   这里有一个细节, 我之前没有注意, 我之前以为perplexity这家公司没什么技术, 但是在演示中发现, perplexity搜索速度蛮快的, 这里有我不知道的点.   还有这里解释为什么会出现不正确输出的原因, 因为预测本身就不会是100%正确的, 很正常很自然.  还讲了GPT模型不透明的情况, 比如虽然选了GPT-4o但是你怎么知道运行的是不是4o, 明确的提及了在用户没有登录的时候, GPT提供的是一个size非常小的模型.  上下文搜索  现在的模型, 只要用过, 就会发现模型具有一定的上下文记忆能力，即它能够理解并引用同一对话中的先前输入和输出。此外，如果持续在同一对话中交流，token 消耗会非常快，这也意味着模型实际上是在不断地处理和整合之前的对话内容。每次新的输入都会与之前的输入输出结合.   看视频的时候直接跳过了, 但是这里有个疑问, 就是, 模型是怎么选择之前的记忆的呢? 首先这个window肯定有一个size, 如果已经输入的内容和输出的内容过长, 这个window肯定是装不下的, 但是抛弃之前的内容的策略是? 之前就知道会丢和能保存.      问了GPT,  LLM 的上下文窗口(context window)是有限的，有一个固定的大小(如 4096、8192 或更大的 token 数), 当输入和输出的内容超出上下文窗口的容量时，模型必须决定如何舍弃部分旧内容。策略有, 滑动窗口（Sliding Window）, 基于重要性截取（Relevance-Based Pruning）, 层次化摘要（Hierarchical Summarization）, 基于提示（Prompt Engineering）    OK, 策略这么多, 如何这里如何选择也是一个黑盒…  不同模型的价格  这里就是说一下不同模型的价格和提供的服务不同, 没有涉及到api.   联网搜索 * Search  为什么有联网搜索的功能? 本质上因为创建那个zip file的过程是一个由时间限制的东西, 决定使用23年4月为止的内容, 那么之后的内容当然涉及不到. 比如询问大模型一个今天的天气, 有点强模型所难了. 如果使用搜索改变了什么呢, 相当于爬虫爬取了网上搜索得到的内容, 作为输入, 那么这里有新的输入了, 这部分知识, 在输出回答的时候, 就可以回到诸如今天的天气和气温这类的问题.   Reasoning Model  由GPT-o1开始, 强化学习来解决数学编码等逻辑问题, 这个思路被做出来了一个产品. 原理我不懂,  有空有必要了再学吧. 这里浅显的说法是, 对于数学推理、代码生成等任务，我们希望模型一步步地推理，而不是仅仅根据概率生成看起来正确的文本.   所以之前一个高中生的prompt让claude 3.5变reasoning model的新闻有点扯淡. 两个看似相似的输出, 输出的文本背后的逻辑都不一样.  deepResearch  有点感觉是一个set of reasoning model的组合, 忘了, 回去看的时候再补一下, 这里好像说到了现在grok和gpt都有这种能力, 挺有潜力的一个功能, 但是我目前没感觉特别厉害, 或者我没有使用场景. 我冲了20美元的GPT会员使用下来(可以用10次), 我用了两次, 我使用的情况是没跑出来什么特别有用的东西…  LLM 文件上传(主要是pdf)  这里在使用claude的时候, 提及了在pdf中的插图应该是不会被使用的. 识别的都是大量的文字, 应该也是类似于多模态调用OCR的能力? 虽然我事后搜索了一下Claude有识别读取pdf中图片的能力, 所以, 不知道是不是 Karpathy 讲错了还是在使用中没有发现对插图有识别和作为输入. 我在之前使用的时候没意识到这个细节, 但是我记得在只输入图片的情况下是可以识别的(which就是一张图中有示意图和文字解释或文字内容), 但是我记得之前输入一个graph, 让GPT判断后输出BFS或者DFS还是挺费劲的, 这里不知道是为什么. 感觉要了解图片是怎么被LLM读取的才可以搞明白.   这样就有一个疑问就是, 我希望LLM在处理图片输入的时候, 希望它在使用正确的信息, 这里在prompt的地方可以说一下, 提及一下就是, 让模型输出OCR后, 它看到了什么, 这样可以在输出OCR结果不对的情况下发现错误.  Code interpreter(容器?) data analy  LLM的代码能力非常好, 我猜测是因为代码有一条类似于flow的处理逻辑, 是不是非常容易被强化学习拟合啊? 就是, 输入的数据啊, 个数啊, 类型啊, 都是设计好的, hh无端猜测了.  这里想到一个经典问题, 好像是9.9大还是9.11 大什么的,这里如果使用python解释器来输出结果应该是没问题的, 但是我记得有新闻是说, 这里GPT会比较的是圣经的章节, 所以 9section的第9 subsection当然小于9section的第11 subsection的, 这里想到这是一个简单的小计算过程, 如果在一个大型项目中, 使用LLM认为过于简单没有自动调用Code interpreter使用python输出来比较的话, 在这一步给出一个正确的答案会怎么办呢? 过程如果过于多, 还挺难定位这个问题的 在这里视频的最后写了一下直接使用GPT做data analysis其实网上有大量的资源, 不展开介绍.然后在演示的时候, GPT还出现了数据的错误. 我记得是一个最大值的数据点搞错了  One more related tool , Claude Artifacts(apps, diagrams)   这里Andrej Karpathy甚至生成了一个anki卡片的网页应用, 然后来检测从wiki上复制的亚当斯密的知识点, 神了, 反正我之前是没有这样使用过和没想过的. 有交互还有反馈. 然后在这个section, Karpathy介绍了一下用Claude生成mermaid流程图, 然后展示出来, 这个事情其实我在GPT3.5的时候就做过, 生成完code再粘贴到mermaid模拟器上, 在视频中看到Claude就是多了一个出完code的时候及时生成展示图片的功能, 好确实好, 但是没感觉多好,hhhhh, 可能就是有没有想到这样去用LLM来得到这个输出的区别. 我想想当时好像是软件工程的作业要画流程图, 我发现一个geek朋友非常喜欢用代码写那个软件的工程图, 我们大部分是用线上的画图软件自己画的, 我画了第一个图之后,感觉非常非常麻烦. 我没学过那个流程图的代码框架, 这时候想到why not 用GPT生成那个结构代码, 刚好typora也支持mermaid, 用代码写这种流程图完全不需要关注框图的间距, 箭头的粗细这种问题, 然后我就一直使用这样方法写这部分的任务. 后来的latex也是. 一次一次的任务然后习惯了使用md的语法, 最开始是发现gpt一直在使用这种格式的文本输出, 觉得挺轻便和美观的就在b站学了半小时之后写到了现在.  这里我想到LLM直接跑D3.js还有Graphviz应该都蛮棒的 这里Andrej Karpathy的用法是, 使用mermaid梳理文本, 梳理人物关系网, 梳理故事发展过程, 这个用法我之前没想到过, 以后可以多加使用.   (我加的)任务处理  下次再说吧, 是Claude开发的一个工具.  cursor  之前看课代表立正的视频的时候, 里面一个视频讲, 对于自己的粉丝做了一个调查是, 认为过去一年ai没什么发展的和ai发展飞速的好像是一半一半, 但是认为过去一年ai发展快速的人中, 绝大部分的人是使用过cursor的,  这里, 就是感觉, 虽然明面上说是整个文件都是一个上下文窗口中读入的, 但是项目一大, 应该仍然是会丢失的, 那么那些神奇的策略们的选择黑箱, 该如何选择, 这里的策略好像不可以被人为调控.  Karpathy飞速的做了两个demo, 挺不错的. 有点神奇的是, 如果本地环境下, asset中没有一些文件, (视频中是一个点击的声音特效, 还是胜利音频特效来着), cursor居然会联网爬一个库下载下来, 我真是一脸正经, 之前一直以为是巧妇难为无米之炊的, 这还可以自己下一个文件过来? 但是转念一想, 好像这和运行一些项目要使用一些lib然后自动下了一些pip好像没什么不同, 然后又不觉得特别神奇了.  使用声音输入 / 输出   这里只是使用speech-to-text模型输入文本给GPT, 然后得到文本的返回, 没有使用下面的语音模型. 很多时候, 其实我们只需要一轮问答, 比如, 现在的Karpathy 在视频里面讲使用快捷键F5快速调用(类似于siri), 询问一个问题, 得到LLM的回复, Karpathy 说现在接近一半他都是在这个使用场景下使用的 我想了想, 确实比较方便, 打算下个礼拜在自己的电脑上整好这个操作.  使用语音模型, 伦理   这里我记得使用grok可以沟通出一些怪怪的声音和对话内容, 是在使用GPT的语音对话无法实现的, 而且GPT语音还是拒绝回答一些类型的问题, “利用怪怪的声音快速说1-20”我记得视频里面好像说了这个例子.  NotebookLM  输入一些文件, pdf, 然后gemini出一个talk. 我之前有听说这个功能十分惊艳, 但是没引起重视, 或者觉得这个功能无法帮助到我.  1, 是想不出这个功能的实用价值, 首先我不用播客类节目变现, 再是在油管和xhs加上一个B站这些视频流媒体平台提供给我的内容, 无论是否优质, 已经足够足够多了, 我现在的精力甚至是减弱这些平台给我的影响, 减少注意力分散, 我不应该去关注太多信息来源, 虽然很多优质的信息还是从这方面来的, 没办法无法隔离.  2, OK回到这个NoteBook播客功能上, 还有一个原因就是语言(英语水平)还是存在问题, 虽然CS, 科技, 数码 or 摄影相关的英文内容我可以做到95%的时间follow上和听得懂, 但是非母语还是有问题就是, 感觉脑子在输入英语的时候有一层decoder一样, 还是要慢一些, 我脑子在输入英语的时候对专注要求更加高, 这样听这个英语博客还是挺累的, 中文还是我的舒适区无法改变了, 不然这篇文章我肯定是想用英文打出来的.  OK, 所以这个应用就对我来说有点鸡肋, 我不需要使用这个function来获取信息, 加上流畅使用还是有语言门槛, 如果想快速了解某个领域的知识, 为什么不直接上网搜索一个general的介绍呢? 整10篇文章输入, 做一个博客有点奇怪. 或者说, 泛泛的去了解一个domain的知识这样做有点出力太多, 但是如果想认真学习一下, 这样做是远远不够的, 所以我困惑于对我自己的使用场景. 我感觉是不是deep research加上这个NotebookLLM podcast的功能是不是有使用价值一点, 其实我希望连选都不要选topic, 用一个推荐算法什么的, 网易云音乐式得生成高质量podcast如果有一个这样的产品我会愿意去用, 我连花时间喂Notebook的生成podcast的操作都懒.   然后Karpathy说, 整了一些podcast可以在开车路上听, 哈哈好吧, 碎片时间, 可惜我没有车.   图片输入          之前提到过, 图片输入往往有输入的错误, 这里Karpathy说他 使用方法是分成两步, 而不是直接让LLM输出结果, 比如使用prompt, 分成两步, 第一步输出OCR的输出结果, 第二步使用这些结果输出我想要的答案            转成公式 simpleTex, Math Snipping Tool这种识别论文中的公式使用OCR的小而美的business应该都快寄了, 我真感觉用一个LLM的api再使用一个prompt做一个小应用就行, 用cursor做可能不用半小时.       突然有点好奇LLM的输入, 图片和文字的区别, 是直接图片使用分配给OCR的模型读取么  ChatGPT的个性化助手和应用市场, 提示词?  这里涉及了好多Karpathy的个人信息啊哈哈哈哈, 看到网上的comment是他谈了一个韩国女友, 所以在各种姿势学习韩文. OK离开八卦的话是, LLM在翻译任务上简直是出人意料的好, 逻辑流畅舒适, 甚至可以输出一些引申的含义.  还有我其实有个疑问是, 要不要使用xml类似的指令? 使用自然语言和xml语言有对文本读取来说有多大的差别, 如果有差别的话, 我自己感觉是各模型厂家在post train的时候调整的, 还有如果使用api去调用的话, 在code界面, 大家使用的都是xml的结构. 我自己感觉是有区别但是区别不大, 不然其中的一种方法会被大肆宣传的. 比如下面是我希望解释Leetcode问题时候的prompt  &lt;task&gt; 编写一个解决这个问题的程序 &lt;context&gt; 我希望你像一个人类程序员一样思考这个问题。请展示完整的思考过程,包括: - 初步理解问题时的想法 - 尝试解决时遇到的困惑 - 思路的演变和修正 - 为什么最终选择这个实现方案 &lt;/context&gt;  &lt;format&gt; 请用以下格式输出: 1. 初步分析 - 用简单的语言描述你对问题的第一理解 - 列出可能需要考虑的关键点  2. 解决方案构思 - 写下你能想到的几种方案 - 分析每种方案的优缺点 - 解释为什么选择或放弃某个方案  1. 代码实现 - 每写一个代码块前,先解释你准备做什么 - 用注释记录当时的思考 - 如果发现问题需要修改,说明原因 - 展示完整的思维过程,包括错误的尝试  2. 最终总结 - 回顾整个解决过程 - 指出关键的思考点 - 分享可能的改进方向  &lt;style&gt; 注释风格: # 初步想法 # 发现问题 # 修正思路 # 实现原因 &lt;/style&gt;   另外一个疑问是在customize ChatGPT的时候 What traits should ChatGPT have? 和 Anything else ChatGPT should know about you? 在输入的时候到底有什么区别.   演示了一些图片生成, 视频生成   Andrej Karpathy翻了一个twitter的po文, 我本人对这部分功能兴趣不大, 但是看的时候, Google 生成的视频非常真实, 感觉还挺厉害的.   Finally  08-March-2025 本来想用20min写一点想法和总结就行, 但是居然写了快2个小时半才写了一半内容, 麻了, 太废了, 实在是太笨了, 效率太低了,打字速度也慢.  今天先不写了, 不然任务完不成了. 看了一眼左下角字数统计, 一边想, 一边整理两个小时写2100多字, 好像也不算是非常非常慢的整理速度, 好吧, 平衡了.  09-March-2025 今天好像也是花了好久在写这个东西…   希望 llya 这位LLM真神可以在5年之内弄出一个更加逆天的模型.  ","categories": [],
        "tags": [],
        "url": "/How-I-use-LLMs-by-Andrej-Karpathy-%E7%9C%8B%E5%90%8E%E6%80%BB%E7%BB%93/",
        "teaser": null
      },{
        "title": "Recursive problem and Thinking Process",
        "excerpt":"The article contains mistakes and misunderstandings, as it is a record of my own incorrect notes rather than a proper summary document.   First Module 1 - Arrays, ArrayLists, Recursion   Given this recursive method and an input of n = 7, what will the output be? Please enter your answer as a Comma Separated List (e.g 1, 2, 3, 4)  public void recursiveMethod(int n) {       if (n &lt;= 0) {           return;       } else {           System.out.println(n);           recursiveMethod(n - 2);           System.out.println(n - 1);       }   }    Your Answer:7,5,3,1   Correct Answer: 7, 5, 3, 1, 0, 2, 4, 6     The answer relies on a recognition that the output will come before the recursive call, and that the output after all recursive calls are made will output from smallest to largest instead of largest to smallest   Then a CMU web, Towers of Hanoi   In this puzzle, we have three pegs and several disks, initially stacked from largest to smallest on the left peg. (See the 6-disk picture below.) The rules are simple:      Our goal is to move the entire tower to the middle peg.   We can only move one disk at a time.   We can never place a larger disk on a smaller one.                  If JavaScript 1.2 is enabled on your browser, you can try it yourself. Just click on the disk you want to move, and then click on the peg you want to put it at. Although technically you are only allowed to move one disk at a time, the program will move several disks if it is necessary to complete the move.   We’ll answer both of these questions in sequence.   To describe how the monks should solve this puzzle, the concept of recursion will be useful. We look at that next.   Next: Recursion.   Then a simple leetcode Q 104. Maximum Depth of Binary Tree   104. Maximum Depth of Binary Tree eng ver   But most people did like this, correct, but…, not friendly for me at first   class Solution:     def maxDepth(self, root: Optional[TreeNode]) -&gt; int:         return 1 + max(self.maxDepth(root.left), self.maxDepth(root.right))           Then two prob   Reverse Linked List  https://neetcode.io/problems/reverse-a-linked-list Not the normal Iteration  class Solution:     def reverseList(self, head: Optional[ListNode]) -&gt; Optional[ListNode]:         if head is None or head.next is None:             return head        \t# weird place         node = self.reverseList(head.next)                  head.next.next = head         head.next = None         return node   And 104. Maximum Depth of Binary Tree again , simple question again I think it is a good way to understand?  # Definition for a binary tree node.  # class TreeNode: #     def __init__(self, val=0, left=None, right=None): #         self.val = val #         self.left = left #         self.right = right   class Solution:     def maxDepth(self, root: Optional[TreeNode]) -&gt; int:          # I'm starting from the root node now          if root is None:  # if there is no root, there is no root node at all, so I should return the value 0              return 0          # OK, the logic now is that there is at least one root node. Now, based on the logic of the recursive function,          # we can know the depth of the left and right nodes starting from the root          # which is          left_depth = self.maxDepth(root.left)          right_depth = self.maxDepth(root.right)          # OK, now, we start to think, we have the depth of the root nodes root.left and root.right, now we want to add          # the depth of the root layer itself, so we need to add 1. At the same time, we want the maximum depth, so we have the max function          return max(left_depth, right_depth) + 1    Right now, the problems are     Reinforce point   Return type, and helper method (create a new helper method)   A simple Leetcode Q,  The thinking flow of recursive Q in BST 617. Merge Two Binary Trees  # Definition for a binary tree node. # class TreeNode: #     def __init__(self, val=0, left=None, right=None): #         self.val = val #         self.left = left #         self.right = right class Solution:     def mergeTrees(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -&gt; Optional[TreeNode]:         if not root1:             return root2         if not root2:             return root1         def merge(node1,node2):             # if two entering roots are None, direct return one of trees,              # return node2 # ? wired, wanna change [root1s] val, but it return a value,               if node1 is None and node2 is None:                 return                           if node1 and node2:                 node1.val += node2.val                          if not node2:                 return              if not node1.left and node2.left:                 node1.left = TreeNode(0)             if not node1.right and node2.right:                 node1.right = TreeNode(0)             merge(node1.left,node2.left)             merge(node1.right,node2.right)                                   merge(root1,root2)         return root1   # Definition for a binary tree node. # class TreeNode: #     def __init__(self, val=0, left=None, right=None): #         self.val = val #         self.left = left #         self.right = right class Solution:     def mergeTrees(self, root1: Optional[TreeNode], root2: Optional[TreeNode]) -&gt; Optional[TreeNode]:          def merge(root1,root2): # -&gt; treeNode             if not root1:                 return root2             if not root2:                 return root1             # if root1 and root2 # adding value logic                          root1.val += root2.val             root1.left = merge(root1.left,root2.left)             root1.right = merge(root1.right,root2.right)                          return root1         return merge(root1,root2)           Leetcode 450  450. Delete Node in a BST  # Definition for a binary tree node. # class TreeNode: #     def __init__(self, val=0, left=None, right=None): #         self.val = val #         self.left = left #         self.right = right class Solution:     def deleteNode(self, root: Optional[TreeNode], key: int) -&gt; Optional[TreeNode]:          def dfsFinder(node,val): # Unsure of the return type, changing the tree structure, so should the return type be treeNode?          # Or do I only need a single return, because I'm only changing the tree structure?  Confused              # no root , return None             if node is None:                 return None # Confused here. The question says if found, delete it; if not found, return None or the original?                  # I don't know whether to write return or return None, I can't convince myself.                           # if node: ... so right now this place has a node, first one is root             # from root perspective             if node.val == val:                 # using successor, that is the minimum value of the right subtree.                  node = successorHelp(node)                                  # Oh, it can be using if statment here.                 # if node.right and not not node.left ....               elif node.val &gt; val: # node.left                 temp = dfsFinder(node.left,val)                 return temp #?             elif node.val &lt; val:                 return dfsFinder(node.right,val)                  def successorHelp(node):             # When calling itself, the input cannot be None, but I think it's okay to check?  \t\t\t# Wow, it seems that a check is necessary because of the recursive boundary problem, but can we directly check if it's a leaf node? No, what if there's only a left subtree and no right subtree?              if node is None:                 return None # I suddenly don't know what to return.  Returning None feels strange.                                   # It was written as None at the end, but after thinking about it, I don't think it will be called.              # .right once             node = node.right             if node.right:                 while node.left:                     node = node.left                                  # delete that node                 new_value = node.val                 node = None                 return new_value             else:                 return node.left                          # I think the above can be adjusted.  It's about `val` and an impossible `val`. If it's an impossible `val`, it means there's no right subtree starting from the node, so connect to the left subtree starting from the node, that is, `node = node.left`.                                               ","categories": [],
        "tags": [],
        "url": "/recursive-problem/",
        "teaser": null
      },{
        "title": "Thinking and Re-thinking of Learning and Happiness",
        "excerpt":"Using LLMs to refine context through chaotic thinking, but I think GPT-4.5 (2025-04-22) is quite good.   下面的内容是我胡乱打的, 也就是说想到什么写什么说什么, 但是大概follow了我在想一些事情时候的本意.      感觉学习递归的过程, 认为让我理解了学习为什么困难or为什么成绩不好什么的. 一个本质的问题是, 你是否认为一个人可以学会任何东西. 相信大脑的能力,相信神经. 我相信这一点, 不过在学习时间够长的情况下. 为什么在一个阶段学不懂, 我认为是之前其实有东西没学懂.  基础出现问题. (补充) 但是可能硬件不同, or正常理解框架下的智商, 我感觉是大脑全链路激活层的学习速度, 我觉得学习速度应该是真有快慢的, 这是事实. 有些人, 有些快, 在比较心理, 认为自己的不行的暗示下, 距离就逐渐拉开了. 知识没有被分成足够小的chuck.     学习的目的非常重要, 我认为需要正反馈. 不可以骗自己, 可以骗一个月, 不可能骗10年, follow自己的内心, 非常重要. 感觉这也是另外一种版本的价值回归.     回到递归, 做递归, 最忌讳的就是思考递归的细节, 但是学习为什么感觉都是一个逆过程, 追求成绩, 违反本身的追求真理的逻辑, 学习过程的正反馈是, 在相同时间内学的比别人快, 学的比别人多, 而不是增加探究世界现象的手段, 当然痛苦.     我感觉学习, 读书, 好像在不断获得和学习认识这个时间的工具, 就像一个天生近视800度的人, 可以逐渐看清越来越远的东西, 像镜头的景深越来越深, 这个过程当然是快乐的, 而且是逐步快乐的, 这个时候检测 考试, 好像就是解读一些观察时候的corner case. 但是push的手段却是比较时间断内, 谁看到的世界比较大, 谁获得的知识比较多, 奇怪, 不过如果检测集足够大, 确实可以筛选出来那些本身获得正反馈的, 和本身速度就比较快的人…    使用的简单prompt是, 这个是一个混乱的思路文稿,{上面的文本内容},解读,组织成一个结果完整的文章    claude 3.7      递归学习与思维过程的反思     您分享的文稿表达了对学习过程、特别是递归思维的一些深刻反思。我将整理您的想法，并从编程与学习思维的角度进行解构分析。     递归思维的本质与编程应用     在编写代码时，尤其是面对递归问题时，人脑应该关注的核心不是递归的具体执行细节，而是问题的整体结构和解决方案的框架。这与您所说的”最忌讳的就是思考递归的细节”相呼应。     在编程思维过程中，我们应该关注：          问题分解 - 将复杂问题拆解为更小、更易管理的子问题     模式识别 - 发现问题中的重复模式，这是递归的基础     边界条件 - 明确递归的终止条件，防止无限循环     信任抽象 - 相信子问题的解决方案，而不陷入执行细节       编码思维流程     当我们编写递归代码时，思维流程通常是：          首先识别问题是否适合递归解决（是否有重复的子问题结构）     定义基本情况（边界条件）- 递归必须有终止点     设计递归关系 - 如何将大问题分解为同类型的小问题     实现递归逻辑，相信递归会正确处理子问题     验证解决方案，检查边界情况       这个过程与您提到的”学习的逆过程”有相似之处。递归编程要求我们相信函数能够完成其承诺，而不是纠结于每一层的执行细节。     学习过程的启示     您的文稿中提到了几个关于学习的重要观点：          学习基础的重要性 - “在学习时间够长的情况下，为什么在一个阶段学不懂，我认为是之前其实有东西没学懂，基础出现问题”     内在动机与正反馈 - “学习的目的非常重要，我认为需要正反馈”     知识分块 - “知识没有被分成足够小的chuck”       这些观点与有效的编程学习特别相关。编程学习也需要将复杂概念分解为可管理的小块，建立在坚实的基础上，并通过解决问题获得正反馈。     编程与学习的哲学联系     编写代码，尤其是递归代码，可以视为一种认知训练，它培养了以下思维能力：          抽象思维 - 看到问题的本质而非表面细节     系统思考 - 理解部分与整体的关系     信任机制 - 相信系统各部分能够协同工作       这与您描述的学习过程相似：”学习，读书，好像在不断获得和学习认识这个时间的工具，就像一个天生近视800度的人，可以逐渐看清越来越远的东西，像镜头的景深越来越深”。     实践建议     在面对递归等复杂编程概念时：          先理解问题的整体结构，而非实现细节     确定最简单情况的解决方案（基本情况）     设计递归关系，而不是试图在脑中跟踪整个执行过程     编写代码时关注逻辑结构，而非执行顺序     通过测试简单情况验证代码，建立对解决方案的信心       这种方法类似于您所提倡的学习方式：关注整体理解，而非机械记忆；追求内在价值，而非外部评判；将复杂问题分解为可管理的部分。     通过这种方式，编程不仅是一种技能获取，更是一种思维培养，帮助我们”看清越来越远的东西”，扩展我们认知的”景深”。    deepseek - R1      递归思维与学习困境：一场关于认知本质的思辨     在计算机科学的递归算法里，程序员最忌惮陷入函数调用的细节迷宫。这个编程隐喻恰如其分地揭示了人类认知的深层困境——当我们面对知识体系的建构时，常常迷失在表层现象的追逐中，却遗忘了思维递归的本质特征：每个层次的突破都建立在坚实基础之上。     一、知识大厦的地基危机     现代教育体系如同加速运转的传送带，将标准化知识模块源源不断地输送给学习者。在这个过程中，多数人陷入”知识假性完整”的认知陷阱：微积分公式的机械套用掩盖了极限概念的模糊，编程语法的熟练操作遮蔽了算法思维的缺失。这种基础性认知漏洞如同建筑地基的裂缝，在知识体系不断叠加的过程中产生级联效应，最终导致整个认知结构的崩塌。     认知神经科学的最新研究证实，大脑新皮层的神经可塑性并非均匀分布。前额叶皮层与海马体构成的记忆环路，其信息处理效率直接影响知识模块的整合质量。当基础概念网络存在结构缺陷时，高阶认知功能的神经表征将出现拓扑紊乱，这正是”阶段式学习困境”的神经生物学基础。     二、认知时钟的速率谜题     在慕尼黑大学的天才追踪研究中，发现顶尖学者的大脑白质纤维束呈现出独特的拓扑结构。这些增强的神经连接通道，使得他们的信息处理速度比常人快3-5个数量级。这种硬件差异如同CPU的时钟频率，决定了知识编译的基本速率。但神经可塑性研究同样表明，持续的正向刺激能使大脑胼胝体的髓鞘厚度每年增加0.5-1%，这意味着学习速度本身具有可塑性。     教育评估体系制造的比较陷阱，本质上是将马拉松改造成百米冲刺的竞技场。当知识检测简化为碎片信息的提取速度测试，真正的认知深度反而被排除在评价体系之外。这种异化机制催生出大批”解题运动员”，他们熟练操作知识符号却丧失了概念建构能力。     三、认知觉醒的正向递归     真正的学习革命始于元认知的觉醒。当学习者将注意力从外部评价转向内在建构，知识获取就转化为持续的正反馈循环。这个过程遵循着严格的递归逻辑：每个新概念必须完全内化为认知基元，才能支撑更高层级的思维跃迁。MIT媒体实验室的认知增强实验证明，采用这种递归学习法的被试者，其知识留存率是传统学习者的4.7倍。     建立认知增强系统需要重构学习范式：将知识体系分解为原子化概念单元，通过间隔重复形成稳定的神经突触连接；构建概念之间的多维联结，形成抗干扰的认知拓扑网络；最终在问题求解中实现知识的创造性重组。这个过程如同3D打印认知结构，逐层构建却始终保持整体一致性。     站在认知革命的门槛上，我们需要重新理解学习的本质。知识获取不是信息的简单堆砌，而是认知结构的递归升级。当我们将每个知识节点都锻造成坚实的认知基元，就能在思维空间实现真正的维度跃迁。这种递归式认知进化，终将带领我们突破智能边界，见证思维宇宙的奇点时刻。    GPT - 4.5      学习递归的过程让我意识到为什么学习对很多人来说如此困难，也让我进一步理解了成绩表现不佳背后的原因。     首先，我们必须承认一个基本问题：人类是否能够学习任何内容？我个人相信大脑具备这样的能力，相信神经网络能够通过不断训练和刺激逐渐掌握知识。然而，即便学习时间充足，某些阶段的知识却依然难以理解，这背后往往是因为之前的基础知识并没有真正掌握透彻。     然而，这里还存在另一个重要因素：硬件的不同，或者我们常规理解中的智力差异。每个人大脑中神经元连接的效率，即所谓的“全链路激活层”，确实存在差别。这导致了不同人的学习速度存在客观上的差异。这种差异本身是真实存在的事实。有些人学得更快，有些人则相对慢一些。当人们开始将自己与他人比较，并暗示自己能力不足时，这种差距便会逐渐扩大。此外，知识没有被分解成足够小的知识单元（chunks），也进一步加剧了学习困难。     明确学习的目的至关重要。我认为最重要的是持续的正反馈。一个人可能短暂地欺骗自己一段时间，比如一个月，但绝不可能持续地自欺欺人十年之久。因此，诚实地追随内心真正的兴趣与价值观尤为重要。这实际上也是一种价值回归——回归到学习本质的乐趣与探索。     以递归为例，递归最大的忌讳便是陷入细节，却忽略整体思维。可是现实的学习过程却经常与这种理念背道而驰。追求分数和表面成绩的过程中，往往偏离了对真理与知识本身的追求。真正的正反馈应该来源于自己对世界现象的深入探索和理解，而不是在相同时间内比别人学得更多或更快。然而，现行的学习模式与评估机制却经常以知识量和学习速度为衡量标准，这自然带来学习的痛苦与焦虑。     我感觉学习的过程，就像不断地获得观察世界的工具。就好像一个天生视力不足、近视800度的人，通过不断调整镜片逐渐看清更远处的风景，视野变得越来越清晰，景深也逐渐增加。这种逐步清晰的过程本应是快乐且满足的。而考试或者测试，就像是观察世界中的一些特殊案例（corner cases），本质上是一种检验我们观察能力的方式。     但令人奇怪的是，我们往往用一种截然相反的标准去评价——在特定的时间段内，谁观察得更多，掌握的知识更广。这种评价方法尽管表面上合理，但实际上却忽略了真正重要的事情：人们学习过程中自发的正反馈和内在的学习速度。不过如果评估的范围和规模足够大，确实能够从中挑选出那些本身就能获得正反馈、学习速度较快的人。     最终，学习不应只是一场速度与数量的竞争，而更应该是一场逐渐拓宽视野、深入理解世界的旅程。理解并尊重学习的本质，才能真正享受学习的快乐与成长。    2025-04-27   好像也解决了那个所谓买菜为什么要数学的问题, 如果对探知的要求只有百元以内的菜价, 那么好像确实没有持续学习的必要了. 再引申开来一点的话, 如果课本里的知识没有在帮助解决现实中的问题，只提供难和奇怪的过程, 就很容易让人觉得它们抽象且难以消化。而且，我认为一部分学习带来的成就感来源于和他人的比较，一旦身边的同路人越来越少，或者遇到天赋更高的人，这种动力就会逐渐消失. 所以我感觉做事的时候更应该想清楚目的.   一点粗浅的感想罢了.   ","categories": [],
        "tags": [],
        "url": "/learning/",
        "teaser": null
      },{
        "title": "Linear Algebra Starting from Matrix Multiplication",
        "excerpt":"好像写成一个的线代的内容了, 有很多未完待续的内容   我可以算出矩阵乘法的题目，但当涉及到矩阵乘法的交换顺序的意义，或者说矩阵乘法本身的内在含义时，我往往无法在第一时间作出直觉反应。   在做矩阵乘法的时候，我依赖的是一种背诵的技巧, 提醒自己这个东西叫 “行列式”, 所以“前一个矩阵的行, 乘以后一个矩阵的列”。但我并不知道这个操作实际上意味着什么。 经过自己的反思，我发现，我之所以缺乏这种直觉，是因为我对“矩阵乘法”这一概念没有真正理解。在除了得到一个结果外, 矩阵乘法到底在干什么。这个很基本的数学定义 or 数学概念想要解决现实中的什么问题?   这种基于死记硬背的方式，让我在进一步思考矩阵相关的概念时(如旋转、投影、缩放等操作, 或者是去括号, 转置, 求可逆矩阵的一些变式)，总是感觉模糊和经常出错。因为从最底层开始，我对矩阵的理解就是模糊的，甚至可以说是错的，导致我没法基于它构建准确的思维。   我想解决这个问题。   线性变换的复合 (Composition of Linear Transformations)   出现问题的一个comment的场景  下面是一个 $5 \\times 5$ 的矩阵相乘的例子, 这是一个很好的例子就是,  \\(\\begin{bmatrix} A_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} &amp; a_{15} \\\\ A_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} &amp; a_{25} \\\\ A_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} &amp; a_{35} \\\\ A_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} &amp; a_{45} \\\\ A_{51} &amp; a_{52} &amp; a_{53} &amp; a_{54} &amp; a_{55} \\\\ \\end{bmatrix} \\times \\begin{bmatrix} B_{11} &amp; b_{12} &amp; b_{13} &amp; b_{14} &amp; b_{15} \\\\ B_{21} &amp; b_{22} &amp; b_{23} &amp; b_{24} &amp; b_{25} \\\\ B_{31} &amp; b_{32} &amp; b_{33} &amp; b_{34} &amp; b_{35} \\\\ B_{41} &amp; b_{42} &amp; b_{43} &amp; b_{44} &amp; b_{45} \\\\ B_{51} &amp; b_{52} &amp; b_{53} &amp; b_{54} &amp; b_{55} \\\\ \\end{bmatrix} = \\begin{bmatrix} C_{11} &amp; c_{12} &amp; c_{13} &amp; c_{14} &amp; c_{15} \\\\ C_{21} &amp; c_{22} &amp; c_{23} &amp; c_{24} &amp; c_{25} \\\\ C_{31} &amp; c_{32} &amp; c_{33} &amp; c_{34} &amp; c_{35} \\\\ C_{41} &amp; c_{42} &amp; c_{43} &amp; c_{44} &amp; c_{45} \\\\ C_{51} &amp; c_{52} &amp; c_{53} &amp; c_{54} &amp; c_{55} \\\\ \\end{bmatrix}\\)   疑惑的点是, 如果认为任意一个matrix都是列向量的话, 那么其实在这个显而易见的式子中, $A   x = b$ 中, 一个认知是$A$  可以被认为是一个大的系统(如果是 n by m的matrix), $x$作为一个vector(拆分成竖直方向上的单列) (woc这里应该是 1 乘 多少的单列vector我不可以一秒判断出来), 由于疑惑, 我回到传统想法上的记住行列式的乘法的方法, 会发现, 这个结果也是一列的其实, 但是我对于怎么乘是模糊的, OK再想 行乘以列这个口诀, 也就是说, vector的第一个, 乘了A的第一个行, 这是也是第一个b上的结果, 那么这个第一个位置上的结果到底是什么东西呢, 不是最后要写的结果, 而是搞不明白代表什么东西   {3Blue1Brown} Linear transformations and matrices | Chapter 3, Essence of linear algebra   回到一个简单的问题, 下面是一个在二维平面中的vector, \\(\\vec{v} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}\\) 如何看待这个对象呢, 可以认为是, 使用两个单位矩阵构造的, which is  $\\hat{j} = \\begin{bmatrix} 0\\ 1 \\end{bmatrix}$ 和$\\hat{i}= \\begin{bmatrix} 1\\ 0 \\end{bmatrix}$, 这里可以注意到, $\\hat{j}$ 在 $y$ 轴上, 而 $\\hat{i}$ 在 $x$ 轴上, 那么我们的 $\\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ 是如何得到的呢?  使用线性变换(注:要补充)的概念非常简单, 我们可以得到 \\(\\vec{v} = (-1) \\cdot \\hat{i} + 2 \\cdot \\hat{j} = (-1) \\cdot \\begin{bmatrix} 1\\\\ 0 \\end{bmatrix} + 2 \\cdot \\begin{bmatrix} 0\\\\ 1 \\end{bmatrix} = \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}\\)   OK, 再进一步的视角是,  \\(\\)   我原来以为, $\\begin{bmatrix} -1 \\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 &amp; 0 \\0 &amp;1 \\end{bmatrix}$ 是可以得到 $\\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ , 但是现在发现我错了(而且这也是非法的矩阵相乘), 应该是$\\begin{bmatrix} 1 &amp; 0 \\0 &amp;1 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$因为和下面的逻辑混淆了, 3Blue1Brown说, 对于(这里我随机写了一个例子) $\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ 这里其实是让新的基底变成 $\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix}$ 而不再是原来的 $\\begin{bmatrix} 1 &amp; 0 \\0 &amp;1 \\end{bmatrix}$ 我在想是不是原来对于 $\\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ 是不是后面都藏着一个 $\\begin{bmatrix} 1 &amp; 0 \\0 &amp;1 \\end{bmatrix}$ 代表着原来的基底?   哦哦, 不是的, 应该说一个结果的基座向量会写在结果的前面, $I \\cdot \\vec{v} = \\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix} = \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$, 这样反而是恰当的, 合乎逻辑的, 但是在前面乘一个单位矩阵太傻了, 但是可以发现的是, 在前面乘就是提供 一个要变换的指令, 只不过单位矩阵恰好是没有任何变化要求的那个. 而 $\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ 可以被认为是$\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$   这个表述错了 $\\rightarrow$ 其实在$\\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$的后面乘是逆变化, 不过这是后话了. 变化可以认为就是在前面乘, 在前面乘就是在做各种线性操作, 比如转回去就是在前面的位置乘一个逆就行了   但是我好像还是没搞懂为什么能变成这样, $(-1) \\cdot \\begin{bmatrix} -1 \\ 1\\end{bmatrix} \\cdot + 2 \\cdot  \\begin{bmatrix} 4 \\ 2\\end{bmatrix}$  3Blue1Brown的视频中, 是这样写的, $\\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$  被我们看成了单独放置的点 or 一个向量的箭头指向这个点的位置, 这样的意义也可以这样表示$\\vec{v} = -1 \\cdot \\vec{i}_1 + 2 \\cdot \\vec{j}_2$,  这个点的表示分, 我突然看到感觉好陌生, 之前好像没有只是顺着写了一下, 自己不知道为什么可以这样写. OK, 如果可以这样写的话, 就相对清晰了, 就是, 直接换了一套基座, 对于这个式子而言, $\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 \\ 2 \\end{bmatrix}$ 不是吗,   再描述一个更加抽象的例子   \\[A \\cdot B = C\\]  这里的$A$ 和 $B$ 都是 $4 \\times 4$ 的matrix   从列的角度看这个问题后, 好吧, 突然我也不知道这里从列的角度看是什么意思, 我姑且认为在做的开始, $A$ 和 $B$ 都被认为是一列一列呈现的   $A$就被我们看成从$$   A = \\begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} \\ a_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} \\ a_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} \\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} \\end{bmatrix} \\(​​​​ 列向量视角的 $A$：\\) A = \\left[ \\vec{a}_1 \\quad \\vec{a}_2 \\quad \\vec{a}_3 \\quad \\vec{a}_4 \\right] $$   \\[\\vec{a}_1 = \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix}, \\quad \\vec{a}_2 = \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix}, \\quad \\vec{a}_3 = \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix}, \\quad \\vec{a}_4 = \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix}\\]  OK, 我们得到 $A = \\left[ \\vec{a}_1 \\quad \\vec{a}_2 \\quad \\vec{a}_3 \\quad \\vec{a}_4 \\right]$ 后开始处理 $B$ , 同样列向量视角 ​​​​  从\\(B = \\begin{bmatrix} b_{11} &amp; b_{12} &amp; b_{13} &amp; b_{14} \\\\ b_{21} &amp; b_{22} &amp; b_{23} &amp; b_{24} \\\\ b_{31} &amp; b_{32} &amp; b_{33} &amp; b_{34} \\\\ b_{41} &amp; b_{42} &amp; b_{43} &amp; b_{44} \\end{bmatrix}\\) ​到 \\(B = \\left[ \\vec{b}_1 \\quad \\vec{b}_2 \\quad \\vec{b}_3 \\quad \\vec{b}_4 \\right]\\)   \\[\\vec{b}_1 = \\begin{bmatrix} b_{11} \\\\ b_{21} \\\\ b_{31} \\\\ b_{41} \\end{bmatrix}, \\quad \\vec{b}_2 = \\begin{bmatrix} b_{12} \\\\ b_{22} \\\\ b_{32} \\\\ b_{42} \\end{bmatrix}, \\quad  \\vec{b}_3 = \\begin{bmatrix} b_{13} \\\\ b_{23} \\\\ b_{33} \\\\ b_{43} \\end{bmatrix}, \\quad  \\vec{b}_4 = \\begin{bmatrix} b_{14} \\\\ b_{24} \\\\ b_{34} \\\\ b_{44} \\end{bmatrix}, \\quad\\]  写完后, 我们的 $B$ 作为之前的数值位置, $A$中的向量都是作为新的坐标系来构建, 那么我们可以得到   3. “列中列”展开法的具体表示   矩阵乘积 $C = A \\cdot B$ 的完整展开形式：   \\[C = \\left[ \\begin{array}{cccc} b_{11} \\cdot \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix} + b_{21} \\cdot \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix} + b_{31} \\cdot \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix} + b_{41} \\cdot \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix} &amp; b_{12} \\cdot \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix} + b_{22} \\cdot \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix} + b_{32} \\cdot \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix} + b_{42} \\cdot \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix} &amp; b_{13} \\cdot \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix} + b_{23} \\cdot \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix} + b_{33} \\cdot \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix} + b_{43} \\cdot \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix} &amp; b_{14} \\cdot \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix} + b_{24} \\cdot \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix} + b_{34} \\cdot \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix} + b_{44} \\cdot \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix} \\end{array} \\right]\\]  $\\rightarrow$   \\(\\left[ \\begin{array}{cccc} \\begin{bmatrix} b_{11} a_{11} \\\\ b_{11} a_{21} \\\\ b_{11} a_{31} \\\\ b_{11} a_{41} \\end{bmatrix} + \\begin{bmatrix} b_{21} a_{12} \\\\ b_{21} a_{22} \\\\ b_{21} a_{32} \\\\ b_{21} a_{42} \\end{bmatrix} + \\begin{bmatrix} b_{31} a_{13} \\\\ b_{31} a_{23} \\\\ b_{31} a_{33} \\\\ b_{31} a_{43} \\end{bmatrix} + \\begin{bmatrix} b_{41} a_{14} \\\\ b_{41} a_{24} \\\\ b_{41} a_{34} \\\\ b_{41} a_{44} \\end{bmatrix} &amp; \\begin{bmatrix} b_{12} a_{11} \\\\ b_{12} a_{21} \\\\ b_{12} a_{31} \\\\ b_{12} a_{41} \\end{bmatrix} + \\begin{bmatrix} b_{22} a_{12} \\\\ b_{22} a_{22} \\\\ b_{22} a_{32} \\\\ b_{22} a_{42} \\end{bmatrix} + \\begin{bmatrix} b_{32} a_{13} \\\\ b_{32} a_{23} \\\\ b_{32} a_{33} \\\\ b_{32} a_{43} \\end{bmatrix} + \\begin{bmatrix} b_{42} a_{14} \\\\ b_{42} a_{24} \\\\ b_{42} a_{34} \\\\ b_{42} a_{44} \\end{bmatrix} &amp; \\begin{bmatrix} b_{13} a_{11} \\\\ b_{13} a_{21} \\\\ b_{13} a_{31} \\\\ b_{13} a_{41} \\end{bmatrix} + \\begin{bmatrix} b_{23} a_{12} \\\\ b_{23} a_{22} \\\\ b_{23} a_{32} \\\\ b_{23} a_{42} \\end{bmatrix} + \\begin{bmatrix} b_{33} a_{13} \\\\ b_{33} a_{23} \\\\ b_{33} a_{33} \\\\ b_{33} a_{43} \\end{bmatrix} + \\begin{bmatrix} b_{43} a_{14} \\\\ b_{43} a_{24} \\\\ b_{43} a_{34} \\\\ b_{43} a_{44} \\end{bmatrix} &amp; \\begin{bmatrix} b_{14} a_{11} \\\\ b_{14} a_{21} \\\\ b_{14} a_{31} \\\\ b_{14} a_{41} \\end{bmatrix} + \\begin{bmatrix} b_{24} a_{12} \\\\ b_{24} a_{22} \\\\ b_{24} a_{32} \\\\ b_{24} a_{42} \\end{bmatrix} + \\begin{bmatrix} b_{34} a_{13} \\\\ b_{34} a_{23} \\\\ b_{34} a_{33} \\\\ b_{34} a_{43} \\end{bmatrix} + \\begin{bmatrix} b_{44} a_{14} \\\\ b_{44} a_{24} \\\\ b_{44} a_{34} \\\\ b_{44} a_{44} \\end{bmatrix} \\end{array} \\right]\\)  $\\rightarrow$   其中我们拿出一条来 \\(b_{11} \\cdot \\begin{bmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\\\ a_{41} \\end{bmatrix} + b_{21} \\cdot \\begin{bmatrix} a_{12} \\\\ a_{22} \\\\ a_{32} \\\\ a_{42} \\end{bmatrix} + b_{31} \\cdot \\begin{bmatrix} a_{13} \\\\ a_{23} \\\\ a_{33} \\\\ a_{43} \\end{bmatrix} + b_{41} \\cdot \\begin{bmatrix} a_{14} \\\\ a_{24} \\\\ a_{34} \\\\ a_{44} \\end{bmatrix}\\) 是这样的,  \\(\\begin{bmatrix} b_{11}a_{11} \\\\ b_{11}a_{21} \\\\ b_{11}a_{31} \\\\ b_{11}a_{41} \\end{bmatrix} + \\begin{bmatrix} b_{21}a_{12} \\\\ b_{21}a_{22} \\\\ b_{21}a_{32} \\\\ b_{21}a_{42} \\end{bmatrix} + \\begin{bmatrix} b_{31} a_{13} \\\\ b_{31}a_{23} \\\\ b_{31} a_{33} \\\\ b_{31} a_{43} \\end{bmatrix} +\\begin{bmatrix} b_{41}a_{14} \\\\ b_{41}a_{24} \\\\ b_{41}a_{34} \\\\ b_{41}a_{44} \\end{bmatrix}\\)   再线性相加 \\(= \\begin{bmatrix} b_{11}a_{11} + b_{21}a_{12} + b_{31}a_{13} + b_{41}a_{14} \\\\ b_{11}a_{21} + b_{21}a_{22} + b_{31}a_{23} + b_{41}a_{24} \\\\ b_{11}a_{31} + b_{21}a_{32} + b_{31}a_{33} + b_{41}a_{34} \\\\ b_{11}a_{41} + b_{21}a_{42} + b_{31}a_{43} + b_{41}a_{44} \\end{bmatrix}\\)   这是一个$4\\times 1$的矩阵, 然后我们有4条, 最后是 一个$4\\times 4$ 的结果   \\[\\begin{bmatrix} a_{11} b_{11} + a_{12} b_{21} + a_{13} b_{31} + a_{14} b_{41} &amp; a_{11} b_{12} + a_{12} b_{22} + a_{13} b_{32} + a_{14} b_{42} &amp; a_{11} b_{13} + a_{12} b_{23} + a_{13} b_{33} + a_{14} b_{43} &amp; a_{11} b_{14} + a_{12} b_{24} + a_{13} b_{34} + a_{14} b_{44} \\\\ a_{21} b_{11} + a_{22} b_{21} + a_{23} b_{31} + a_{24} b_{41} &amp; a_{21} b_{12} + a_{22} b_{22} + a_{23} b_{32} + a_{24} b_{42} &amp; a_{21} b_{13} + a_{22} b_{23} + a_{23} b_{33} + a_{24} b_{43} &amp; a_{21} b_{14} + a_{22} b_{24} + a_{23} b_{34} + a_{24} b_{44} \\\\ a_{31} b_{11} + a_{32} b_{21} + a_{33} b_{31} + a_{34} b_{41} &amp; a_{31} b_{12} + a_{32} b_{22} + a_{33} b_{32} + a_{34} b_{42} &amp; a_{31} b_{13} + a_{32} b_{23} + a_{33} b_{33} + a_{34} b_{43} &amp; a_{31} b_{14} + a_{32} b_{24} + a_{33} b_{34} + a_{34} b_{44} \\\\ a_{41} b_{11} + a_{42} b_{21} + a_{43} b_{31} + a_{44} b_{41} &amp; a_{41} b_{12} + a_{42} b_{22} + a_{43} b_{32} + a_{44} b_{42} &amp; a_{41} b_{13} + a_{42} b_{23} + a_{43} b_{33} + a_{44} b_{43} &amp; a_{41} b_{14} + a_{42} b_{24} + a_{43} b_{34} + a_{44} b_{44} \\end{bmatrix}\\]  这时候有一些经典的问题, 就是从这个转动的性质出发了           矩阵相乘是否满足交换率? 当然不行, 都完全是两个东西了            矩阵相乘成立的条件是前一个matrix的什么要等于后一个matrix的什么? 完全不用急, 想着 $Ax = b$ 在这个时候,  $A$ 是我们的旋转/变换系统, 想象每一列都是独立的, rank是满秩的(其实不用只要操作的时候有那个维度就OK了), 那么在这个情况下, 我们的 $x$ 中的 $[x_1 \\dots x_n]$ 当然是要和前面的 $A$ 有多少列要匹配了            这里理解错了, 说明有知识点没懂     $Ax = b$ 中的 b是 几乘几点结果, 感觉x的维度是怎样, b就长怎样? 如果从 $A$ 是提供旋转功能的角度出发的话, 为什么会因为旋转 b相比原先旋转的对象 x 增加维度呢?  这其实是更广义的「线性变换」，不仅仅是旋转, 不一定是严格的旋转，它可以是 旋转 + 拉伸(放大缩小) 投影 (把高维变低维) 嵌入 (把低维映射到高维) 剪切(shear)       如果说 3 by 2的matrix, 如何0.5s内说出 2 是2行还是2列? 之前我是使用行列式这样的背住然后套的, 但是这里提供一种更加直觉的想法, 是, 我们定义这个名字的时候, 更加关注输出, 什么是输出, 变换后矩阵的维度, 那么变换后矩阵的维度是什么, 是由什么确定的, 这样想下去就是, 当然是  $A$ 这个提供变换的方案的matrix确定, 然后再想象一下, 这里的A的维度是什么, 是A的行数(row), 因为我们考虑的是A每一列vector的维度, 这样我们这个变化系统的row就确定了, 所以3 by 2的matrix的话, 3 $\\rightarrow$  row, 所以是3 行 2 列的矩阵.   未完待续     矩阵乘法的剩下三种理解方法   变化的特色case, 为什么有些乘上有些矩阵的时候, 在一个维度上没有变动   第二个问题在看3Blue1Brown发现他希望不动的x维度上, 对应的 A的位置, 好像都是单位矩阵的part, 虽然不知道再哪个位置(哪一层)放1   之后要详细讨论的点是, 在3这个视频中, 所谓的 单个 $A$ 矩阵如果是变换作用的话, 居然直接是单位矩阵想要最后变成的固定状态(停在那个位置).   左乘看成新坐标系的基向量，右边的原向量看成标量     标准基底下的矢量                                                                                                                                                                                                                                  î (1,0)          ĵ (0,1)          v (1,2)                                                                变换基底后的矢量                                                                                                                                                                                                                             î' (1,0)          ĵ' (1,1)          v' (3,2)                                                                   还有细节是对于提供变化的matrix $\\begin{bmatrix} -1 &amp; 4 \\ 1 &amp; 2 \\end{bmatrix}$ , 我们可以直接认为其中$\\begin{bmatrix} -1  \\ 1  \\end{bmatrix}$ 就是 unit vector $i$ 的新位置, 而$\\begin{bmatrix} 4 \\2 \\end{bmatrix}$ 就是 unit vector $j$ 的新位置   #  Chapter 4, Essence of linear algebra, Chapter 5 说了一下三维, 没讲什么  章节中对于$x$ 多维过程计算一个batch的过程, 其实就是拆开一步步的过程   $$ \\begin{align*} &amp;\\underset{M_2}{\\begin{bmatrix} \\textcolor{purple}0 &amp; \\textcolor{purple}2 \\ \\textcolor{purple}1 &amp; \\textcolor{purple}0 \\end{bmatrix}}  \\cdot  \\underset{M_1}{\\begin{bmatrix}  \\color{green}{1} &amp; \\color{orange}{-2} \\  \\color{green}{1} &amp; \\color{orange}{0}  \\end{bmatrix}}  =  \\begin{bmatrix}  ? &amp; ? \\  ? &amp; ?  \\end{bmatrix}  \\[10pt]   &amp;\\begin{bmatrix}  \\textcolor{purple}0 &amp; \\textcolor{purple}2 \\  \\textcolor{purple}1 &amp; \\textcolor{purple}0  \\end{bmatrix}  \\cdot  \\begin{bmatrix}  \\color{green}{1}\\  \\color{green}{1} \\end{bmatrix}  = \\textcolor{green}{1} \\cdot \\begin{bmatrix}  \\textcolor{purple}0 \\  \\textcolor{purple}1 \\end{bmatrix}     \\textcolor{green}{1} \\cdot  \\begin{bmatrix}  \\textcolor{purple}2 \\  \\textcolor{purple}0  \\end{bmatrix}  =  \\begin{bmatrix}  2 \\  1  \\end{bmatrix} \\end{align} \\(我们得出 $\\rightarrow$\\) \\begin{align} &amp;\\underset{M_2}{\\begin{bmatrix} \\textcolor{purple}0 &amp; \\textcolor{purple}2 \\ \\textcolor{purple}1 &amp; \\textcolor{purple}0 \\end{bmatrix}}  \\cdot  \\underset{M_1}{\\begin{bmatrix}  \\color{green}{1} &amp; \\color{orange}{-2} \\  \\color{green}{1} &amp; \\color{orange}{0}  \\end{bmatrix}}  =  \\begin{bmatrix}  2 &amp; ? \\  1 &amp; ?  \\end{bmatrix}  \\[10pt] \\end{align*}   $$ 这里其实有一个小疑惑, 就是$ABCDEF \\cdot x$ 中, 第一个$F$, 对于 $x$ 的坐标映射, 是不是就是遵循$F$ 中的样子来就可以了, 但是对于剩下的步骤, 因为大概率不orthogonal, 所以其实多维的都有影响?   1. 矩阵乘法的剩下三种理解方法   图设计来自gwave 知乎答主, 使用svg重新绘制, 突出版权, 在重制中仍然保留水印.   矩阵-向量乘法-列视角：矩阵右乘列向量，向量对矩阵的列进行线性组合                                                  ×            a      b      c         =                        a         +                        b         +                        c         =                        知乎 @waywa  矩阵-向量乘法-行视角：矩阵左乘行向量，向量对矩阵的行进行线性组合           a      b      c         ×                                                   =               a                  +            b                  +            c                  =                        知乎 @waywa  还没理解完, 未完待续   RREF(Reduced Row-Echelon Form)   感觉是一个很小的概念不在ML中常用到,  意思是“是不是高斯消元法最后让每个基向量尽可能简单”，那可以说是的。每一行代表一个单位基方向，其他方向全0, 可以理解成“最小单位向量”，但其实数学上是标准基, 但是注意，它们不一定是整个空间的 unit vector，而是 在矩阵的列空间或行空间中形成了一个基底。   彼此线性无关，数量就是行空间的维度，也就是矩阵的秩。 列空间的秩=行空间的秩, 这个概念好像是有点背的, 还有下面这个公式 \\(rank(A)=rank(A^\\top)\\) 秩，GPT说其实代表这个系统“真正有多复杂”，而不是表面的行和列数量。   Reference   矩阵乘法核心思想（2）：行空间 - gwave 知乎 https://zhuanlan.zhihu.com/p/348551903 Essence of linear algebra 3Blue1Brown  https://youtu.be/fNk_zzaMoSs?si=UlVZ_LHcoih4kQvu NTU 线性代数 Hung-yi Lee (李宏毅) https://googly-mingto.github.io/LA_2022_fall/2022-fall.html MIT18.06 Linear-Algebra  https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/  ","categories": [],
        "tags": [],
        "url": "/%E4%BB%8EMatrix-%E4%B9%98%E6%B3%95%E8%AE%A1%E7%AE%97%E5%87%BA%E5%8F%91%E7%9A%84Linear-Algebra/",
        "teaser": null
      }]
